{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RL_MountainCar_DQN_Conv.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10Pr-JPdviDa",
        "outputId": "2656c7a9-1856-475f-93b5-fa36542bcae4"
      },
      "source": [
        "# install required system dependencies\n",
        "!apt-get install -y xvfb python-opengl > /dev/null 2>&1\n",
        "!pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "!apt-get install x11-utils > /dev/null 2>&1\n",
        "!pip install pyglet==v1.5.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pyglet==v1.5.0 in /usr/local/lib/python3.6/dist-packages (1.5.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from pyglet==v1.5.0) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3gDx9KDRh2m"
      },
      "source": [
        "import math\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from collections import namedtuple\n",
        "from itertools import count\n",
        "from PIL import Image\n",
        "import cv2\n",
        "\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "\n",
        "# set up matplotlib\n",
        "is_ipython = 'inline' in matplotlib.get_backend()\n",
        "if is_ipython:\n",
        "    from IPython import display\n",
        "\n",
        "plt.ion()\n",
        "\n",
        "# Open AI related\n",
        "import gym\n",
        "from gym import logger as gymlogger\n",
        "from gym.wrappers import Monitor\n",
        "gymlogger.set_level(40) #error only\n",
        "\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "\n",
        "# set up OpenAi Gym render in Colab\n",
        "from IPython import display as ipythondisplay\n",
        "from pyvirtualdisplay import Display\n",
        "_display = Display(visible=False,  # use False with Xvfb\n",
        "                   size=(1400, 900))\n",
        "_ = _display.start()\n",
        "\n",
        "# if gpu is to be used\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAkSJXnZ6ZwX"
      },
      "source": [
        "## Show Gym Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jX13PeR03duc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "fdcbc87a-c4f9-4530-c5ff-a193c2615776"
      },
      "source": [
        "env = gym.make('MountainCar-v0').unwrapped\n",
        "env.reset()\n",
        "img = plt.imshow(env.render(mode='rgb_array')) # returned screen by gym is 400x600x3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33GSJbtVZavN"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoGBBakfZe-6"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "GAMMA = 0.999\n",
        "EPS_START = 1 # explore rate (start)\n",
        "EPS_END = 0.1 # explore rate (end)\n",
        "MAX_EPS_DECAY_STEPS = 500000\n",
        "TARGET_UPDATE = 10 # Freqency of updating target network, copying all weights and biases in DQN\n",
        "REPLAY_MEMORY_SIZE = 50000\n",
        "NUM_EPISODE = 150\n",
        "k = 4 # Agenet select new action on every kth frame\n",
        "SCREEN_SIZE = 84 # height and width since we want training image to be a square"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2lF4pPBI_hgH"
      },
      "source": [
        "## Replay Memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0fr3w347npT"
      },
      "source": [
        "Transition = namedtuple('Transition',('state', 'action', 'next_state', 'reward'))\n",
        "\n",
        "\n",
        "class ReplayMemory(object):\n",
        "\n",
        "    def __init__(self, capacity):\n",
        "        self.capacity = capacity\n",
        "        self.memory = []\n",
        "        self.position = 0\n",
        "\n",
        "    def push(self, *args):\n",
        "        \"\"\"Saves a transition.\"\"\"\n",
        "        if len(self.memory) < self.capacity:\n",
        "            self.memory.append(None)\n",
        "        self.memory[self.position] = Transition(*args)\n",
        "        self.position = (self.position + 1) % self.capacity\n",
        "\n",
        "    def sample(self, batch_size):\n",
        "        return random.sample(self.memory, batch_size)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.memory)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x92xQonBntXT"
      },
      "source": [
        "## Deep Q Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3WY0aj078g4"
      },
      "source": [
        "class DQN(nn.Module):\n",
        "\n",
        "    def __init__(self, outputs):\n",
        "        super(DQN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(4, 16, kernel_size=8, stride=4) \n",
        "        self.bn1 = nn.BatchNorm2d(16)\n",
        "        self.conv2 = nn.Conv2d(16, 32, kernel_size=4, stride=2)\n",
        "        self.bn2 = nn.BatchNorm2d(32)\n",
        "        self.conv3 = nn.Conv2d(32, 32, kernel_size=3, stride=1)\n",
        "        self.bn3 = nn.BatchNorm2d(32)\n",
        "\n",
        "        # Number of Linear input connections depends on output of conv2d layers\n",
        "        # and therefore the input image size, so compute it.\n",
        "        def conv2d_size_out(size, kernel_size, stride):\n",
        "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
        "        \n",
        "        conv_size1 = conv2d_size_out(SCREEN_SIZE, 8, 4)\n",
        "        conv_size2 = conv2d_size_out(conv_size1, 4, 2)\n",
        "        conv_size3 = conv2d_size_out(conv_size2, 3, 1)\n",
        "\n",
        "        linear_input_size = conv_size3 * conv_size3 * 32\n",
        "        print(\"linear_input_size:\", linear_input_size)\n",
        "\n",
        "        # fully connected layor\n",
        "        self.fc1 = nn.Linear(linear_input_size, 256)\n",
        "        self.fc2 = nn.Linear(256, outputs)\n",
        "\n",
        "    # Called with either one element to determine next action, or a batch\n",
        "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        # fully connected\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BodgRA9xdWRP"
      },
      "source": [
        "## Extract and Process Images from Gym Environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFW577rn1EZV"
      },
      "source": [
        "def get_screen(environment):\n",
        "    # Transpose returned screen from gym (400x600x3) into torch order (CHW).\n",
        "    screen = environment.render(mode='rgb_array').transpose((2, 0, 1))\n",
        "    \n",
        "    # Convert to float, rescale, convert to torch tensor\n",
        "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
        "    screen = torch.from_numpy(screen)\n",
        "    # Resize\n",
        "    resize = T.Compose([T.ToPILImage(),\n",
        "                    T.Grayscale(num_output_channels=1),\n",
        "                    T.Resize((SCREEN_SIZE, SCREEN_SIZE), interpolation=Image.CUBIC),\n",
        "                    T.ToTensor()])\n",
        "    return resize(screen)\n",
        "\n",
        "def stack_past_four_frames(frame1, frame2, frame3, frame4):\n",
        "    frames = torch.stack([frame1.squeeze(0), frame2.squeeze(0), frame3.squeeze(0), frame4.squeeze(0)], dim=0)\n",
        "    # Add a batch dimension (BCHW)\n",
        "    return frames.unsqueeze(0).to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "xaBjhEjrXYD_",
        "outputId": "09bb3813-2707-4f3e-9d07-b842d18ea45f"
      },
      "source": [
        "env.reset()\n",
        "plt.figure()\n",
        "example_screen = get_screen(env).cpu().squeeze(0).numpy()\n",
        "plt.imshow(example_screen, interpolation='none')\n",
        "plt.title('Example Extracted Screen')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAEICAYAAACZA4KlAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAc3UlEQVR4nO3deZhU1Z3/8feHZgdlBwlgwJWgRjCEyGAUt4gmAhmNQhInGhOzRyc+uE2exzhjMjEmQX/jRMfRROI4UWPcgo4biBEUESKuuICiICigKAKKLOf3x71169pWd1fT1bX0/byep54+de6tqu+t6lPn1LnnnqMQAmbW9rWrdABmVh4u7GYZ4cJulhEu7GYZ4cJulhEu7GYZ4cJeJSSdKmlupeOoNpKCpL0qHUdbkInCLmm5pPclbUzdrqh0XKUiaY6kD+od31+LeNzQuDC1b6W4WvULTNJ+ku6T9LakdyQtknRca71erWuVD7lKHR9CeKDSQbSiH4YQrin1k0pqH0LYVurnLZG/AlcCX4rvfxZQc55AkgCFEHaUOLaqk4mavTGSrpT0l9T9SyTNUqSXpJmS1kpaH6cHp/adI+liSY/kalNJfSTdIGmDpMclDU3tHyT9WNLLktZJulRSwc9A0nBJ98e11guSTtrJ4ztX0mO52lvS9yQ9K6kz8Ld4t3fi+MfGtfE8SdMlvQX8TNKekmZLeiuO+wZJPVOvMUTSrfH79JakKyR9CrgKGBs/9zvxvp0k/VrSa5LelHSVpC6p55omabWkVZK+2chx9QWGAf8dQvgwvs0LIcxN7TNJ0uL4s1gmaUKcP0fSzyXNAzYDezT2fjcWs6TxklZKOlvSmjj203bms2p1IYQ2fwOWA0c1sK0r8CJwKvB5YB0wON7WBzgh3mcX4M/A7anHzgGWAnsCPYDn4uc6iqjV9EfgD6n9A/Ag0BvYPd73W/G2U4G5cbobsAI4LX6eUXFcIxo4hjm55ymwrR1Rof4ZsDewHhgVbxsax9Q+tf+pwDbgR/FrdwH2Ao4GOgH94ue7LN6/DngSmB7H3Rk4pP4xpZ5/OnBn/B7sQlQ7/3u8bQLwJrB//Fz/G8e3V4HjEvASMBOYDAyot30M8G4cdztgEDA89X69BuwXH2OPxt7vJmIeH79f/wp0AI4j+gLpVen/+4+9Z5UOoCwHGRX2jcA7qdu3U9s/B7wNvApMbeR5RgLr6xWyf0nd/w3wf6n7xwOLU/cDMCF1//vArPoFAzgZeLjea/8XcGEDcc2J/8HSx/dvqe1D4+NbApxfL79QYX+tifdzMvBEnB4LrE0/R73nmpu6L2ATsGcqbyzwSpz+PfDL1LZ9aKCwx9sHA1cAy4AdRF9Ce6fer+mNvF//mrrf4PtdRMzjgffrvYdrgIMr/X9f/5al3+yTQwO/2UMIj0l6GegP3JzLl9SV6Ft9AtArzt5FUl0IYXt8/83UU71f4H73ei+3IpV+FfhEgZA+CXwu1/SNtQeuLxR/7Mehgd/sIYTlkh4kqnX+s5HnKBQjkgYAlxO1fHYhqinXx5uHAK+G4n7X9yNqJS2KfipHT0/UOoDovViU2v/Vxp4shLAS+GEc4xDgaqLW1Ng4rrsbeXj6GBt7v5uKGeCtese/mY9/7hWX+d/sAJJ+QNREXQWck9p0NrAv8LkQwq7AobmHtODlhqTSu8evWd8K4KEQQs/UrXsI4Xs784KSvkhUAGYBl6Y2NXTJY/38X8R5B8Tvw9fJvwcrgN0b6NGv/zzriL4A90sdV48QQq5grObj709RQggriL7I9k/FtWdjD0mlG3u/m4q5ZmS+sEvaB7iY6B/4FOAcSSPjzbsQfdDvSOpN1KxrqWlxx98Q4EzgpgL7zAT2kXSKpA7x7bNxp1ezxB1Z1wDfAr4BHJ86PbWWqPm7RxNPswvRz6B3JQ0CpqW2LSAqpL+U1E1SZ0nj4m1vAoMldQQIUY/3fwPTJfWP4xsk6Zh4/5uBUyWNiFtVDb7f8Xt4kaS9JLWLj/ObwPx4l2uB0yQdGW8fJGl4A0/X4PtdRMw1I0uF/a/66Hno2+La6H+AS0IIT4YQXgIuAK6X1Am4jKiDah3RP9E9JYjjDqKm6mLgLqJ/yo8IIbwHfAGYQlTzvwFcQtT6aMgV9Y4v1xy+GrgjhHB3COEt4HTgGkl9QgibgZ8D8xSdpz64gee+CDiIqMPrLuDWVKzbifom9iLq9FpJ9BsYYDbwLPCGpHVx3rlEnZrzJW0AHiBqPRFC+D+i93x2vM/sRo73Q6I+hweADcAzwBaifgJCCAuIOtymx3E/RNRc/5gi3u8GY64lijsUrAwkBaIOpKWVjsWyJ0s1u1mmubCbZUSLCrukCfFoo6WSzitVUG1VCEFuwlul7PRvdkl1RCPAjibqlHmcaEDKc6ULz8xKpSWDasYAS0MILwNIuhGYRDRktKC+vevC0CEdWvCSZtaY5Su2su7t7QXHgbSksA/io6OQVhINO23Q0CEdWHDvkMZ2MbMWGHPMiga3tXoHnaQzJC2UtHDtW9ubfoCZtYqWFPbX+ejQxsFx3keEEK4OIYwOIYzu16eu/mYzK5OWFPbHgb0lDYuHQ04hugzQzKrQTv9mDyFsk/RD4F6iK4B+H0J4tmSRmVlJtegS1xDC3TR+GaGZVQmPoDPLiCxNXmFWE7aG/Fmr+97vlqQP6hhdONi/rmuSV1d4CsOCXLObZYRrdrMqs4P8rNYXv/TFJN2r8/sAHNQrP3Dm9F6PAjCsQ9MT57hmN8sIF3azjHAz3qzKpDvoRvXND0o9qfcCAEZ0fC/J69Mu31nXFNfsZhnhwm6WEW7Gm1WZ7akp7b/Q85kkPb5Lrpe+GzvDNbtZRrhmN6tiH4bSXRbumt0sI1zYzTLChd0sI1zYzTLChd0sI5os7JJ+L2mNpGdSeb0l3S/ppfhvr9YN08xaqpia/TpgQr2884BZIYS9gVnxfTOrYk0W9hDC34C362VPAmbE6RnA5BLHZWYltrO/2QeEEFbH6TeAASWKx8xaSYs76EK0MmSDq0N6RRiz6rCzhf1NSQMB4r9rGtrRK8KYVYedLex3At+I098A7ihNOGbWWpq8EEbSn4DxQF9JK4ELgV8CN0s6HXgVOKk1gzTLkh7tuiTp/nXvNbJn8zRZ2EMIUxvYdGTJojCzVucRdGYZ4evZzarE6m0bAbhg1bFJ3kMLRyTp9n2jeePbtcuf/Dpxn8UATOsbTUa5PTXnfH2u2c0ywjW7WQXkavF/uP+sJG/A7Kg4frirkry6ofnHhI3R3HM7UqNa7rn3EABmbR4HwIsrL2vwNV2zm2WEC7tZRrgZb1YmX33l8CS97KrhAGhMvkPtgp/9EYCJ3TY3+7lv3xQt7HjOU281uI9rdrOMcGE3ywg3481a0V4Pnpakuz+WHwb7/QtuB+CMHqtK8jqTu0W9+79o5/PsZpnnmt2sFQy769sA1G3IX9b9yDn5c+Bd23Use0yu2c0ywoXdLCPcjDcrkT0e+Gb+zvZoyOvSqVel9ih/0z3NNbtZRrhmN2uh8c9EM6mHTfni9MqkqysVToOKWRFmiKQHJT0n6VlJZ8b5XhXGrIYU04zfBpwdQhgBHAz8QNIIvCqMWU0pZg661cDqOP2epCXAIKJVYcbHu80A5gDntkqUZlVm2hujkvSqRQMBePaUy1N7VLYzrpBmddBJGgqMAh6jyFVhvEiEWXUouoNOUnfgL8BZIYQNUn42jRBCkFRwVZgQwtXA1QCjD+zc4MoxZtXuxa2bkvQd9x6cpG+ZOh2Aru06lz2m5iiqZpfUgaig3xBCuDXOLnpVGDOrvGJ64wVcCywJIfw2tcmrwpjVkGKa8eOAU4CnJS2O8y7Aq8JYRmwJWwE49tazk7zvHn9fkv50x+puvucU0xs/F1ADm70qjFmN8HBZs4zwcFmzJnz7tagB23/42iRvWu9llQpnp7lmN8sI1+xmBfxl465J+uHF0bTP1XhxS3O4ZjfLCBd2s4xwM94sZWuIrt+Ydu/UJO/KY6+rUDSl5ZrdLCNcs5ulfHfFYQB02i2/3tqErlsqFU5JuWY3ywgXdrOMcDPeMm/Jh/km+5z5+wPw6Am/Se3RrcwRtQ7X7GYZ4cJulhFuxlvmTZr/3SR91D88CUD/urbRdE9zzW6WEa7ZLZP+uKFvkt76Tn6mmd8Nmhen2l49WMwcdJ0lLZD0ZLwizEVx/jBJj0laKukmSdU3UbaZJYr5+toCHBFCOBAYCUyQdDBwCTA9hLAXsB44vfXCNLOWKmYOugBsjO92iG8BOAL4apw/A/gZcGXpQzQrvQvn/GOSvmj8rUm6Tm2v+Z5T7LzxdfHMsmuA+4FlwDshhG3xLiuJloQq9FivCGNWBYrqoAshbAdGSuoJ3AYML/YF0ivCDN6/R7j07T2B2pzDy2rfhWv3A0BdtyV5/7TrukqFU1bNarOEEN4BHgTGAj0l5b4sBgOvlzg2MyuhYnrj+8U1OpK6AEcDS4gK/Ynxbl4RxqzKFdOMHwjMkFRH9OVwcwhhpqTngBslXQw8QbREVKPWrd+V399yDADfOP1SoG2OVLLqkpt9BuCGBz4PwO0nXJbaozZWdGmpYnrjnyJaprl+/svAmNYIysxKr+2eZzCzjyjrcNkO3bey27ioH2/i09ECsPNH3lLOECyDTll+dJLuuue7QO0sxlhKrtnNMqKsNfvenddz16f+DMCnb/oxAC/utynZvk8Hd9ZZ6by7430AFj6yb5I3++RL41T3CkRUWa7ZzTLChd0sI8rajG+H6NouuhL2yM9HM4JMWpCfJWTJuOvLGY61cV9bGl3s0ntEfjjs7u2z13zPcc1ulhEVm6nmikFzARg+98Akb/GWaOWNkZ06VSQmq31rtuc7fJ9/fCgAj0z5dWqP7HYCu2Y3ywgXdrOMqFgzvoPqAJh82IIk78RHvwPA0vHXVSIkawNOWvK1JD1k5CrAF1vluGY3ywgXdrOMqPi88b/abWGSvv1v0RWz8z7YkeSN6+zvI2tarhf+9cUDk7x5U3O98G7Gg2t2s8yoeM2enrp38qFRZ92p87+Z5L3kzjorwonPfR2AoZ9ZmeS5Y+6jiq7Z4+mkn5A0M77vFWHMakhzmvFnEk00meMVYcxqSFHNeEmDgS8CPwd+Ikm0woowv9ztcSDfUQfurLOGvbZtY5Je/eRuACz86m9Te3Qpc0TVrdjScxlwDpAreX3wijBmNaXJml3Sl4A1IYRFksY39wXSK8KMPrBzaGzfZFTdoflRde6ss4ac+PRpSXrfMcsB6NHOtXlDimnGjwMmSjqOaILtXYHLiVeEiWt3rwhjVuWabMaHEM4PIQwOIQwFpgCzQwhfwyvCmNWUlpxnP5dmrghTrEKj6iDfWeeOuuxal7peff2zfZP03VOvi1M+t96QZhX2EMIcYE6c9oowZjXEVaRZRlR8uGwhhYbQQr5n3r3y2XVi6nr1waNWJem+HhrbJNfsZhlRlTV7WqHOuvkf5AfnHNy5ruwxWfk1fgkruGOuaa7ZzTLChd0sI6q+GV+os+6U+fkL7NxZlw0nPx9dc5XulPP16s3jmt0sI6q+Zk/Lddbd/lB+LE+us84ddW1PenWXlU98AoBH3Sm301yzm2WEC7tZRtRUMz7XWXfEuKeTvNMWnQp4uee2KNcpBzBo5GrAI+VawjW7WUa4sJtlRE0143OuGDwnSe839wAAFo/ekuR5fffatn77ZgBW/v0TSd68r3p1l5ZyzW6WETVZs3dShyR9+CFRZ93Uhd9K8txZV9tOWXYCAH0OWJvkebRcyxU7b/xy4D1gO7AthDBaUm/gJmAosBw4KYSwvnXCNLOWak4z/vAQwsgQwuj4/nnArBDC3sCs+L6ZVamWNOMnAePj9AyiuenObWE8zZbrrMt11IE762rRuzveT9IvLBgKwINTLk3t0b28AbVBxdbsAbhP0iJJZ8R5A0IIq+P0G8CAQg/0ijBm1aHYmv2QEMLrkvoD90t6Pr0xhBAkFVztpTkrwuyMXGddrqMO3FlXiyYvmZKkc6PlBrd3bV5KRdXsIYTX479rgNuIppB+U9JAgPjvmtYK0sxarsnCLqmbpF1yaeALwDPAnUQrwYBXhDGresU04wcAt0WrNNMe+N8Qwj2SHgdulnQ68CpwUuuF2bT0qLoR8/KddYu2fAjAZzp1LHdI1oRC16tDeiJJn1svpSYLe7zyy4EF8t8CjmyNoMys9Dxc1iwjanK4bCHpIbSTD8uvIjPl0ehMoSemrD4npVZ3yfXAg4fGthbX7GYZ0WZq9jSvIlPdVm7bGP19arck75GTf5PawzV7a3DNbpYRLuxmGdEmm/HpVWROHD8fgK8/mh9Cu/TwP5Q9Jsv7x6dPA2D46FeTPHfKtT7X7GYZ0SZr9rRLBiwG4M/zPpfk3bmpKwATu22uSExZtGzrxiT99pI+ANx78ozUHl3LHFH2uGY3ywgXdrOMaPPN+JwfH35vkj7zoWilkYnHXVOpcDJn8t/PSNJjxr4AQK86N93LyTW7WUa4sJtlRGaa8Wf1Wp6kL98uAK5+N38N9Rk9VpU7pExYsGUrAJuX75rkzRiTmyrMw5bLyTW7WUZkpmZPu+TwmwE494GTk7zTJ12VpNMj8Kxlpjz8HQC+ccTfkrwOco1eCUX9V0vqKekWSc9LWiJprKTeku6X9FL8t1drB2tmO6/YKuxy4J4QwnCiKaqW4BVhzGpKk814ST2AQ4FTAUIIHwIfSqqKFWF2xknd3wXggh5bk7zz3vxMkr50tyfKHlNbct2G/kk6bI7+xS7s91ylwrFYMTX7MGAt8AdJT0i6Jp5S2ivCmNWQYjro2gMHAT8KITwm6XLqNdkruSJMS9wx7ndJeuKt/5ykf3rSIwD0aNel7DG1BRfNnpykf33UjRWMxNKKqdlXAitDCI/F928hKvxeEcashjRZ2EMIbwArJO0bZx0JPIdXhDGrKcWeZ/8RcIOkjsDLwGlEXxRVsyLMztivY76ZPnBEvmFy4gvRodz/qb+WPaZaNe2NUUm6rueHSfqE7hsqEY4VUFRhDyEsBkYX2OQVYcxqRCZH0BUy64CbkvSIm38EwII98qfmxnTq8LHHWH5a6NsezM8ENPsrv07t4WWXq4XHhZplhAu7WUa4GR9LrxU39fB50d+5+dlVlh3p6acL+fJT3wRgxOjlSd7u7d10r0au2c0ywoXdLCPcjC/g4v5PA3Bju/zZxtx5ZF8kAze+l7+aed2KngA8MvFPqT18vXo1cs1ulhGu2Rsx+/P/kaTH33k2AN8//uEkb1iHbHVEbd4RjYy74L78YMlr4um4PftM9XPNbpYRLuxmGeFmfCPS54tP+fxcAI56+EdJ3rIjsnXu/QvPTAHgoJHLkrwju3hCklrhmt0sI1yzF+mifs8CcIPGJHlTXjkCgBuHza5ITMXIdarV17Vdx6Ie/9M1ByTpVS/2A+ChE25J7eH6olb4kzLLCBd2s4xwM76Z5qTOvR/xP9MAuL3/giRvcreNZY8p59p3d0vSFz84EYA9bsl3oI28ND/67zcD/97g8zz74ftJ+qZ7DknSN578/wCok6/tr0VN1uyS9pW0OHXbIOksrwhjVluKmXDyhRDCyBDCSOAzwGbgNrwijFlNaW4z/khgWQjh1VpeEaYlBqfOvf/qK9HSw+df/09J3gGn/ypJ71ni4bTLtuZ/Ipy4+FtJuuMtUaOqz8znk7x91ud/WuTcs3y/JF2oGb9xxwcAfPnGnyR5XzlmXpL21Fy1rbkddFOA3OVNXhHGrIYUXbPH00hPBM6vv61WV4RpqVxn3H3H52vJ466flqQXnTodgO7tOpfk9X6xekKS7j/p+Y9t/8hXabvowpT2A/olWdue3zW/fezHn//Tt58JwCdGvpl/zQFP7VywVnWaU7MfC/w9hJD7T/CKMGY1pDmFfSr5Jjx4RRizmlJUMz5etfVo4Dup7F9S4yvClMrvBs1P0uPH5M91H3R9tFjk4lMuT/KKHaZayHG9803qa3cdmd/QMeo42/HOu0nW1sMOBODlL+Rfr9APrWF35ifVrOu9BYC5n751p2O06lXsijCbgD718t7CK8KY1QyPoCuxOfvfnqRHvR9dEvrZ352V5M38TnRqbmdmuflc51VJ+j8OOTlJrzok+hj7PpWvujcNiH6hbe+8I8n75IjVSXqvG74XJXpuS/KWjr+u2TFZ7fDYeLOMcGE3ywg341vRE5+9EYDxXSYneSf8e3Qe/tBvP57kXTZwYVHPN6Auv8T0yiPzEzwqPsG+ZuIHSd6UEYsA+PNd+QtZ3p8xMEl3+nK0lPKzY28o6rWt9rlmN8sIF3azjFAI5RvBOvrAzmHBvUPK9nrV6MK10cUoM393aJK3YVh++7RJ0dikM3qsojGLtuSnm/rK3dEkmF12y18os/mtrgD0m5f/pTbqB4uT9H8NfrS5oVsNGHPMChY++YEKbXPNbpYRrtkrJD0R5MiHv52ke90d1cjbO+X33TQo+qLePnxTkrdjZdckvdv86Fx6qMt/oa86Muq1e+jY6Umel1Ju+1yzm5kLu1lW+Dx7haQviHnxsBlJesuhWwH4t7UHJXl3vRp16m18Pj/NX7vdNyfp0RdEc9r/tP9DSV7fum5xyk13i7hmN8sI1+xVplM8TfPF/Z9O8pL0Z5t6dLemdrAMc81ulhEu7GYZ4cJulhFFFXZJ/yzpWUnPSPqTpM6Shkl6TNJSSTfFs8+aWZUqZvmnQcCPgdEhhP2BOqL54y8BpocQ9gLWA6e3ZqBm1jLFNuPbA10ktQe6AquBI4DcQt0zgMkNPNbMqkAxa729DvwaeI2okL8LLALeCSHkJjBbCQwq9HivCGNWHYppxvcCJgHDgE8Qncyd0OiDUkIIV4cQRocQRvfrU9f0A8ysVRTTjD8KeCWEsDaEsBW4FRgH9Iyb9QCDgddbKUYzK4FiCvtrwMGSukoS0VzxzwEPAifG+3hFGLMqV8xv9seIOuL+DjwdP+ZqouWZfyJpKdECEte2Ypxm1kLFrghzIXBhveyXgTElj8jMWoVH0JllhAu7WUa4sJtlRFknnJS0FtgErCvbi7a+vvh4qlVbOhYo7ng+GULoV2hDWQs7gKSFIYTRZX3RVuTjqV5t6Vig5cfjZrxZRriwm2VEJQr71RV4zdbk46lebelYoIXHU/bf7GZWGW7Gm2WEC7tZRpS1sEuaIOmFeN6688r52i0laYikByU9F8/Hd2ac31vS/ZJeiv/2auq5qomkOklPSJoZ36/ZuQUl9ZR0i6TnJS2RNLaWP59Sz/1YtsIuqQ74T+BYYAQwVdKIcr1+CWwDzg4hjAAOBn4Qx38eMCuEsDcwK75fS84ElqTu1/LcgpcD94QQhgMHEh1XTX4+rTL3YwihLDdgLHBv6v75wPnlev1WOJ47gKOBF4CBcd5A4IVKx9aMYxhMVACOAGYCIhqh1b7QZ1bNN6AH8Apxp3MqvyY/H6Jp3lYAvYmuTp0JHNOSz6eczfhc8DkNzltX7SQNBUYBjwEDQgir401vAAMqFNbOuAw4B9gR3+9DkXMLVqFhwFrgD/HPkmskdaNGP5/QwrkfC3EHXTNJ6g78BTgrhLAhvS1EX7c1cS5T0peANSGERZWOpUTaAwcBV4YQRhFdg/GRJnuNfT4tmvuxkHIW9teBIan7NTdvnaQORAX9hhDCrXH2m5IGxtsHAmsqFV8zjQMmSloO3EjUlL+c2p1bcCWwMkQzK0E0u9JB1O7nU/K5H8tZ2B8H9o57EzsSdTbcWcbXb5F4/r1rgSUhhN+mNt1JNAcf1NBcfCGE80MIg0MIQ4k+i9khhK9Ro3MLhhDeAFZI2jfOys2VWJOfD60x92OZOx2OA14ElgH/UulOkGbGfghRE/ApYHF8O47od+4s4CXgAaB3pWPdiWMbD8yM03sAC4ClwJ+BTpWOrxnHMRJYGH9GtwO9avnzAS4CngeeAa4HOrXk8/FwWbOMcAedWUa4sJtlhAu7WUa4sJtlhAu7WUa4sJtlhAu7WUb8f3i14x+MqAUOAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "supLL4d2Yqom"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9YdHcCdZR1Y",
        "outputId": "beb3642e-9bc7-4767-8714-17405ef2fb92"
      },
      "source": [
        "# Get number of actions from gym action space\n",
        "n_actions = env.action_space.n\n",
        "\n",
        "policy_net = DQN(n_actions).to(device)\n",
        "target_net = DQN(n_actions).to(device)\n",
        "target_net.load_state_dict(policy_net.state_dict())\n",
        "target_net.eval()\n",
        "\n",
        "optimizer = optim.RMSprop(policy_net.parameters())\n",
        "memory = ReplayMemory(REPLAY_MEMORY_SIZE)\n",
        "\n",
        "steps_done = 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "linear_input_size: 1568\n",
            "linear_input_size: 1568\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bBUpKX0Eaz5F"
      },
      "source": [
        "def decay_epsilon(step):\n",
        "    # linearly decay epsilon\n",
        "    frac = min(float(step) / MAX_EPS_DECAY_STEPS, 1.0)\n",
        "    return EPS_START + frac*(EPS_END - EPS_START)\n",
        "\n",
        "def get_q_values(state):\n",
        "    return policy_net(state)\n",
        "\n",
        "def select_action(q_values):\n",
        "    global steps_done\n",
        "    sample = random.random()\n",
        "    eps_threshold = decay_epsilon(steps_done)\n",
        "    steps_done += 1\n",
        "    if sample > eps_threshold:\n",
        "        # t.max(1) will return largest column value of each row.\n",
        "        # second column on max result is index of where max element was\n",
        "        # found, so we pick action with the larger expected reward.\n",
        "        return q_values.max(1)[1].view(1, 1)\n",
        "    else:\n",
        "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "egpoL3jzbBbG"
      },
      "source": [
        "def optimize_model():\n",
        "    if len(memory) < BATCH_SIZE:\n",
        "        return\n",
        "    transitions = memory.sample(BATCH_SIZE)\n",
        "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
        "    # detailed explanation). This converts batch-array of Transitions\n",
        "    # to Transition of batch-arrays.\n",
        "    batch = Transition(*zip(*transitions))\n",
        "\n",
        "    # Compute a mask of non-final states and concatenate the batch elements\n",
        "    # (a final state would've been the one after which simulation ended)\n",
        "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
        "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
        "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
        "                                                if s is not None])\n",
        "    state_batch = torch.cat(batch.state)\n",
        "    action_batch = torch.cat(batch.action)\n",
        "    reward_batch = torch.cat(batch.reward)\n",
        "\n",
        "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
        "    # columns of actions taken. These are the actions which would've been taken\n",
        "    # for each batch state according to policy_net\n",
        "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
        "\n",
        "    # Compute V(s_{t+1}) for all next states.\n",
        "    # Expected values of actions for non_final_next_states are computed based\n",
        "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
        "    # This is merged based on the mask, such that we'll have either the expected\n",
        "    # state value or 0 in case the state was final.\n",
        "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
        "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
        "    # Compute the expected Q values\n",
        "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
        "\n",
        "    # Compute Huber loss\n",
        "    loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
        "\n",
        "    # Optimize the model\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    for param in policy_net.parameters():\n",
        "        param.grad.data.clamp_(-1, 1)\n",
        "    optimizer.step()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FSxdmob7bM6Z"
      },
      "source": [
        "episode_durations = []\n",
        "all_episode_max_q_vals = []\n",
        "all_episode_training_time = []\n",
        "\n",
        "def train(num_episode, environment):\n",
        "    for i_episode in range(num_episode):\n",
        "        # Initialize the environment and state\n",
        "        environment.reset()\n",
        "        # Stack 4 most recent frames\n",
        "        past_screen3 = get_screen(environment)\n",
        "        past_screen2 = get_screen(environment)\n",
        "        past_screen1 = get_screen(environment)\n",
        "        current_screen = get_screen(environment)\n",
        "        state = stack_past_four_frames(current_screen, past_screen1, past_screen2, past_screen3)\n",
        "\n",
        "        max_q_vals = []\n",
        "        last_action = None\n",
        "        start = time.time()\n",
        "        for t in count():\n",
        "            print(\"episode {}, iteration {}\".format(i_episode, t))\n",
        "            \n",
        "            # Select and perform an action on every kth frame\n",
        "            if t % k == 0:\n",
        "                # Compute Q values from policy net\n",
        "                q_values = get_q_values(state)\n",
        "                print(\"q values: \", q_values)\n",
        "                max_q_vals.append(q_values.max().item())\n",
        "\n",
        "                # Choose action based on max q value\n",
        "                action = select_action(q_values)\n",
        "                last_action = action\n",
        "            else:\n",
        "                action = last_action\n",
        "            print(\"Action: \", action.item())\n",
        "\n",
        "            # Execute action\n",
        "            new_ob, reward, done, info = environment.step(action.item())\n",
        "\n",
        "            # re-evaluate reward\n",
        "            if new_ob[0] > 0.1:\n",
        "              reward = 1\n",
        "            elif new_ob[0] > 0.25:\n",
        "              reward = 2\n",
        "            reward = torch.tensor([reward], device=device)\n",
        "\n",
        "            # Observe new state\n",
        "            past_screen3 = past_screen2\n",
        "            past_screen2 = past_screen1\n",
        "            past_screen1 = current_screen\n",
        "            current_screen = get_screen(environment)\n",
        "            print(\"Current state after Action: \", new_ob)\n",
        "            \n",
        "            if not done:\n",
        "                next_state = stack_past_four_frames(current_screen, past_screen1, past_screen2, past_screen3)\n",
        "            else:\n",
        "                next_state = None\n",
        "\n",
        "            # Store the transition in memory\n",
        "            memory.push(state, action, next_state, reward)\n",
        "\n",
        "            # Move to the next state\n",
        "            state = next_state\n",
        "\n",
        "            # Perform one step of the optimization (on the target network)\n",
        "            optimize_model()\n",
        "            if done:\n",
        "                end = time.time()\n",
        "                all_episode_training_time.append(end - start)\n",
        "                episode_durations.append(t + 1)\n",
        "                all_episode_max_q_vals.append(max_q_vals)\n",
        "                break\n",
        "        # Update the target network, copying all weights and biases in DQN\n",
        "        if i_episode % TARGET_UPDATE == 0:\n",
        "            target_net.load_state_dict(policy_net.state_dict())\n",
        "\n",
        "    print('Training Complete')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSslOSxMyWTP",
        "outputId": "97c82553-e2ca-46d3-a5c1-d33d2111e59c"
      },
      "source": [
        "train(NUM_EPISODE, env)\n",
        "env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "episode 148, iteration 469\n",
            "Action:  2\n",
            "Current state after Action:  [-0.47451829 -0.02894281]\n",
            "episode 148, iteration 470\n",
            "Action:  2\n",
            "Current state after Action:  [-0.50282788 -0.02830959]\n",
            "episode 148, iteration 471\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53029315 -0.02746527]\n",
            "episode 148, iteration 472\n",
            "q values:  tensor([[4.9860, 4.9692, 4.9642]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55870821 -0.02841506]\n",
            "episode 148, iteration 473\n",
            "Action:  0\n",
            "Current state after Action:  [-0.58786044 -0.02915223]\n",
            "episode 148, iteration 474\n",
            "Action:  0\n",
            "Current state after Action:  [-0.61753369 -0.02967325]\n",
            "episode 148, iteration 475\n",
            "Action:  0\n",
            "Current state after Action:  [-0.64751171 -0.02997802]\n",
            "episode 148, iteration 476\n",
            "q values:  tensor([[5.0113, 4.9842, 5.0598]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.67558164 -0.02806993]\n",
            "episode 148, iteration 477\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70155079 -0.02596915]\n",
            "episode 148, iteration 478\n",
            "Action:  2\n",
            "Current state after Action:  [-0.72524779 -0.02369701]\n",
            "episode 148, iteration 479\n",
            "Action:  2\n",
            "Current state after Action:  [-0.746523   -0.02127521]\n",
            "episode 148, iteration 480\n",
            "q values:  tensor([[5.0268, 4.9954, 5.0253]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.76624815 -0.01972515]\n",
            "episode 148, iteration 481\n",
            "Action:  1\n",
            "Current state after Action:  [-0.78430995 -0.0180618 ]\n",
            "episode 148, iteration 482\n",
            "Action:  1\n",
            "Current state after Action:  [-0.80060977 -0.01629982]\n",
            "episode 148, iteration 483\n",
            "Action:  1\n",
            "Current state after Action:  [-0.81506301 -0.01445325]\n",
            "episode 148, iteration 484\n",
            "q values:  tensor([[5.0121, 4.9973, 4.9597]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.82859837 -0.01353536]\n",
            "episode 148, iteration 485\n",
            "Action:  0\n",
            "Current state after Action:  [-0.84115233 -0.01255396]\n",
            "episode 148, iteration 486\n",
            "Action:  0\n",
            "Current state after Action:  [-0.85266888 -0.01151655]\n",
            "episode 148, iteration 487\n",
            "Action:  0\n",
            "Current state after Action:  [-0.86309921 -0.01043032]\n",
            "episode 148, iteration 488\n",
            "q values:  tensor([[4.9211, 4.9325, 4.8831]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.87140123 -0.00830202]\n",
            "episode 148, iteration 489\n",
            "Action:  1\n",
            "Current state after Action:  [-0.87754293 -0.00614171]\n",
            "episode 148, iteration 490\n",
            "Action:  1\n",
            "Current state after Action:  [-0.88150152 -0.00395858]\n",
            "episode 148, iteration 491\n",
            "Action:  1\n",
            "Current state after Action:  [-0.88326266 -0.00176115]\n",
            "episode 148, iteration 492\n",
            "q values:  tensor([[4.9492, 4.9074, 4.9204]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-8.82820104e-01  4.42559422e-04]\n",
            "episode 148, iteration 493\n",
            "Action:  1\n",
            "Current state after Action:  [-0.88017541  0.0026447 ]\n",
            "episode 148, iteration 494\n",
            "Action:  1\n",
            "Current state after Action:  [-0.87533804  0.00483737]\n",
            "episode 148, iteration 495\n",
            "Action:  1\n",
            "Current state after Action:  [-0.86832565  0.00701239]\n",
            "episode 148, iteration 496\n",
            "q values:  tensor([[4.9372, 4.9238, 4.9708]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.85816464  0.010161  ]\n",
            "episode 148, iteration 497\n",
            "Action:  2\n",
            "Current state after Action:  [-0.84489499  0.01326966]\n",
            "episode 148, iteration 498\n",
            "Action:  2\n",
            "Current state after Action:  [-0.82857179  0.0163232 ]\n",
            "episode 148, iteration 499\n",
            "Action:  2\n",
            "Current state after Action:  [-0.80926731  0.01930448]\n",
            "episode 148, iteration 500\n",
            "q values:  tensor([[4.9208, 4.7382, 4.9405]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.78707311  0.02219419]\n",
            "episode 148, iteration 501\n",
            "Action:  2\n",
            "Current state after Action:  [-0.76210229  0.02497082]\n",
            "episode 148, iteration 502\n",
            "Action:  2\n",
            "Current state after Action:  [-0.73449146  0.02761083]\n",
            "episode 148, iteration 503\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70440237  0.0300891 ]\n",
            "episode 148, iteration 504\n",
            "q values:  tensor([[4.9361, 5.0366, 4.9530]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.67302277  0.0313796 ]\n",
            "episode 148, iteration 505\n",
            "Action:  1\n",
            "Current state after Action:  [-0.64055965  0.03246312]\n",
            "episode 148, iteration 506\n",
            "Action:  1\n",
            "Current state after Action:  [-0.60723721  0.03332244]\n",
            "episode 148, iteration 507\n",
            "Action:  1\n",
            "Current state after Action:  [-0.57329404  0.03394317]\n",
            "episode 148, iteration 508\n",
            "q values:  tensor([[4.9765, 4.9660, 4.9558]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53797954  0.0353145 ]\n",
            "episode 148, iteration 509\n",
            "Action:  2\n",
            "Current state after Action:  [-0.50155721  0.03642232]\n",
            "episode 148, iteration 510\n",
            "Action:  2\n",
            "Current state after Action:  [-0.46430008  0.03725713]\n",
            "episode 148, iteration 511\n",
            "Action:  2\n",
            "Current state after Action:  [-0.42648535  0.03781473]\n",
            "episode 148, iteration 512\n",
            "q values:  tensor([[4.9550, 4.9214, 4.9404]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.3893887   0.03709664]\n",
            "episode 148, iteration 513\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35327166  0.03611705]\n",
            "episode 148, iteration 514\n",
            "Action:  1\n",
            "Current state after Action:  [-0.31837719  0.03489446]\n",
            "episode 148, iteration 515\n",
            "Action:  1\n",
            "Current state after Action:  [-0.28492649  0.03345071]\n",
            "episode 148, iteration 516\n",
            "q values:  tensor([[4.9206, 4.9151, 4.9502]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.25311674  0.03180975]\n",
            "episode 148, iteration 517\n",
            "Action:  1\n",
            "Current state after Action:  [-0.2231202   0.02999654]\n",
            "episode 148, iteration 518\n",
            "Action:  1\n",
            "Current state after Action:  [-0.19508421  0.02803599]\n",
            "episode 148, iteration 519\n",
            "Action:  1\n",
            "Current state after Action:  [-0.16913215  0.02595206]\n",
            "episode 148, iteration 520\n",
            "q values:  tensor([[4.8843, 4.9694, 4.9464]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.14536513  0.02376703]\n",
            "episode 148, iteration 521\n",
            "Action:  1\n",
            "Current state after Action:  [-0.12386412  0.02150101]\n",
            "episode 148, iteration 522\n",
            "Action:  1\n",
            "Current state after Action:  [-0.10469249  0.01917163]\n",
            "episode 148, iteration 523\n",
            "Action:  1\n",
            "Current state after Action:  [-0.08789856  0.01679393]\n",
            "episode 148, iteration 524\n",
            "q values:  tensor([[4.9802, 5.0217, 4.9775]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.07251821  0.01538034]\n",
            "episode 148, iteration 525\n",
            "Action:  2\n",
            "Current state after Action:  [-0.05857894  0.01393927]\n",
            "episode 148, iteration 526\n",
            "Action:  2\n",
            "Current state after Action:  [-0.04610116  0.01247778]\n",
            "episode 148, iteration 527\n",
            "Action:  2\n",
            "Current state after Action:  [-0.03509951  0.01100165]\n",
            "episode 148, iteration 528\n",
            "q values:  tensor([[4.9077, 4.9203, 4.8809]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.02658401  0.0085155 ]\n",
            "episode 148, iteration 529\n",
            "Action:  1\n",
            "Current state after Action:  [-0.02056057  0.00602344]\n",
            "episode 148, iteration 530\n",
            "Action:  1\n",
            "Current state after Action:  [-0.01703237  0.0035282 ]\n",
            "episode 148, iteration 531\n",
            "Action:  1\n",
            "Current state after Action:  [-0.01600091  0.00103146]\n",
            "episode 148, iteration 532\n",
            "q values:  tensor([[5.0142, 5.0124, 5.0195]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.01746657 -0.00146566]\n",
            "episode 148, iteration 533\n",
            "Action:  1\n",
            "Current state after Action:  [-0.02142879 -0.00396223]\n",
            "episode 148, iteration 534\n",
            "Action:  1\n",
            "Current state after Action:  [-0.02788586 -0.00645706]\n",
            "episode 148, iteration 535\n",
            "Action:  1\n",
            "Current state after Action:  [-0.03683418 -0.00894832]\n",
            "episode 148, iteration 536\n",
            "q values:  tensor([[4.9033, 4.6986, 4.9086]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.04826725 -0.01143307]\n",
            "episode 148, iteration 537\n",
            "Action:  1\n",
            "Current state after Action:  [-0.06217416 -0.01390691]\n",
            "episode 148, iteration 538\n",
            "Action:  1\n",
            "Current state after Action:  [-0.07853771 -0.01636355]\n",
            "episode 148, iteration 539\n",
            "Action:  1\n",
            "Current state after Action:  [-0.09733218 -0.01879447]\n",
            "episode 148, iteration 540\n",
            "q values:  tensor([[4.9129, 4.8614, 4.9295]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.11752083 -0.02018865]\n",
            "episode 148, iteration 541\n",
            "Action:  2\n",
            "Current state after Action:  [-0.13905571 -0.02153488]\n",
            "episode 148, iteration 542\n",
            "Action:  2\n",
            "Current state after Action:  [-0.16187619 -0.02282048]\n",
            "episode 148, iteration 543\n",
            "Action:  2\n",
            "Current state after Action:  [-0.18590763 -0.02403144]\n",
            "episode 148, iteration 544\n",
            "q values:  tensor([[4.9969, 5.0137, 5.0078]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.21106022 -0.02515259]\n",
            "episode 148, iteration 545\n",
            "Action:  2\n",
            "Current state after Action:  [-0.23722819 -0.02616797]\n",
            "episode 148, iteration 546\n",
            "Action:  2\n",
            "Current state after Action:  [-0.26428931 -0.02706112]\n",
            "episode 148, iteration 547\n",
            "Action:  2\n",
            "Current state after Action:  [-0.29210494 -0.02781564]\n",
            "episode 148, iteration 548\n",
            "q values:  tensor([[5.0117, 5.0301, 5.0960]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.32152055 -0.0294156 ]\n",
            "episode 148, iteration 549\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35236059 -0.03084005]\n",
            "episode 148, iteration 550\n",
            "Action:  1\n",
            "Current state after Action:  [-0.38442918 -0.03206859]\n",
            "episode 148, iteration 551\n",
            "Action:  1\n",
            "Current state after Action:  [-0.41751147 -0.0330823 ]\n",
            "episode 148, iteration 552\n",
            "q values:  tensor([[4.9483, 4.8936, 4.8424]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.45237606 -0.03486459]\n",
            "episode 148, iteration 553\n",
            "Action:  0\n",
            "Current state after Action:  [-0.48877076 -0.0363947 ]\n",
            "episode 148, iteration 554\n",
            "Action:  0\n",
            "Current state after Action:  [-0.5264262  -0.03765544]\n",
            "episode 148, iteration 555\n",
            "Action:  0\n",
            "Current state after Action:  [-0.56506043 -0.03863423]\n",
            "episode 148, iteration 556\n",
            "q values:  tensor([[4.9769, 5.0538, 4.9353]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6033845  -0.03832407]\n",
            "episode 148, iteration 557\n",
            "Action:  1\n",
            "Current state after Action:  [-0.64111588 -0.03773138]\n",
            "episode 148, iteration 558\n",
            "Action:  1\n",
            "Current state after Action:  [-0.67798402 -0.03686814]\n",
            "episode 148, iteration 559\n",
            "Action:  1\n",
            "Current state after Action:  [-0.71373523 -0.03575121]\n",
            "episode 148, iteration 560\n",
            "q values:  tensor([[2.5388, 2.3821, 2.2374]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.74813649 -0.03440127]\n",
            "episode 148, iteration 561\n",
            "Action:  1\n",
            "Current state after Action:  [-0.78097822 -0.03284173]\n",
            "episode 148, iteration 562\n",
            "Action:  1\n",
            "Current state after Action:  [-0.81207578 -0.03109756]\n",
            "episode 148, iteration 563\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84126991 -0.02919412]\n",
            "episode 148, iteration 564\n",
            "q values:  tensor([[4.9802, 4.9371, 4.9483]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.86942612 -0.02815621]\n",
            "episode 148, iteration 565\n",
            "Action:  0\n",
            "Current state after Action:  [-0.89642951 -0.02700339]\n",
            "episode 148, iteration 566\n",
            "Action:  0\n",
            "Current state after Action:  [-0.9221843  -0.02575479]\n",
            "episode 148, iteration 567\n",
            "Action:  0\n",
            "Current state after Action:  [-0.94661285 -0.02442855]\n",
            "episode 148, iteration 568\n",
            "q values:  tensor([[5.0695, 5.0607, 5.2175]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.96865437 -0.02204151]\n",
            "episode 148, iteration 569\n",
            "Action:  1\n",
            "Current state after Action:  [-0.98826496 -0.01961059]\n",
            "episode 148, iteration 570\n",
            "Action:  1\n",
            "Current state after Action:  [-1.00541452 -0.01714956]\n",
            "episode 148, iteration 571\n",
            "Action:  1\n",
            "Current state after Action:  [-1.0200837  -0.01466918]\n",
            "episode 148, iteration 572\n",
            "q values:  tensor([[4.9272, 4.8911, 4.9389]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.03226115 -0.01217745]\n",
            "episode 148, iteration 573\n",
            "Action:  1\n",
            "Current state after Action:  [-1.0419411  -0.00967995]\n",
            "episode 148, iteration 574\n",
            "Action:  1\n",
            "Current state after Action:  [-1.04912137 -0.00718027]\n",
            "episode 148, iteration 575\n",
            "Action:  1\n",
            "Current state after Action:  [-1.05380168 -0.00468031]\n",
            "episode 148, iteration 576\n",
            "q values:  tensor([[4.8133, 4.9710, 5.0086]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.05498247 -0.0011808 ]\n",
            "episode 148, iteration 577\n",
            "Action:  2\n",
            "Current state after Action:  [-1.05266395  0.00231852]\n",
            "episode 148, iteration 578\n",
            "Action:  2\n",
            "Current state after Action:  [-1.04684577  0.00581818]\n",
            "episode 148, iteration 579\n",
            "Action:  2\n",
            "Current state after Action:  [-1.03752759  0.00931818]\n",
            "episode 148, iteration 580\n",
            "q values:  tensor([[4.9418, 4.9776, 4.9460]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.02571045  0.01181713]\n",
            "episode 148, iteration 581\n",
            "Action:  1\n",
            "Current state after Action:  [-1.01139852  0.01431194]\n",
            "episode 148, iteration 582\n",
            "Action:  1\n",
            "Current state after Action:  [-0.99460098  0.01679753]\n",
            "episode 148, iteration 583\n",
            "Action:  1\n",
            "Current state after Action:  [-0.9753345   0.01926648]\n",
            "episode 148, iteration 584\n",
            "q values:  tensor([[4.9173, 4.9868, 4.9929]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.9526259  0.0227086]\n",
            "episode 148, iteration 585\n",
            "Action:  2\n",
            "Current state after Action:  [-0.92651724  0.02610866]\n",
            "episode 148, iteration 586\n",
            "Action:  2\n",
            "Current state after Action:  [-0.89707064  0.0294466 ]\n",
            "episode 148, iteration 587\n",
            "Action:  2\n",
            "Current state after Action:  [-0.86437334  0.0326973 ]\n",
            "episode 148, iteration 588\n",
            "q values:  tensor([[4.8747, 4.8975, 4.9154]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.82854273  0.03583061]\n",
            "episode 148, iteration 589\n",
            "Action:  2\n",
            "Current state after Action:  [-0.78973097  0.03881176]\n",
            "episode 148, iteration 590\n",
            "Action:  2\n",
            "Current state after Action:  [-0.74812862  0.04160235]\n",
            "episode 148, iteration 591\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70396678  0.04416184]\n",
            "episode 148, iteration 592\n",
            "q values:  tensor([[4.9819, 4.9938, 4.9794]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.65951723  0.04444955]\n",
            "episode 148, iteration 593\n",
            "Action:  0\n",
            "Current state after Action:  [-0.61507631  0.04444092]\n",
            "episode 148, iteration 594\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57095789  0.04411842]\n",
            "episode 148, iteration 595\n",
            "Action:  0\n",
            "Current state after Action:  [-0.52748546  0.04347242]\n",
            "episode 148, iteration 596\n",
            "q values:  tensor([[4.9894, 4.9979, 4.9788]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.48398389  0.04350157]\n",
            "episode 148, iteration 597\n",
            "Action:  1\n",
            "Current state after Action:  [-0.44077873  0.04320516]\n",
            "episode 148, iteration 598\n",
            "Action:  1\n",
            "Current state after Action:  [-0.39818835  0.04259038]\n",
            "episode 148, iteration 599\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35651651  0.04167184]\n",
            "episode 148, iteration 600\n",
            "q values:  tensor([[4.9900, 5.0055, 5.0018]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.31504597  0.04147054]\n",
            "episode 148, iteration 601\n",
            "Action:  2\n",
            "Current state after Action:  [-0.27403951  0.04100646]\n",
            "episode 148, iteration 602\n",
            "Action:  2\n",
            "Current state after Action:  [-0.23373473  0.04030478]\n",
            "episode 148, iteration 603\n",
            "Action:  2\n",
            "Current state after Action:  [-0.19434011  0.03939462]\n",
            "episode 148, iteration 604\n",
            "q values:  tensor([[4.8429, 4.9092, 4.9501]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.1560325   0.03830761]\n",
            "episode 148, iteration 605\n",
            "Action:  2\n",
            "Current state after Action:  [-0.11895596  0.03707654]\n",
            "episode 148, iteration 606\n",
            "Action:  2\n",
            "Current state after Action:  [-0.08322191  0.03573405]\n",
            "episode 148, iteration 607\n",
            "Action:  2\n",
            "Current state after Action:  [-0.04891035  0.03431156]\n",
            "episode 148, iteration 608\n",
            "q values:  tensor([[5.0555, 5.0697, 5.0507]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.01807192  0.03083843]\n",
            "episode 148, iteration 609\n",
            "Action:  0\n",
            "Current state after Action:  [0.00927018 0.0273421 ]\n",
            "episode 148, iteration 610\n",
            "Action:  0\n",
            "Current state after Action:  [0.03311324 0.02384307]\n",
            "episode 148, iteration 611\n",
            "Action:  0\n",
            "Current state after Action:  [0.05346864 0.02035539]\n",
            "episode 148, iteration 612\n",
            "q values:  tensor([[6.7698, 6.8430, 6.8176]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.07135612 0.01788749]\n",
            "episode 148, iteration 613\n",
            "Action:  1\n",
            "Current state after Action:  [0.08680067 0.01544455]\n",
            "episode 148, iteration 614\n",
            "Action:  1\n",
            "Current state after Action:  [0.0998295  0.01302883]\n",
            "episode 148, iteration 615\n",
            "Action:  1\n",
            "Current state after Action:  [0.11046962 0.01064011]\n",
            "episode 148, iteration 616\n",
            "q values:  tensor([[9.1590, 9.0008, 9.3157]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.11774577 0.00727615]\n",
            "episode 148, iteration 617\n",
            "Action:  0\n",
            "Current state after Action:  [0.12167628 0.00393051]\n",
            "episode 148, iteration 618\n",
            "Action:  0\n",
            "Current state after Action:  [0.1222715  0.00059522]\n",
            "episode 148, iteration 619\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.11953304 -0.00273846]\n",
            "episode 148, iteration 620\n",
            "q values:  tensor([[8.5960, 8.6833, 9.0901]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [ 0.1154536  -0.00407944]\n",
            "episode 148, iteration 621\n",
            "Action:  2\n",
            "Current state after Action:  [ 0.11002263 -0.00543097]\n",
            "episode 148, iteration 622\n",
            "Action:  2\n",
            "Current state after Action:  [ 0.1032266  -0.00679602]\n",
            "episode 148, iteration 623\n",
            "Action:  2\n",
            "Current state after Action:  [ 0.0950495 -0.0081771]\n",
            "episode 148, iteration 624\n",
            "q values:  tensor([[4.9880, 4.9784, 4.9409]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.08347335 -0.01157615]\n",
            "episode 148, iteration 625\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.06847518 -0.01499817]\n",
            "episode 148, iteration 626\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.05002957 -0.01844561]\n",
            "episode 148, iteration 627\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.02811207 -0.0219175 ]\n",
            "episode 148, iteration 628\n",
            "q values:  tensor([[4.9449, 4.9467, 4.9290]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.00270345 -0.02540862]\n",
            "episode 148, iteration 629\n",
            "Action:  0\n",
            "Current state after Action:  [-0.02620508 -0.02890853]\n",
            "episode 148, iteration 630\n",
            "Action:  0\n",
            "Current state after Action:  [-0.05860589 -0.03240081]\n",
            "episode 148, iteration 631\n",
            "Action:  0\n",
            "Current state after Action:  [-0.09446817 -0.03586227]\n",
            "episode 148, iteration 632\n",
            "q values:  tensor([[4.9943, 4.9628, 4.9393]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.13173071 -0.03726255]\n",
            "episode 148, iteration 633\n",
            "Action:  2\n",
            "Current state after Action:  [-0.17030056 -0.03856985]\n",
            "episode 148, iteration 634\n",
            "Action:  2\n",
            "Current state after Action:  [-0.21005117 -0.03975061]\n",
            "episode 148, iteration 635\n",
            "Action:  2\n",
            "Current state after Action:  [-0.25082163 -0.04077045]\n",
            "episode 148, iteration 636\n",
            "q values:  tensor([[5.0422, 5.0906, 4.9717]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.2924171  -0.04159547]\n",
            "episode 148, iteration 637\n",
            "Action:  2\n",
            "Current state after Action:  [-0.33461074 -0.04219364]\n",
            "episode 148, iteration 638\n",
            "Action:  2\n",
            "Current state after Action:  [-0.37714706 -0.04253632]\n",
            "episode 148, iteration 639\n",
            "Action:  2\n",
            "Current state after Action:  [-0.41974677 -0.04259971]\n",
            "episode 148, iteration 640\n",
            "q values:  tensor([[4.9518, 4.9059, 4.9461]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.46411284 -0.04436606]\n",
            "episode 148, iteration 641\n",
            "Action:  0\n",
            "Current state after Action:  [-0.50992268 -0.04580984]\n",
            "episode 148, iteration 642\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55683506 -0.04691239]\n",
            "episode 148, iteration 643\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60449859 -0.04766353]\n",
            "episode 148, iteration 644\n",
            "q values:  tensor([[4.9716, 5.0474, 4.9261]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.65256131 -0.04806272]\n",
            "episode 148, iteration 645\n",
            "Action:  0\n",
            "Current state after Action:  [-0.70068075 -0.04811945]\n",
            "episode 148, iteration 646\n",
            "Action:  0\n",
            "Current state after Action:  [-0.74853368 -0.04785293]\n",
            "episode 148, iteration 647\n",
            "Action:  0\n",
            "Current state after Action:  [-0.79582474 -0.04729106]\n",
            "episode 148, iteration 648\n",
            "q values:  tensor([[4.9829, 4.9948, 4.9958]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.84029362 -0.04446888]\n",
            "episode 148, iteration 649\n",
            "Action:  2\n",
            "Current state after Action:  [-0.88172883 -0.04143521]\n",
            "episode 148, iteration 650\n",
            "Action:  2\n",
            "Current state after Action:  [-0.9199658  -0.03823696]\n",
            "episode 148, iteration 651\n",
            "Action:  2\n",
            "Current state after Action:  [-0.95488268 -0.03491688]\n",
            "episode 148, iteration 652\n",
            "q values:  tensor([[4.9852, 4.9090, 4.9755]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.98739482 -0.03251214]\n",
            "episode 148, iteration 653\n",
            "Action:  1\n",
            "Current state after Action:  [-1.01744708 -0.03005227]\n",
            "episode 148, iteration 654\n",
            "Action:  1\n",
            "Current state after Action:  [-1.0450093  -0.02756222]\n",
            "episode 148, iteration 655\n",
            "Action:  1\n",
            "Current state after Action:  [-1.07007157 -0.02506227]\n",
            "episode 148, iteration 656\n",
            "q values:  tensor([[4.7988, 4.8376, 4.7299]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.09363973 -0.02356815]\n",
            "episode 148, iteration 657\n",
            "Action:  0\n",
            "Current state after Action:  [-1.11573211 -0.02209238]\n",
            "episode 148, iteration 658\n",
            "Action:  0\n",
            "Current state after Action:  [-1.13637714 -0.02064504]\n",
            "episode 148, iteration 659\n",
            "Action:  0\n",
            "Current state after Action:  [-1.15561112 -0.01923397]\n",
            "episode 148, iteration 660\n",
            "q values:  tensor([[4.1277, 4.1191, 3.9567]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.17147616 -0.01586504]\n",
            "episode 148, iteration 661\n",
            "Action:  2\n",
            "Current state after Action:  [-1.18401295 -0.01253679]\n",
            "episode 148, iteration 662\n",
            "Action:  2\n",
            "Current state after Action:  [-1.19325739 -0.00924444]\n",
            "episode 148, iteration 663\n",
            "Action:  2\n",
            "Current state after Action:  [-1.19923801 -0.00598062]\n",
            "episode 148, iteration 664\n",
            "q values:  tensor([[4.2954, 4.2528, 4.3178]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.2  0. ]\n",
            "episode 148, iteration 665\n",
            "Action:  1\n",
            "Current state after Action:  [-1.1977581  0.0022419]\n",
            "episode 148, iteration 666\n",
            "Action:  1\n",
            "Current state after Action:  [-1.19326692  0.00449118]\n",
            "episode 148, iteration 667\n",
            "Action:  1\n",
            "Current state after Action:  [-1.18651196  0.00675497]\n",
            "episode 148, iteration 668\n",
            "q values:  tensor([[4.3746, 4.4221, 4.4350]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.17747218  0.00903978]\n",
            "episode 148, iteration 669\n",
            "Action:  1\n",
            "Current state after Action:  [-1.16612091  0.01135127]\n",
            "episode 148, iteration 670\n",
            "Action:  1\n",
            "Current state after Action:  [-1.15242707  0.01369384]\n",
            "episode 148, iteration 671\n",
            "Action:  1\n",
            "Current state after Action:  [-1.13635677  0.0160703 ]\n",
            "episode 148, iteration 672\n",
            "q values:  tensor([[5.1245, 5.0650, 5.0946]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.11887536  0.0174814 ]\n",
            "episode 148, iteration 673\n",
            "Action:  0\n",
            "Current state after Action:  [-1.09995154  0.01892382]\n",
            "episode 148, iteration 674\n",
            "Action:  0\n",
            "Current state after Action:  [-1.07955896  0.02039258]\n",
            "episode 148, iteration 675\n",
            "Action:  0\n",
            "Current state after Action:  [-1.05767815  0.02188081]\n",
            "episode 148, iteration 676\n",
            "q values:  tensor([[4.9984, 4.9850, 4.9834]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.03429857  0.02337957]\n",
            "episode 148, iteration 677\n",
            "Action:  0\n",
            "Current state after Action:  [-1.00942087  0.0248777 ]\n",
            "episode 148, iteration 678\n",
            "Action:  0\n",
            "Current state after Action:  [-0.98305921  0.02636166]\n",
            "episode 148, iteration 679\n",
            "Action:  0\n",
            "Current state after Action:  [-0.95524368  0.02781553]\n",
            "episode 148, iteration 680\n",
            "q values:  tensor([[4.2613, 4.1589, 4.0919]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.92502268  0.030221  ]\n",
            "episode 148, iteration 681\n",
            "Action:  1\n",
            "Current state after Action:  [-0.89246773  0.03255495]\n",
            "episode 148, iteration 682\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85767731  0.03479041]\n",
            "episode 148, iteration 683\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82078021  0.0368971 ]\n",
            "episode 148, iteration 684\n",
            "q values:  tensor([[4.7367, 4.7531, 4.7237]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.782938    0.03784221]\n",
            "episode 148, iteration 685\n",
            "Action:  0\n",
            "Current state after Action:  [-0.74434111  0.03859688]\n",
            "episode 148, iteration 686\n",
            "Action:  0\n",
            "Current state after Action:  [-0.70520704  0.03913407]\n",
            "episode 148, iteration 687\n",
            "Action:  0\n",
            "Current state after Action:  [-0.6657773   0.03942974]\n",
            "episode 148, iteration 688\n",
            "q values:  tensor([[4.9559, 4.9818, 4.9879]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.62431326  0.04146404]\n",
            "episode 148, iteration 689\n",
            "Action:  2\n",
            "Current state after Action:  [-0.5811053   0.04320796]\n",
            "episode 148, iteration 690\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53646818  0.04463712]\n",
            "episode 148, iteration 691\n",
            "Action:  2\n",
            "Current state after Action:  [-0.49073457  0.04573362]\n",
            "episode 148, iteration 692\n",
            "q values:  tensor([[4.9746, 4.9110, 5.0480]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.44524703  0.04548753]\n",
            "episode 148, iteration 693\n",
            "Action:  1\n",
            "Current state after Action:  [-0.40034174  0.04490529]\n",
            "episode 148, iteration 694\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35633995  0.04400179]\n",
            "episode 148, iteration 695\n",
            "Action:  1\n",
            "Current state after Action:  [-0.31354063  0.04279933]\n",
            "episode 148, iteration 696\n",
            "q values:  tensor([[4.9615, 4.9502, 4.9889]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.27121451  0.04232611]\n",
            "episode 148, iteration 697\n",
            "Action:  2\n",
            "Current state after Action:  [-0.22960554  0.04160898]\n",
            "episode 148, iteration 698\n",
            "Action:  2\n",
            "Current state after Action:  [-0.18892656  0.04067898]\n",
            "episode 148, iteration 699\n",
            "Action:  2\n",
            "Current state after Action:  [-0.14935666  0.03956989]\n",
            "episode 148, iteration 700\n",
            "q values:  tensor([[5.0097, 4.9918, 5.0190]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.11103998  0.03831668]\n",
            "episode 148, iteration 701\n",
            "Action:  2\n",
            "Current state after Action:  [-0.07408587  0.03695411]\n",
            "episode 148, iteration 702\n",
            "Action:  2\n",
            "Current state after Action:  [-0.03857026  0.03551561]\n",
            "episode 148, iteration 703\n",
            "Action:  2\n",
            "Current state after Action:  [-0.00453793  0.03403233]\n",
            "episode 148, iteration 704\n",
            "q values:  tensor([[4.9314, 4.9705, 4.9169]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.02599463 0.03053256]\n",
            "episode 148, iteration 705\n",
            "Action:  0\n",
            "Current state after Action:  [0.05303478 0.02704016]\n",
            "episode 148, iteration 706\n",
            "Action:  0\n",
            "Current state after Action:  [0.07660651 0.02357173]\n",
            "episode 148, iteration 707\n",
            "Action:  0\n",
            "Current state after Action:  [0.09674398 0.02013746]\n",
            "episode 148, iteration 708\n",
            "q values:  tensor([[9.3407, 9.4484, 9.3150]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.113486   0.01674202]\n",
            "episode 148, iteration 709\n",
            "Action:  0\n",
            "Current state after Action:  [0.12687151 0.01338551]\n",
            "episode 148, iteration 710\n",
            "Action:  0\n",
            "Current state after Action:  [0.13693593 0.01006442]\n",
            "episode 148, iteration 711\n",
            "Action:  0\n",
            "Current state after Action:  [0.14370836 0.00677243]\n",
            "episode 148, iteration 712\n",
            "q values:  tensor([[9.3516, 9.3507, 9.3923]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.14920955 0.00550119]\n",
            "episode 148, iteration 713\n",
            "Action:  2\n",
            "Current state after Action:  [0.15345704 0.0042475 ]\n",
            "episode 148, iteration 714\n",
            "Action:  2\n",
            "Current state after Action:  [0.15646482 0.00300778]\n",
            "episode 148, iteration 715\n",
            "Action:  2\n",
            "Current state after Action:  [0.15824299 0.00177817]\n",
            "episode 148, iteration 716\n",
            "q values:  tensor([[9.2220, 9.4218, 9.3771]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.15879762 0.00055463]\n",
            "episode 148, iteration 717\n",
            "Action:  2\n",
            "Current state after Action:  [ 0.15813062 -0.00066701]\n",
            "episode 148, iteration 718\n",
            "Action:  2\n",
            "Current state after Action:  [ 0.15623968 -0.00189093]\n",
            "episode 148, iteration 719\n",
            "Action:  2\n",
            "Current state after Action:  [ 0.15311838 -0.0031213 ]\n",
            "episode 148, iteration 720\n",
            "q values:  tensor([[9.2758, 9.1989, 9.1214]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.14675623 -0.00636215]\n",
            "episode 148, iteration 721\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.13713249 -0.00962374]\n",
            "episode 148, iteration 722\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.12421734 -0.01291515]\n",
            "episode 148, iteration 723\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.10797377 -0.01624356]\n",
            "episode 148, iteration 724\n",
            "q values:  tensor([[4.9063, 4.9241, 4.8593]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.08836023 -0.01961355]\n",
            "episode 148, iteration 725\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.065334   -0.02302623]\n",
            "episode 148, iteration 726\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.03885564 -0.02647836]\n",
            "episode 148, iteration 727\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.00889424 -0.02996139]\n",
            "episode 148, iteration 728\n",
            "q values:  tensor([[4.9854, 4.9761, 4.9874]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.02356626 -0.0324605 ]\n",
            "episode 148, iteration 729\n",
            "Action:  1\n",
            "Current state after Action:  [-0.05852052 -0.03495426]\n",
            "episode 148, iteration 730\n",
            "Action:  1\n",
            "Current state after Action:  [-0.09593635 -0.03741583]\n",
            "episode 148, iteration 731\n",
            "Action:  1\n",
            "Current state after Action:  [-0.13574935 -0.039813  ]\n",
            "episode 148, iteration 732\n",
            "q values:  tensor([[4.9118, 4.9620, 4.8116]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.17885789 -0.04310854]\n",
            "episode 148, iteration 733\n",
            "Action:  0\n",
            "Current state after Action:  [-0.22511509 -0.0462572 ]\n",
            "episode 148, iteration 734\n",
            "Action:  0\n",
            "Current state after Action:  [-0.27432351 -0.04920843]\n",
            "episode 148, iteration 735\n",
            "Action:  0\n",
            "Current state after Action:  [-0.32623206 -0.05190854]\n",
            "episode 148, iteration 736\n",
            "q values:  tensor([[5.0114, 5.0007, 4.9741]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.37953586 -0.05330381]\n",
            "episode 148, iteration 737\n",
            "Action:  1\n",
            "Current state after Action:  [-0.43388682 -0.05435095]\n",
            "episode 148, iteration 738\n",
            "Action:  1\n",
            "Current state after Action:  [-0.48890252 -0.0550157 ]\n",
            "episode 148, iteration 739\n",
            "Action:  1\n",
            "Current state after Action:  [-0.54417797 -0.05527545]\n",
            "episode 148, iteration 740\n",
            "q values:  tensor([[5.0407, 4.9747, 4.9567]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60029918 -0.05612121]\n",
            "episode 148, iteration 741\n",
            "Action:  0\n",
            "Current state after Action:  [-0.65685019 -0.05655102]\n",
            "episode 148, iteration 742\n",
            "Action:  0\n",
            "Current state after Action:  [-0.71342823 -0.05657804]\n",
            "episode 148, iteration 743\n",
            "Action:  0\n",
            "Current state after Action:  [-0.76965826 -0.05623003]\n",
            "episode 148, iteration 744\n",
            "q values:  tensor([[4.9086, 4.9165, 4.8823]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.82520594 -0.05554768]\n",
            "episode 148, iteration 745\n",
            "Action:  0\n",
            "Current state after Action:  [-0.87978783 -0.05458189]\n",
            "episode 148, iteration 746\n",
            "Action:  0\n",
            "Current state after Action:  [-0.93317845 -0.05339061]\n",
            "episode 148, iteration 747\n",
            "Action:  0\n",
            "Current state after Action:  [-0.98521389 -0.05203545]\n",
            "episode 148, iteration 748\n",
            "q values:  tensor([[5.0209, 4.9610, 4.9726]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.03379244 -0.04857854]\n",
            "episode 148, iteration 749\n",
            "Action:  2\n",
            "Current state after Action:  [-1.078873   -0.04508057]\n",
            "episode 148, iteration 750\n",
            "Action:  2\n",
            "Current state after Action:  [-1.12046485 -0.04159184]\n",
            "episode 148, iteration 751\n",
            "Action:  2\n",
            "Current state after Action:  [-1.15861684 -0.03815199]\n",
            "episode 148, iteration 752\n",
            "q values:  tensor([[5.2961, 5.1668, 5.2308]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.1944072  -0.03579036]\n",
            "episode 148, iteration 753\n",
            "Action:  1\n",
            "Current state after Action:  [-1.2  0. ]\n",
            "episode 148, iteration 754\n",
            "Action:  1\n",
            "Current state after Action:  [-1.1977581  0.0022419]\n",
            "episode 148, iteration 755\n",
            "Action:  1\n",
            "Current state after Action:  [-1.19326692  0.00449118]\n",
            "episode 148, iteration 756\n",
            "q values:  tensor([[4.3844, 4.7071, 4.5498]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.18551196  0.00775497]\n",
            "episode 148, iteration 757\n",
            "Action:  2\n",
            "Current state after Action:  [-1.17446914  0.01104281]\n",
            "episode 148, iteration 758\n",
            "Action:  2\n",
            "Current state after Action:  [-1.16010635  0.01436279]\n",
            "episode 148, iteration 759\n",
            "Action:  2\n",
            "Current state after Action:  [-1.14238562  0.01772074]\n",
            "episode 148, iteration 760\n",
            "q values:  tensor([[5.1003, 5.1381, 5.2075]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.12126613  0.02111949]\n",
            "episode 148, iteration 761\n",
            "Action:  2\n",
            "Current state after Action:  [-1.0967081   0.02455803]\n",
            "episode 148, iteration 762\n",
            "Action:  2\n",
            "Current state after Action:  [-1.0686776  0.0280305]\n",
            "episode 148, iteration 763\n",
            "Action:  2\n",
            "Current state after Action:  [-1.03715229  0.03152531]\n",
            "episode 148, iteration 764\n",
            "q values:  tensor([[4.9406, 4.9563, 4.9378]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.00212811  0.03502418]\n",
            "episode 148, iteration 765\n",
            "Action:  2\n",
            "Current state after Action:  [-0.96362675  0.03850136]\n",
            "episode 148, iteration 766\n",
            "Action:  2\n",
            "Current state after Action:  [-0.92170355  0.0419232 ]\n",
            "episode 148, iteration 767\n",
            "Action:  2\n",
            "Current state after Action:  [-0.87645545  0.04524811]\n",
            "episode 148, iteration 768\n",
            "q values:  tensor([[5.0279, 5.0478, 5.0481]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.8280282   0.04842725]\n",
            "episode 148, iteration 769\n",
            "Action:  2\n",
            "Current state after Action:  [-0.77662216  0.05140604]\n",
            "episode 148, iteration 770\n",
            "Action:  2\n",
            "Current state after Action:  [-0.7224955   0.05412666]\n",
            "episode 148, iteration 771\n",
            "Action:  2\n",
            "Current state after Action:  [-0.66596407  0.05653143]\n",
            "episode 148, iteration 772\n",
            "q values:  tensor([[4.9869, 4.9722, 4.9740]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60939707  0.056567  ]\n",
            "episode 148, iteration 773\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55319366  0.05620341]\n",
            "episode 148, iteration 774\n",
            "Action:  0\n",
            "Current state after Action:  [-0.49776858  0.05542508]\n",
            "episode 148, iteration 775\n",
            "Action:  0\n",
            "Current state after Action:  [-0.44353704  0.05423154]\n",
            "episode 148, iteration 776\n",
            "q values:  tensor([[5.0027, 4.9963, 5.0167]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.3889002   0.05463684]\n",
            "episode 148, iteration 777\n",
            "Action:  2\n",
            "Current state after Action:  [-0.33424633  0.05465387]\n",
            "episode 148, iteration 778\n",
            "Action:  2\n",
            "Current state after Action:  [-0.27993745  0.05430888]\n",
            "episode 148, iteration 779\n",
            "Action:  2\n",
            "Current state after Action:  [-0.22629757  0.05363987]\n",
            "episode 148, iteration 780\n",
            "q values:  tensor([[ 9.0225,  9.8937, 10.3555]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.17460337  0.0516942 ]\n",
            "episode 148, iteration 781\n",
            "Action:  1\n",
            "Current state after Action:  [-0.12507397  0.0495294 ]\n",
            "episode 148, iteration 782\n",
            "Action:  1\n",
            "Current state after Action:  [-0.07787063  0.04720334]\n",
            "episode 148, iteration 783\n",
            "Action:  1\n",
            "Current state after Action:  [-0.03309938  0.04477125]\n",
            "episode 148, iteration 784\n",
            "q values:  tensor([[8.8394, 9.3641, 9.9799]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.01018418 0.04328356]\n",
            "episode 148, iteration 785\n",
            "Action:  2\n",
            "Current state after Action:  [0.05196891 0.04178473]\n",
            "episode 148, iteration 786\n",
            "Action:  2\n",
            "Current state after Action:  [0.09228396 0.04031505]\n",
            "episode 148, iteration 787\n",
            "Action:  2\n",
            "Current state after Action:  [0.13119421 0.03891025]\n",
            "episode 148, iteration 788\n",
            "q values:  tensor([[9.9373, 9.8265, 9.9145]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.1687956 0.0376014]\n",
            "episode 148, iteration 789\n",
            "Action:  2\n",
            "Current state after Action:  [0.20521074 0.03641514]\n",
            "episode 148, iteration 790\n",
            "Action:  2\n",
            "Current state after Action:  [0.24058486 0.03537412]\n",
            "episode 148, iteration 791\n",
            "Action:  2\n",
            "Current state after Action:  [0.27508236 0.0344975 ]\n",
            "episode 148, iteration 792\n",
            "q values:  tensor([[9.6261, 9.4669, 9.3670]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.30688392 0.03180156]\n",
            "episode 148, iteration 793\n",
            "Action:  0\n",
            "Current state after Action:  [0.33617223 0.02928831]\n",
            "episode 148, iteration 794\n",
            "Action:  0\n",
            "Current state after Action:  [0.36312774 0.02695552]\n",
            "episode 148, iteration 795\n",
            "Action:  0\n",
            "Current state after Action:  [0.38792568 0.02479794]\n",
            "episode 148, iteration 796\n",
            "q values:  tensor([[8.7529, 8.6380, 8.7037]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.41073393 0.02280825]\n",
            "episode 148, iteration 797\n",
            "Action:  0\n",
            "Current state after Action:  [0.43171178 0.02097785]\n",
            "episode 148, iteration 798\n",
            "Action:  0\n",
            "Current state after Action:  [0.45100916 0.01929739]\n",
            "episode 148, iteration 799\n",
            "Action:  0\n",
            "Current state after Action:  [0.46876642 0.01775726]\n",
            "episode 148, iteration 800\n",
            "q values:  tensor([[2.3057, 2.2558, 2.0315]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.48611429 0.01734787]\n",
            "episode 148, iteration 801\n",
            "Action:  1\n",
            "Current state after Action:  [0.50318162 0.01706733]\n",
            "episode 149, iteration 0\n",
            "q values:  tensor([[4.9725, 4.9663, 4.9970]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-5.02627887e-01 -1.58363285e-04]\n",
            "episode 149, iteration 1\n",
            "Action:  1\n",
            "Current state after Action:  [-5.02943429e-01 -3.15541213e-04]\n",
            "episode 149, iteration 2\n",
            "Action:  1\n",
            "Current state after Action:  [-5.03413786e-01 -4.70357194e-04]\n",
            "episode 149, iteration 3\n",
            "Action:  1\n",
            "Current state after Action:  [-0.50403544 -0.00062165]\n",
            "episode 149, iteration 4\n",
            "q values:  tensor([[4.9735, 4.9854, 4.9859]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.50580373 -0.00176829]\n",
            "episode 149, iteration 5\n",
            "Action:  0\n",
            "Current state after Action:  [-0.50870542 -0.00290169]\n",
            "episode 149, iteration 6\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51271878 -0.00401336]\n",
            "episode 149, iteration 7\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51781372 -0.00509494]\n",
            "episode 149, iteration 8\n",
            "q values:  tensor([[4.9856, 4.9586, 4.7604]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52195205 -0.00413833]\n",
            "episode 149, iteration 9\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52510272 -0.00315068]\n",
            "episode 149, iteration 10\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52724212 -0.0021394 ]\n",
            "episode 149, iteration 11\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52835419 -0.00111207]\n",
            "episode 149, iteration 12\n",
            "q values:  tensor([[4.9970, 5.0158, 5.0844]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.5304306  -0.00207641]\n",
            "episode 149, iteration 13\n",
            "Action:  0\n",
            "Current state after Action:  [-0.53345578 -0.00302517]\n",
            "episode 149, iteration 14\n",
            "Action:  0\n",
            "Current state after Action:  [-0.53740703 -0.00395126]\n",
            "episode 149, iteration 15\n",
            "Action:  0\n",
            "Current state after Action:  [-0.54225476 -0.00484772]\n",
            "episode 149, iteration 16\n",
            "q values:  tensor([[4.9428, 4.8868, 4.9063]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.54796263 -0.00570788]\n",
            "episode 149, iteration 17\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55448795 -0.00652531]\n",
            "episode 149, iteration 18\n",
            "Action:  0\n",
            "Current state after Action:  [-0.56178192 -0.00729397]\n",
            "episode 149, iteration 19\n",
            "Action:  0\n",
            "Current state after Action:  [-0.56979015 -0.00800823]\n",
            "episode 149, iteration 20\n",
            "q values:  tensor([[4.9228, 4.9287, 4.9358]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.57645304 -0.0066629 ]\n",
            "episode 149, iteration 21\n",
            "Action:  2\n",
            "Current state after Action:  [-0.58172119 -0.00526815]\n",
            "episode 149, iteration 22\n",
            "Action:  2\n",
            "Current state after Action:  [-0.58555563 -0.00383444]\n",
            "episode 149, iteration 23\n",
            "Action:  2\n",
            "Current state after Action:  [-0.58792806 -0.00237243]\n",
            "episode 149, iteration 24\n",
            "q values:  tensor([[5.0129, 5.0900, 4.9837]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59082102 -0.00289295]\n",
            "episode 149, iteration 25\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59421321 -0.0033922 ]\n",
            "episode 149, iteration 26\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59807975 -0.00386654]\n",
            "episode 149, iteration 27\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60239232 -0.00431257]\n",
            "episode 149, iteration 28\n",
            "q values:  tensor([[5.2318, 5.2878, 5.2407]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.60511943 -0.00272711]\n",
            "episode 149, iteration 29\n",
            "Action:  2\n",
            "Current state after Action:  [-0.60624121 -0.00112178]\n",
            "episode 149, iteration 30\n",
            "Action:  2\n",
            "Current state after Action:  [-6.05749494e-01  4.91710614e-04]\n",
            "episode 149, iteration 31\n",
            "Action:  2\n",
            "Current state after Action:  [-0.60364787  0.00210162]\n",
            "episode 149, iteration 32\n",
            "q values:  tensor([[4.8232, 5.0555, 5.0404]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60195163  0.00169624]\n",
            "episode 149, iteration 33\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60067315  0.00127849]\n",
            "episode 149, iteration 34\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59982174  0.00085141]\n",
            "episode 149, iteration 35\n",
            "Action:  0\n",
            "Current state after Action:  [-5.99403630e-01  4.18110693e-04]\n",
            "episode 149, iteration 36\n",
            "q values:  tensor([[4.9631, 4.9848, 5.0117]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-5.99421870e-01 -1.82407807e-05]\n",
            "episode 149, iteration 37\n",
            "Action:  0\n",
            "Current state after Action:  [-5.99876329e-01 -4.54458972e-04]\n",
            "episode 149, iteration 38\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60076369 -0.00088736]\n",
            "episode 149, iteration 39\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60207746 -0.00131378]\n",
            "episode 149, iteration 40\n",
            "q values:  tensor([[4.9837, 5.0831, 5.0550]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.60280807 -0.00073061]\n",
            "episode 149, iteration 41\n",
            "Action:  1\n",
            "Current state after Action:  [-6.02950183e-01 -1.42113278e-04]\n",
            "episode 149, iteration 42\n",
            "Action:  1\n",
            "Current state after Action:  [-6.02502766e-01  4.47417146e-04]\n",
            "episode 149, iteration 43\n",
            "Action:  1\n",
            "Current state after Action:  [-0.60146908  0.00103369]\n",
            "episode 149, iteration 44\n",
            "q values:  tensor([[5.0946, 5.0930, 5.1149]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60085666  0.00061242]\n",
            "episode 149, iteration 45\n",
            "Action:  0\n",
            "Current state after Action:  [-6.00669988e-01  1.86675986e-04]\n",
            "episode 149, iteration 46\n",
            "Action:  0\n",
            "Current state after Action:  [-6.00910415e-01 -2.40426430e-04]\n",
            "episode 149, iteration 47\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60157619 -0.00066577]\n",
            "episode 149, iteration 48\n",
            "q values:  tensor([[5.1424, 5.1349, 5.3199]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.60066245  0.00091374]\n",
            "episode 149, iteration 49\n",
            "Action:  2\n",
            "Current state after Action:  [-0.59817587  0.00248658]\n",
            "episode 149, iteration 50\n",
            "Action:  2\n",
            "Current state after Action:  [-0.59413462  0.00404125]\n",
            "episode 149, iteration 51\n",
            "Action:  2\n",
            "Current state after Action:  [-0.58856828  0.00556633]\n",
            "episode 149, iteration 52\n",
            "q values:  tensor([[5.0067, 5.0119, 4.9823]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.58251776  0.00605053]\n",
            "episode 149, iteration 53\n",
            "Action:  1\n",
            "Current state after Action:  [-0.57602764  0.00649012]\n",
            "episode 149, iteration 54\n",
            "Action:  1\n",
            "Current state after Action:  [-0.56914592  0.00688172]\n",
            "episode 149, iteration 55\n",
            "Action:  1\n",
            "Current state after Action:  [-0.56192366  0.00722226]\n",
            "episode 149, iteration 56\n",
            "q values:  tensor([[4.9655, 4.9435, 4.9636]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.5544146   0.00750906]\n",
            "episode 149, iteration 57\n",
            "Action:  1\n",
            "Current state after Action:  [-0.54667475  0.00773985]\n",
            "episode 149, iteration 58\n",
            "Action:  1\n",
            "Current state after Action:  [-0.53876196  0.00791278]\n",
            "episode 149, iteration 59\n",
            "Action:  1\n",
            "Current state after Action:  [-0.5307355   0.00802647]\n",
            "episode 149, iteration 60\n",
            "q values:  tensor([[4.9717, 4.9848, 4.9541]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52165551  0.00907999]\n",
            "episode 149, iteration 61\n",
            "Action:  2\n",
            "Current state after Action:  [-0.51159009  0.01006542]\n",
            "episode 149, iteration 62\n",
            "Action:  2\n",
            "Current state after Action:  [-0.50061472  0.01097537]\n",
            "episode 149, iteration 63\n",
            "Action:  2\n",
            "Current state after Action:  [-0.4888116   0.01180313]\n",
            "episode 149, iteration 64\n",
            "q values:  tensor([[5.0408, 4.9975, 4.9764]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.4762689  0.0125427]\n",
            "episode 149, iteration 65\n",
            "Action:  2\n",
            "Current state after Action:  [-0.46307999  0.01318891]\n",
            "episode 149, iteration 66\n",
            "Action:  2\n",
            "Current state after Action:  [-0.44934248  0.01373751]\n",
            "episode 149, iteration 67\n",
            "Action:  2\n",
            "Current state after Action:  [-0.43515729  0.01418518]\n",
            "episode 149, iteration 68\n",
            "q values:  tensor([[5.0897, 5.0765, 5.1159]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42262766  0.01252963]\n",
            "episode 149, iteration 69\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41184379  0.01078387]\n",
            "episode 149, iteration 70\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40288247  0.00896132]\n",
            "episode 149, iteration 71\n",
            "Action:  0\n",
            "Current state after Action:  [-0.39580685  0.00707561]\n",
            "episode 149, iteration 72\n",
            "q values:  tensor([[4.9557, 4.9419, 4.9608]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.38866637  0.00714048]\n",
            "episode 149, iteration 73\n",
            "Action:  2\n",
            "Current state after Action:  [-0.38151048  0.0071559 ]\n",
            "episode 149, iteration 74\n",
            "Action:  2\n",
            "Current state after Action:  [-0.37438826  0.00712222]\n",
            "episode 149, iteration 75\n",
            "Action:  2\n",
            "Current state after Action:  [-0.36734812  0.00704014]\n",
            "episode 149, iteration 76\n",
            "q values:  tensor([[5.0514, 5.0893, 5.0879]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.36143742  0.0059107 ]\n",
            "episode 149, iteration 77\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35669551  0.0047419 ]\n",
            "episode 149, iteration 78\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35315373  0.00354178]\n",
            "episode 149, iteration 79\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35083531  0.00231843]\n",
            "episode 149, iteration 80\n",
            "q values:  tensor([[4.9964, 4.9469, 4.9058]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-3.50755369e-01  7.99370830e-05]\n",
            "episode 149, iteration 81\n",
            "Action:  0\n",
            "Current state after Action:  [-0.35291444 -0.00215907]\n",
            "episode 149, iteration 82\n",
            "Action:  0\n",
            "Current state after Action:  [-0.35729844 -0.00438399]\n",
            "episode 149, iteration 83\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36387858 -0.00658015]\n",
            "episode 149, iteration 84\n",
            "q values:  tensor([[4.9421, 4.9923, 4.9863]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.37061131 -0.00673273]\n",
            "episode 149, iteration 85\n",
            "Action:  2\n",
            "Current state after Action:  [-0.37745159 -0.00684028]\n",
            "episode 149, iteration 86\n",
            "Action:  2\n",
            "Current state after Action:  [-0.38435319 -0.0069016 ]\n",
            "episode 149, iteration 87\n",
            "Action:  2\n",
            "Current state after Action:  [-0.39126902 -0.00691583]\n",
            "episode 149, iteration 88\n",
            "q values:  tensor([[5.1415, 4.9560, 4.9788]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40015146 -0.00888244]\n",
            "episode 149, iteration 89\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41093873 -0.01078728]\n",
            "episode 149, iteration 90\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42355496 -0.01261623]\n",
            "episode 149, iteration 91\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43791031 -0.01435535]\n",
            "episode 149, iteration 92\n",
            "q values:  tensor([[4.9748, 4.9361, 4.9387]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45290126 -0.01499095]\n",
            "episode 149, iteration 93\n",
            "Action:  1\n",
            "Current state after Action:  [-0.46841848 -0.01551722]\n",
            "episode 149, iteration 94\n",
            "Action:  1\n",
            "Current state after Action:  [-0.48434767 -0.01592918]\n",
            "episode 149, iteration 95\n",
            "Action:  1\n",
            "Current state after Action:  [-0.50057055 -0.01622289]\n",
            "episode 149, iteration 96\n",
            "q values:  tensor([[4.9686, 4.9535, 4.9522]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51796601 -0.01739546]\n",
            "episode 149, iteration 97\n",
            "Action:  0\n",
            "Current state after Action:  [-0.53640372 -0.01843771]\n",
            "episode 149, iteration 98\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55574541 -0.01934169]\n",
            "episode 149, iteration 99\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57584638 -0.02010097]\n",
            "episode 149, iteration 100\n",
            "q values:  tensor([[5.0337, 5.0498, 5.0681]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.59455709 -0.01871071]\n",
            "episode 149, iteration 101\n",
            "Action:  2\n",
            "Current state after Action:  [-0.61173962 -0.01718253]\n",
            "episode 149, iteration 102\n",
            "Action:  2\n",
            "Current state after Action:  [-0.62726878 -0.01552915]\n",
            "episode 149, iteration 103\n",
            "Action:  2\n",
            "Current state after Action:  [-0.64103288 -0.0137641 ]\n",
            "episode 149, iteration 104\n",
            "q values:  tensor([[4.9364, 4.8299, 4.9329]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.65393433 -0.01290145]\n",
            "episode 149, iteration 105\n",
            "Action:  1\n",
            "Current state after Action:  [-0.66588299 -0.01194866]\n",
            "episode 149, iteration 106\n",
            "Action:  1\n",
            "Current state after Action:  [-0.67679663 -0.01091364]\n",
            "episode 149, iteration 107\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6866013  -0.00980468]\n",
            "episode 149, iteration 108\n",
            "q values:  tensor([[5.0258, 5.0222, 5.1021]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6952316 -0.0086303]\n",
            "episode 149, iteration 109\n",
            "Action:  1\n",
            "Current state after Action:  [-0.70263079 -0.00739919]\n",
            "episode 149, iteration 110\n",
            "Action:  1\n",
            "Current state after Action:  [-0.70875087 -0.00612008]\n",
            "episode 149, iteration 111\n",
            "Action:  1\n",
            "Current state after Action:  [-0.71355262 -0.00480175]\n",
            "episode 149, iteration 112\n",
            "q values:  tensor([[4.9855, 4.9839, 4.9644]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.71600558 -0.00245296]\n",
            "episode 149, iteration 113\n",
            "Action:  2\n",
            "Current state after Action:  [-7.16094297e-01 -8.87193738e-05]\n",
            "episode 149, iteration 114\n",
            "Action:  2\n",
            "Current state after Action:  [-0.71381822  0.00227608]\n",
            "episode 149, iteration 115\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70919167  0.00462655]\n",
            "episode 149, iteration 116\n",
            "q values:  tensor([[5.0272, 4.9893, 4.9782]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70224399  0.00694768]\n",
            "episode 149, iteration 117\n",
            "Action:  2\n",
            "Current state after Action:  [-0.69301969  0.0092243 ]\n",
            "episode 149, iteration 118\n",
            "Action:  2\n",
            "Current state after Action:  [-0.68157875  0.01144095]\n",
            "episode 149, iteration 119\n",
            "Action:  2\n",
            "Current state after Action:  [-0.66799681  0.01358193]\n",
            "episode 149, iteration 120\n",
            "q values:  tensor([[4.9861, 4.9938, 4.9881]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.65236545  0.01563136]\n",
            "episode 149, iteration 121\n",
            "Action:  2\n",
            "Current state after Action:  [-0.63479217  0.01757327]\n",
            "episode 149, iteration 122\n",
            "Action:  2\n",
            "Current state after Action:  [-0.61540033  0.01939184]\n",
            "episode 149, iteration 123\n",
            "Action:  2\n",
            "Current state after Action:  [-0.59432865  0.02107168]\n",
            "episode 149, iteration 124\n",
            "q values:  tensor([[4.9680, 4.9573, 4.8854]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.57173046  0.02259819]\n",
            "episode 149, iteration 125\n",
            "Action:  2\n",
            "Current state after Action:  [-0.54777254  0.02395792]\n",
            "episode 149, iteration 126\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52263347  0.02513907]\n",
            "episode 149, iteration 127\n",
            "Action:  2\n",
            "Current state after Action:  [-0.49650164  0.02613183]\n",
            "episode 149, iteration 128\n",
            "q values:  tensor([[4.9319, 4.9024, 4.9066]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.46957282  0.02692882]\n",
            "episode 149, iteration 129\n",
            "Action:  2\n",
            "Current state after Action:  [-0.44204742  0.0275254 ]\n",
            "episode 149, iteration 130\n",
            "Action:  2\n",
            "Current state after Action:  [-0.41412758  0.02791985]\n",
            "episode 149, iteration 131\n",
            "Action:  2\n",
            "Current state after Action:  [-0.38601409  0.02811349]\n",
            "episode 149, iteration 132\n",
            "q values:  tensor([[5.0303, 4.9825, 5.0843]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.35790343  0.02811066]\n",
            "episode 149, iteration 133\n",
            "Action:  2\n",
            "Current state after Action:  [-0.32998493  0.02791849]\n",
            "episode 149, iteration 134\n",
            "Action:  2\n",
            "Current state after Action:  [-0.30243826  0.02754667]\n",
            "episode 149, iteration 135\n",
            "Action:  2\n",
            "Current state after Action:  [-0.27543125  0.02700701]\n",
            "episode 149, iteration 136\n",
            "q values:  tensor([[4.8887, 4.9726, 4.9691]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.25011825  0.025313  ]\n",
            "episode 149, iteration 137\n",
            "Action:  1\n",
            "Current state after Action:  [-0.22663387  0.02348438]\n",
            "episode 149, iteration 138\n",
            "Action:  1\n",
            "Current state after Action:  [-0.20509357  0.0215403 ]\n",
            "episode 149, iteration 139\n",
            "Action:  1\n",
            "Current state after Action:  [-0.1855948   0.01949877]\n",
            "episode 149, iteration 140\n",
            "q values:  tensor([[4.9689, 5.0428, 5.0784]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.16821843  0.01737637]\n",
            "episode 149, iteration 141\n",
            "Action:  1\n",
            "Current state after Action:  [-0.15303042  0.01518802]\n",
            "episode 149, iteration 142\n",
            "Action:  1\n",
            "Current state after Action:  [-0.14008354  0.01294688]\n",
            "episode 149, iteration 143\n",
            "Action:  1\n",
            "Current state after Action:  [-0.12941913  0.01066441]\n",
            "episode 149, iteration 144\n",
            "q values:  tensor([[4.9836, 4.9874, 5.0382]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.12206864  0.00735049]\n",
            "episode 149, iteration 145\n",
            "Action:  0\n",
            "Current state after Action:  [-0.11805239  0.00401625]\n",
            "episode 149, iteration 146\n",
            "Action:  0\n",
            "Current state after Action:  [-0.11738098  0.00067141]\n",
            "episode 149, iteration 147\n",
            "Action:  0\n",
            "Current state after Action:  [-0.12005616 -0.00267518]\n",
            "episode 149, iteration 148\n",
            "q values:  tensor([[4.9788, 4.9888, 4.9825]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.12407094 -0.00401478]\n",
            "episode 149, iteration 149\n",
            "Action:  2\n",
            "Current state after Action:  [-0.12941453 -0.00534359]\n",
            "episode 149, iteration 150\n",
            "Action:  2\n",
            "Current state after Action:  [-0.13607206 -0.00665753]\n",
            "episode 149, iteration 151\n",
            "Action:  2\n",
            "Current state after Action:  [-0.14402416 -0.0079521 ]\n",
            "episode 149, iteration 152\n",
            "q values:  tensor([[5.0013, 5.0123, 4.9967]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.15424651 -0.01022235]\n",
            "episode 149, iteration 153\n",
            "Action:  1\n",
            "Current state after Action:  [-0.16670595 -0.01245944]\n",
            "episode 149, iteration 154\n",
            "Action:  1\n",
            "Current state after Action:  [-0.1813592  -0.01465325]\n",
            "episode 149, iteration 155\n",
            "Action:  1\n",
            "Current state after Action:  [-0.19815146 -0.01679226]\n",
            "episode 149, iteration 156\n",
            "q values:  tensor([[5.0149, 5.0217, 5.0257]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.21701486 -0.0188634 ]\n",
            "episode 149, iteration 157\n",
            "Action:  1\n",
            "Current state after Action:  [-0.23786689 -0.02085203]\n",
            "episode 149, iteration 158\n",
            "Action:  1\n",
            "Current state after Action:  [-0.26060894 -0.02274205]\n",
            "episode 149, iteration 159\n",
            "Action:  1\n",
            "Current state after Action:  [-0.28512506 -0.02451612]\n",
            "episode 149, iteration 160\n",
            "q values:  tensor([[4.9911, 5.0656, 5.0401]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.31128102 -0.02615596]\n",
            "episode 149, iteration 161\n",
            "Action:  1\n",
            "Current state after Action:  [-0.33892385 -0.02764283]\n",
            "episode 149, iteration 162\n",
            "Action:  1\n",
            "Current state after Action:  [-0.36788197 -0.02895812]\n",
            "episode 149, iteration 163\n",
            "Action:  1\n",
            "Current state after Action:  [-0.39796594 -0.03008398]\n",
            "episode 149, iteration 164\n",
            "q values:  tensor([[4.9200, 4.9175, 4.9448]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.42897002 -0.03100407]\n",
            "episode 149, iteration 165\n",
            "Action:  1\n",
            "Current state after Action:  [-0.46067431 -0.03170429]\n",
            "episode 149, iteration 166\n",
            "Action:  1\n",
            "Current state after Action:  [-0.49284774 -0.03217343]\n",
            "episode 149, iteration 167\n",
            "Action:  1\n",
            "Current state after Action:  [-0.52525147 -0.03240373]\n",
            "episode 149, iteration 168\n",
            "q values:  tensor([[5.0545, 4.9931, 4.9970]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.55764281 -0.03239134]\n",
            "episode 149, iteration 169\n",
            "Action:  1\n",
            "Current state after Action:  [-0.58977927 -0.03213645]\n",
            "episode 149, iteration 170\n",
            "Action:  1\n",
            "Current state after Action:  [-0.62142262 -0.03164335]\n",
            "episode 149, iteration 171\n",
            "Action:  1\n",
            "Current state after Action:  [-0.65234278 -0.03092016]\n",
            "episode 149, iteration 172\n",
            "q values:  tensor([[4.9619, 4.9475, 4.9495]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.68132119 -0.02897841]\n",
            "episode 149, iteration 173\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70816033 -0.02683914]\n",
            "episode 149, iteration 174\n",
            "Action:  2\n",
            "Current state after Action:  [-0.73268491 -0.02452458]\n",
            "episode 149, iteration 175\n",
            "Action:  2\n",
            "Current state after Action:  [-0.75474217 -0.02205726]\n",
            "episode 149, iteration 176\n",
            "q values:  tensor([[5.1389, 5.0421, 5.0926]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.77520148 -0.02045931]\n",
            "episode 149, iteration 177\n",
            "Action:  1\n",
            "Current state after Action:  [-0.79394792 -0.01874644]\n",
            "episode 149, iteration 178\n",
            "Action:  1\n",
            "Current state after Action:  [-0.81088184 -0.01693392]\n",
            "episode 149, iteration 179\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82591814 -0.0150363 ]\n",
            "episode 149, iteration 180\n",
            "q values:  tensor([[4.9977, 5.0842, 4.9769]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.83898535 -0.01306722]\n",
            "episode 149, iteration 181\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85002463 -0.01103928]\n",
            "episode 149, iteration 182\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85898867 -0.00896404]\n",
            "episode 149, iteration 183\n",
            "Action:  1\n",
            "Current state after Action:  [-0.86584073 -0.00685207]\n",
            "episode 149, iteration 184\n",
            "q values:  tensor([[5.0096, 4.9870, 4.9813]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.86955378 -0.00371305]\n",
            "episode 149, iteration 185\n",
            "Action:  2\n",
            "Current state after Action:  [-8.70113523e-01 -5.59742247e-04]\n",
            "episode 149, iteration 186\n",
            "Action:  2\n",
            "Current state after Action:  [-0.86751783  0.00259569]\n",
            "episode 149, iteration 187\n",
            "Action:  2\n",
            "Current state after Action:  [-0.86177663  0.0057412 ]\n",
            "episode 149, iteration 188\n",
            "q values:  tensor([[4.9127, 4.8781, 4.8534]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.85291235  0.00886428]\n",
            "episode 149, iteration 189\n",
            "Action:  2\n",
            "Current state after Action:  [-0.84096083  0.01195152]\n",
            "episode 149, iteration 190\n",
            "Action:  2\n",
            "Current state after Action:  [-0.82597275  0.01498809]\n",
            "episode 149, iteration 191\n",
            "Action:  2\n",
            "Current state after Action:  [-0.80801532  0.01795742]\n",
            "episode 149, iteration 192\n",
            "q values:  tensor([[5.1355, 5.1136, 5.1406]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.78817435  0.01984097]\n",
            "episode 149, iteration 193\n",
            "Action:  1\n",
            "Current state after Action:  [-0.76655095  0.0216234 ]\n",
            "episode 149, iteration 194\n",
            "Action:  1\n",
            "Current state after Action:  [-0.7432625   0.02328845]\n",
            "episode 149, iteration 195\n",
            "Action:  1\n",
            "Current state after Action:  [-0.71844326  0.02481924]\n",
            "episode 149, iteration 196\n",
            "q values:  tensor([[4.9828, 4.9345, 4.9129]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.69224448  0.02619877]\n",
            "episode 149, iteration 197\n",
            "Action:  1\n",
            "Current state after Action:  [-0.66483415  0.02741034]\n",
            "episode 149, iteration 198\n",
            "Action:  1\n",
            "Current state after Action:  [-0.63639595  0.02843819]\n",
            "episode 149, iteration 199\n",
            "Action:  1\n",
            "Current state after Action:  [-0.60712783  0.02926812]\n",
            "episode 149, iteration 200\n",
            "q values:  tensor([[5.0579, 4.9914, 4.9895]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.57623978  0.03088805]\n",
            "episode 149, iteration 201\n",
            "Action:  2\n",
            "Current state after Action:  [-0.54395856  0.03228122]\n",
            "episode 149, iteration 202\n",
            "Action:  2\n",
            "Current state after Action:  [-0.51052474  0.03343382]\n",
            "episode 149, iteration 203\n",
            "Action:  2\n",
            "Current state after Action:  [-0.47618895  0.03433579]\n",
            "episode 149, iteration 204\n",
            "q values:  tensor([[5.0259, 5.0228, 5.0303]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.44320753  0.03298142]\n",
            "episode 149, iteration 205\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41182322  0.03138431]\n",
            "episode 149, iteration 206\n",
            "Action:  0\n",
            "Current state after Action:  [-0.3822616   0.02956162]\n",
            "episode 149, iteration 207\n",
            "Action:  0\n",
            "Current state after Action:  [-0.35472854  0.02753307]\n",
            "episode 149, iteration 208\n",
            "q values:  tensor([[5.0007, 5.0532, 5.1941]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.32740851  0.02732003]\n",
            "episode 149, iteration 209\n",
            "Action:  2\n",
            "Current state after Action:  [-0.30047642  0.02693209]\n",
            "episode 149, iteration 210\n",
            "Action:  2\n",
            "Current state after Action:  [-0.27409555  0.02638087]\n",
            "episode 149, iteration 211\n",
            "Action:  2\n",
            "Current state after Action:  [-0.24841605  0.0256795 ]\n",
            "episode 149, iteration 212\n",
            "q values:  tensor([[4.9255, 4.8646, 4.9774]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.22457385  0.0238422 ]\n",
            "episode 149, iteration 213\n",
            "Action:  1\n",
            "Current state after Action:  [-0.20268541  0.02188844]\n",
            "episode 149, iteration 214\n",
            "Action:  1\n",
            "Current state after Action:  [-0.18284887  0.01983654]\n",
            "episode 149, iteration 215\n",
            "Action:  1\n",
            "Current state after Action:  [-0.16514555  0.01770333]\n",
            "episode 149, iteration 216\n",
            "q values:  tensor([[5.0272, 4.9403, 5.1280]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.14864162  0.01650393]\n",
            "episode 149, iteration 217\n",
            "Action:  2\n",
            "Current state after Action:  [-0.13339322  0.0152484 ]\n",
            "episode 149, iteration 218\n",
            "Action:  2\n",
            "Current state after Action:  [-0.11944731  0.01394592]\n",
            "episode 149, iteration 219\n",
            "Action:  2\n",
            "Current state after Action:  [-0.10684259  0.01260472]\n",
            "episode 149, iteration 220\n",
            "q values:  tensor([[4.9116, 4.9414, 4.9389]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.09561054  0.01123205]\n",
            "episode 149, iteration 221\n",
            "Action:  2\n",
            "Current state after Action:  [-0.08577636  0.00983418]\n",
            "episode 149, iteration 222\n",
            "Action:  2\n",
            "Current state after Action:  [-0.07735986  0.0084165 ]\n",
            "episode 149, iteration 223\n",
            "Action:  2\n",
            "Current state after Action:  [-0.07037633  0.00698352]\n",
            "episode 149, iteration 224\n",
            "q values:  tensor([[4.8923, 4.9331, 4.9176]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.06483729  0.00553904]\n",
            "episode 149, iteration 225\n",
            "Action:  2\n",
            "Current state after Action:  [-0.06075111  0.00408618]\n",
            "episode 149, iteration 226\n",
            "Action:  2\n",
            "Current state after Action:  [-0.05812352  0.00262759]\n",
            "episode 149, iteration 227\n",
            "Action:  2\n",
            "Current state after Action:  [-0.05695803  0.0011655 ]\n",
            "episode 149, iteration 228\n",
            "q values:  tensor([[4.9768, 4.9881, 4.9179]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.05725612 -0.00029809]\n",
            "episode 149, iteration 229\n",
            "Action:  2\n",
            "Current state after Action:  [-0.05901742 -0.0017613 ]\n",
            "episode 149, iteration 230\n",
            "Action:  2\n",
            "Current state after Action:  [-0.06223964 -0.00322222]\n",
            "episode 149, iteration 231\n",
            "Action:  2\n",
            "Current state after Action:  [-0.06691841 -0.00467877]\n",
            "episode 149, iteration 232\n",
            "q values:  tensor([[4.9396, 4.9703, 4.9368]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.07404697 -0.00712856]\n",
            "episode 149, iteration 233\n",
            "Action:  1\n",
            "Current state after Action:  [-0.0836141  -0.00956713]\n",
            "episode 149, iteration 234\n",
            "Action:  1\n",
            "Current state after Action:  [-0.09560299 -0.01198889]\n",
            "episode 149, iteration 235\n",
            "Action:  1\n",
            "Current state after Action:  [-0.10998975 -0.01438677]\n",
            "episode 149, iteration 236\n",
            "q values:  tensor([[4.9389, 4.9541, 4.9446]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.12574165 -0.0157519 ]\n",
            "episode 149, iteration 237\n",
            "Action:  2\n",
            "Current state after Action:  [-0.14281777 -0.01707612]\n",
            "episode 149, iteration 238\n",
            "Action:  2\n",
            "Current state after Action:  [-0.16116792 -0.01835015]\n",
            "episode 149, iteration 239\n",
            "Action:  2\n",
            "Current state after Action:  [-0.18073149 -0.01956358]\n",
            "episode 149, iteration 240\n",
            "q values:  tensor([[4.9804, 4.9722, 4.9642]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.20243652 -0.02170502]\n",
            "episode 149, iteration 241\n",
            "Action:  1\n",
            "Current state after Action:  [-0.2261945  -0.02375799]\n",
            "episode 149, iteration 242\n",
            "Action:  1\n",
            "Current state after Action:  [-0.25189865 -0.02570414]\n",
            "episode 149, iteration 243\n",
            "Action:  1\n",
            "Current state after Action:  [-0.27942228 -0.02752363]\n",
            "episode 149, iteration 244\n",
            "q values:  tensor([[5.0192, 5.0902, 4.9591]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.30961779 -0.03019551]\n",
            "episode 149, iteration 245\n",
            "Action:  0\n",
            "Current state after Action:  [-0.34231018 -0.03269239]\n",
            "episode 149, iteration 246\n",
            "Action:  0\n",
            "Current state after Action:  [-0.37729619 -0.03498601]\n",
            "episode 149, iteration 247\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41434458 -0.03704839]\n",
            "episode 149, iteration 248\n",
            "q values:  tensor([[4.9093, 4.9264, 4.8978]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45219779 -0.0378532 ]\n",
            "episode 149, iteration 249\n",
            "Action:  1\n",
            "Current state after Action:  [-0.49058241 -0.03838463]\n",
            "episode 149, iteration 250\n",
            "Action:  1\n",
            "Current state after Action:  [-0.52921426 -0.03863184]\n",
            "episode 149, iteration 251\n",
            "Action:  1\n",
            "Current state after Action:  [-0.56780398 -0.03858973]\n",
            "episode 149, iteration 252\n",
            "q values:  tensor([[4.9020, 4.8995, 4.7815]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.60506315 -0.03725916]\n",
            "episode 149, iteration 253\n",
            "Action:  2\n",
            "Current state after Action:  [-0.64071739 -0.03565424]\n",
            "episode 149, iteration 254\n",
            "Action:  2\n",
            "Current state after Action:  [-0.6745112  -0.03379381]\n",
            "episode 149, iteration 255\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70621145 -0.03170024]\n",
            "episode 149, iteration 256\n",
            "q values:  tensor([[4.3494, 4.4345, 4.3552]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.73660958 -0.03039814]\n",
            "episode 149, iteration 257\n",
            "Action:  1\n",
            "Current state after Action:  [-0.76551667 -0.02890709]\n",
            "episode 149, iteration 258\n",
            "Action:  1\n",
            "Current state after Action:  [-0.79276451 -0.02724784]\n",
            "episode 149, iteration 259\n",
            "Action:  1\n",
            "Current state after Action:  [-0.81820595 -0.02544144]\n",
            "episode 149, iteration 260\n",
            "q values:  tensor([[4.9476, 4.9486, 4.9464]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.84271447 -0.02450852]\n",
            "episode 149, iteration 261\n",
            "Action:  0\n",
            "Current state after Action:  [-0.86617883 -0.02346435]\n",
            "episode 149, iteration 262\n",
            "Action:  0\n",
            "Current state after Action:  [-0.88850284 -0.02232402]\n",
            "episode 149, iteration 263\n",
            "Action:  0\n",
            "Current state after Action:  [-0.90960487 -0.02110203]\n",
            "episode 149, iteration 264\n",
            "q values:  tensor([[4.8521, 4.9127, 4.8794]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.92841688 -0.018812  ]\n",
            "episode 149, iteration 265\n",
            "Action:  1\n",
            "Current state after Action:  [-0.94488593 -0.01646906]\n",
            "episode 149, iteration 266\n",
            "Action:  1\n",
            "Current state after Action:  [-0.95897183 -0.0140859 ]\n",
            "episode 149, iteration 267\n",
            "Action:  1\n",
            "Current state after Action:  [-0.97064478 -0.01167295]\n",
            "episode 149, iteration 268\n",
            "q values:  tensor([[4.8977, 4.9341, 4.8595]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.97988337 -0.00923859]\n",
            "episode 149, iteration 269\n",
            "Action:  1\n",
            "Current state after Action:  [-0.98667277 -0.0067894 ]\n",
            "episode 149, iteration 270\n",
            "Action:  1\n",
            "Current state after Action:  [-0.99100326 -0.00433049]\n",
            "episode 149, iteration 271\n",
            "Action:  1\n",
            "Current state after Action:  [-0.9928692  -0.00186594]\n",
            "episode 149, iteration 272\n",
            "q values:  tensor([[4.9990, 5.0025, 5.0617]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.99126827  0.00160093]\n",
            "episode 149, iteration 273\n",
            "Action:  2\n",
            "Current state after Action:  [-0.98620244  0.00506582]\n",
            "episode 149, iteration 274\n",
            "Action:  2\n",
            "Current state after Action:  [-0.97767835  0.00852409]\n",
            "episode 149, iteration 275\n",
            "Action:  2\n",
            "Current state after Action:  [-0.96570844  0.01196991]\n",
            "episode 149, iteration 276\n",
            "q values:  tensor([[4.9920, 4.9878, 4.9868]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.95131286  0.01439558]\n",
            "episode 149, iteration 277\n",
            "Action:  1\n",
            "Current state after Action:  [-0.93452     0.01679286]\n",
            "episode 149, iteration 278\n",
            "Action:  1\n",
            "Current state after Action:  [-0.91536862  0.01915138]\n",
            "episode 149, iteration 279\n",
            "Action:  1\n",
            "Current state after Action:  [-0.89391022  0.0214584 ]\n",
            "episode 149, iteration 280\n",
            "q values:  tensor([[3.5682, 3.4654, 3.3382]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.87021153  0.02369869]\n",
            "episode 149, iteration 281\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84435703  0.02585449]\n",
            "episode 149, iteration 282\n",
            "Action:  1\n",
            "Current state after Action:  [-0.8164513   0.02790573]\n",
            "episode 149, iteration 283\n",
            "Action:  1\n",
            "Current state after Action:  [-0.78662103  0.02983028]\n",
            "episode 149, iteration 284\n",
            "q values:  tensor([[4.9118, 4.8380, 4.8864]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.75601651  0.03060452]\n",
            "episode 149, iteration 285\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7248067  0.0312098]\n",
            "episode 149, iteration 286\n",
            "Action:  0\n",
            "Current state after Action:  [-0.69317783  0.03162888]\n",
            "episode 149, iteration 287\n",
            "Action:  0\n",
            "Current state after Action:  [-0.66133126  0.03184656]\n",
            "episode 149, iteration 288\n",
            "q values:  tensor([[5.0130, 5.0846, 5.0525]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62948085  0.03185041]\n",
            "episode 149, iteration 289\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59784961  0.03163124]\n",
            "episode 149, iteration 290\n",
            "Action:  0\n",
            "Current state after Action:  [-0.56666608  0.03118353]\n",
            "episode 149, iteration 291\n",
            "Action:  0\n",
            "Current state after Action:  [-0.53616044  0.03050564]\n",
            "episode 149, iteration 292\n",
            "q values:  tensor([[4.9606, 5.0254, 4.8843]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.50656061  0.02959983]\n",
            "episode 149, iteration 293\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47808852  0.0284721 ]\n",
            "episode 149, iteration 294\n",
            "Action:  0\n",
            "Current state after Action:  [-0.45095669  0.02713183]\n",
            "episode 149, iteration 295\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42536537  0.02559132]\n",
            "episode 149, iteration 296\n",
            "q values:  tensor([[4.9846, 4.9836, 4.9876]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.40050019  0.02486518]\n",
            "episode 149, iteration 297\n",
            "Action:  1\n",
            "Current state after Action:  [-0.3765374   0.02396279]\n",
            "episode 149, iteration 298\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35364214  0.02289526]\n",
            "episode 149, iteration 299\n",
            "Action:  1\n",
            "Current state after Action:  [-0.33196704  0.0216751 ]\n",
            "episode 149, iteration 300\n",
            "q values:  tensor([[4.9209, 4.8801, 4.9115]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.31265131  0.01931573]\n",
            "episode 149, iteration 301\n",
            "Action:  0\n",
            "Current state after Action:  [-0.29581418  0.01683714]\n",
            "episode 149, iteration 302\n",
            "Action:  0\n",
            "Current state after Action:  [-0.28155553  0.01425864]\n",
            "episode 149, iteration 303\n",
            "Action:  0\n",
            "Current state after Action:  [-0.26995684  0.01159869]\n",
            "episode 149, iteration 304\n",
            "q values:  tensor([[4.9448, 4.9328, 4.9250]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.26108213  0.00887471]\n",
            "episode 149, iteration 305\n",
            "Action:  0\n",
            "Current state after Action:  [-0.25497899  0.00610314]\n",
            "episode 149, iteration 306\n",
            "Action:  0\n",
            "Current state after Action:  [-0.25167941  0.00329958]\n",
            "episode 149, iteration 307\n",
            "Action:  0\n",
            "Current state after Action:  [-0.25120045  0.00047897]\n",
            "episode 149, iteration 308\n",
            "q values:  tensor([[4.8899, 4.9074, 4.9166]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.25254455 -0.00134411]\n",
            "episode 149, iteration 309\n",
            "Action:  1\n",
            "Current state after Action:  [-0.25570482 -0.00316027]\n",
            "episode 149, iteration 310\n",
            "Action:  1\n",
            "Current state after Action:  [-0.26066488 -0.00496006]\n",
            "episode 149, iteration 311\n",
            "Action:  1\n",
            "Current state after Action:  [-0.26739872 -0.00673383]\n",
            "episode 149, iteration 312\n",
            "q values:  tensor([[4.8808, 5.0027, 4.9821]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.27587037 -0.00847166]\n",
            "episode 149, iteration 313\n",
            "Action:  1\n",
            "Current state after Action:  [-0.28603362 -0.01016325]\n",
            "episode 149, iteration 314\n",
            "Action:  1\n",
            "Current state after Action:  [-0.29783156 -0.01179794]\n",
            "episode 149, iteration 315\n",
            "Action:  1\n",
            "Current state after Action:  [-0.31119623 -0.01336467]\n",
            "episode 149, iteration 316\n",
            "q values:  tensor([[4.9677, 4.9229, 4.9125]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.32504828 -0.01385205]\n",
            "episode 149, iteration 317\n",
            "Action:  2\n",
            "Current state after Action:  [-0.33930295 -0.01425467]\n",
            "episode 149, iteration 318\n",
            "Action:  2\n",
            "Current state after Action:  [-0.35387049 -0.01456754]\n",
            "episode 149, iteration 319\n",
            "Action:  2\n",
            "Current state after Action:  [-0.3686567 -0.0147862]\n",
            "episode 149, iteration 320\n",
            "q values:  tensor([[4.8821, 4.8846, 4.8962]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.38556357 -0.01690687]\n",
            "episode 149, iteration 321\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40447637 -0.0189128 ]\n",
            "episode 149, iteration 322\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42526369 -0.02078732]\n",
            "episode 149, iteration 323\n",
            "Action:  0\n",
            "Current state after Action:  [-0.44777788 -0.02251419]\n",
            "episode 149, iteration 324\n",
            "q values:  tensor([[4.9828, 4.9753, 5.0123]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47185583 -0.02407795]\n",
            "episode 149, iteration 325\n",
            "Action:  0\n",
            "Current state after Action:  [-0.4973203  -0.02546447]\n",
            "episode 149, iteration 326\n",
            "Action:  0\n",
            "Current state after Action:  [-0.52398165 -0.02666135]\n",
            "episode 149, iteration 327\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55164013 -0.02765848]\n",
            "episode 149, iteration 328\n",
            "q values:  tensor([[4.9731, 4.9727, 5.0185]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.57908854 -0.02744842]\n",
            "episode 149, iteration 329\n",
            "Action:  1\n",
            "Current state after Action:  [-0.60612271 -0.02703416]\n",
            "episode 149, iteration 330\n",
            "Action:  1\n",
            "Current state after Action:  [-0.63254425 -0.02642154]\n",
            "episode 149, iteration 331\n",
            "Action:  1\n",
            "Current state after Action:  [-0.65816316 -0.02561892]\n",
            "episode 149, iteration 332\n",
            "q values:  tensor([[4.9904, 4.9822, 4.9663]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.68380003 -0.02563687]\n",
            "episode 149, iteration 333\n",
            "Action:  0\n",
            "Current state after Action:  [-0.70928112 -0.02548109]\n",
            "episode 149, iteration 334\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7344405  -0.02515938]\n",
            "episode 149, iteration 335\n",
            "Action:  0\n",
            "Current state after Action:  [-0.75912192 -0.02468142]\n",
            "episode 149, iteration 336\n",
            "q values:  tensor([[4.9707, 4.9410, 4.9712]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.78218028 -0.02305835]\n",
            "episode 149, iteration 337\n",
            "Action:  1\n",
            "Current state after Action:  [-0.80348801 -0.02130773]\n",
            "episode 149, iteration 338\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82293469 -0.01944668]\n",
            "episode 149, iteration 339\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84042615 -0.01749146]\n",
            "episode 149, iteration 340\n",
            "q values:  tensor([[4.9327, 4.9721, 5.0131]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85588337 -0.01545722]\n",
            "episode 149, iteration 341\n",
            "Action:  1\n",
            "Current state after Action:  [-0.86924118 -0.01335781]\n",
            "episode 149, iteration 342\n",
            "Action:  1\n",
            "Current state after Action:  [-0.88044687 -0.01120569]\n",
            "episode 149, iteration 343\n",
            "Action:  1\n",
            "Current state after Action:  [-0.88945891 -0.00901204]\n",
            "episode 149, iteration 344\n",
            "q values:  tensor([[4.9733, 4.9780, 4.9539]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.89524568 -0.00578677]\n",
            "episode 149, iteration 345\n",
            "Action:  2\n",
            "Current state after Action:  [-0.89778774 -0.00254206]\n",
            "episode 149, iteration 346\n",
            "Action:  2\n",
            "Current state after Action:  [-8.97076764e-01  7.10979988e-04]\n",
            "episode 149, iteration 347\n",
            "Action:  2\n",
            "Current state after Action:  [-0.89311506  0.0039617 ]\n",
            "episode 149, iteration 348\n",
            "q values:  tensor([[4.9517, 4.9141, 4.9925]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.88591573  0.00719933]\n",
            "episode 149, iteration 349\n",
            "Action:  2\n",
            "Current state after Action:  [-0.87550336  0.01041237]\n",
            "episode 149, iteration 350\n",
            "Action:  2\n",
            "Current state after Action:  [-0.86191536  0.013588  ]\n",
            "episode 149, iteration 351\n",
            "Action:  2\n",
            "Current state after Action:  [-0.84520373  0.01671163]\n",
            "episode 149, iteration 352\n",
            "q values:  tensor([[4.9427, 4.9381, 4.9547]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82643724  0.01876649]\n",
            "episode 149, iteration 353\n",
            "Action:  1\n",
            "Current state after Action:  [-0.80569927  0.02073797]\n",
            "episode 149, iteration 354\n",
            "Action:  1\n",
            "Current state after Action:  [-0.78308922  0.02261006]\n",
            "episode 149, iteration 355\n",
            "Action:  1\n",
            "Current state after Action:  [-0.75872368  0.02436553]\n",
            "episode 149, iteration 356\n",
            "q values:  tensor([[4.8841, 4.8201, 4.8757]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.73173735  0.02698633]\n",
            "episode 149, iteration 357\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70228946  0.02944789]\n",
            "episode 149, iteration 358\n",
            "Action:  2\n",
            "Current state after Action:  [-0.67056466  0.0317248 ]\n",
            "episode 149, iteration 359\n",
            "Action:  2\n",
            "Current state after Action:  [-0.63677298  0.03379168]\n",
            "episode 149, iteration 360\n",
            "q values:  tensor([[4.9439, 4.9712, 4.9259]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.60114871  0.03562427]\n",
            "episode 149, iteration 361\n",
            "Action:  2\n",
            "Current state after Action:  [-0.56394805  0.03720066]\n",
            "episode 149, iteration 362\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52544551  0.03850254]\n",
            "episode 149, iteration 363\n",
            "Action:  2\n",
            "Current state after Action:  [-0.48592911  0.03951639]\n",
            "episode 149, iteration 364\n",
            "q values:  tensor([[4.8359, 4.9670, 4.9655]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.44569464  0.04023447]\n",
            "episode 149, iteration 365\n",
            "Action:  2\n",
            "Current state after Action:  [-0.40503915  0.0406555 ]\n",
            "episode 149, iteration 366\n",
            "Action:  2\n",
            "Current state after Action:  [-0.36425422  0.04078493]\n",
            "episode 149, iteration 367\n",
            "Action:  2\n",
            "Current state after Action:  [-0.32361938  0.04063484]\n",
            "episode 149, iteration 368\n",
            "q values:  tensor([[4.9559, 4.9800, 4.9365]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.28439601  0.03922336]\n",
            "episode 149, iteration 369\n",
            "Action:  1\n",
            "Current state after Action:  [-0.24681661  0.0375794 ]\n",
            "episode 149, iteration 370\n",
            "Action:  1\n",
            "Current state after Action:  [-0.21108262  0.03573399]\n",
            "episode 149, iteration 371\n",
            "Action:  1\n",
            "Current state after Action:  [-0.17736391  0.03371871]\n",
            "episode 149, iteration 372\n",
            "q values:  tensor([[5.0270, 4.9266, 4.8725]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.14679956  0.03056435]\n",
            "episode 149, iteration 373\n",
            "Action:  0\n",
            "Current state after Action:  [-0.11949667  0.02730289]\n",
            "episode 149, iteration 374\n",
            "Action:  0\n",
            "Current state after Action:  [-0.09553485  0.02396182]\n",
            "episode 149, iteration 375\n",
            "Action:  0\n",
            "Current state after Action:  [-0.07497105  0.0205638 ]\n",
            "episode 149, iteration 376\n",
            "q values:  tensor([[4.9653, 4.9349, 4.9382]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.05784428  0.01712676]\n",
            "episode 149, iteration 377\n",
            "Action:  0\n",
            "Current state after Action:  [-0.04417997  0.01366431]\n",
            "episode 149, iteration 378\n",
            "Action:  0\n",
            "Current state after Action:  [-0.03399373  0.01018624]\n",
            "episode 149, iteration 379\n",
            "Action:  0\n",
            "Current state after Action:  [-0.0272945   0.00669923]\n",
            "episode 149, iteration 380\n",
            "q values:  tensor([[5.1215, 4.9493, 4.9297]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.0240869  0.0032076]\n",
            "episode 149, iteration 381\n",
            "Action:  0\n",
            "Current state after Action:  [-0.02437277 -0.00028587]\n",
            "episode 149, iteration 382\n",
            "Action:  0\n",
            "Current state after Action:  [-0.02815196 -0.00377919]\n",
            "episode 149, iteration 383\n",
            "Action:  0\n",
            "Current state after Action:  [-0.03542224 -0.00727028]\n",
            "episode 149, iteration 384\n",
            "q values:  tensor([[4.9871, 4.9526, 5.0418]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.04617842 -0.01075618]\n",
            "episode 149, iteration 385\n",
            "Action:  0\n",
            "Current state after Action:  [-0.06041065 -0.01423223]\n",
            "episode 149, iteration 386\n",
            "Action:  0\n",
            "Current state after Action:  [-0.07810193 -0.01769128]\n",
            "episode 149, iteration 387\n",
            "Action:  0\n",
            "Current state after Action:  [-0.0992249  -0.02112297]\n",
            "episode 149, iteration 388\n",
            "q values:  tensor([[4.9435, 4.8629, 4.9671]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.12273793 -0.02351302]\n",
            "episode 149, iteration 389\n",
            "Action:  1\n",
            "Current state after Action:  [-0.14858338 -0.02584545]\n",
            "episode 149, iteration 390\n",
            "Action:  1\n",
            "Current state after Action:  [-0.17668455 -0.02810117]\n",
            "episode 149, iteration 391\n",
            "Action:  1\n",
            "Current state after Action:  [-0.20694268 -0.03025812]\n",
            "episode 149, iteration 392\n",
            "q values:  tensor([[4.8034, 4.8976, 4.8365]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.23923429 -0.03229162]\n",
            "episode 149, iteration 393\n",
            "Action:  1\n",
            "Current state after Action:  [-0.2734092  -0.03417491]\n",
            "episode 149, iteration 394\n",
            "Action:  1\n",
            "Current state after Action:  [-0.30928925 -0.03588005]\n",
            "episode 149, iteration 395\n",
            "Action:  1\n",
            "Current state after Action:  [-0.34666816 -0.0373789 ]\n",
            "episode 149, iteration 396\n",
            "q values:  tensor([[4.9766, 4.9743, 4.9897]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.3853126  -0.03864444]\n",
            "episode 149, iteration 397\n",
            "Action:  1\n",
            "Current state after Action:  [-0.42496469 -0.0396521 ]\n",
            "episode 149, iteration 398\n",
            "Action:  1\n",
            "Current state after Action:  [-0.4653458 -0.0403811]\n",
            "episode 149, iteration 399\n",
            "Action:  1\n",
            "Current state after Action:  [-0.50616158 -0.04081578]\n",
            "episode 149, iteration 400\n",
            "q values:  tensor([[5.0484, 5.0031, 5.1235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.54810808 -0.0419465 ]\n",
            "episode 149, iteration 401\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59087092 -0.04276284]\n",
            "episode 149, iteration 402\n",
            "Action:  0\n",
            "Current state after Action:  [-0.63413264 -0.04326172]\n",
            "episode 149, iteration 403\n",
            "Action:  0\n",
            "Current state after Action:  [-0.67758047 -0.04344783]\n",
            "episode 149, iteration 404\n",
            "q values:  tensor([[4.9523, 4.9218, 4.9384]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.71891407 -0.0413336 ]\n",
            "episode 149, iteration 405\n",
            "Action:  2\n",
            "Current state after Action:  [-0.7578652  -0.03895113]\n",
            "episode 149, iteration 406\n",
            "Action:  2\n",
            "Current state after Action:  [-0.79420045 -0.03633524]\n",
            "episode 149, iteration 407\n",
            "Action:  2\n",
            "Current state after Action:  [-0.82772186 -0.03352142]\n",
            "episode 149, iteration 408\n",
            "q values:  tensor([[4.9608, 4.9560, 4.9405]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85926589 -0.03154403]\n",
            "episode 149, iteration 409\n",
            "Action:  1\n",
            "Current state after Action:  [-0.88869683 -0.02943094]\n",
            "episode 149, iteration 410\n",
            "Action:  1\n",
            "Current state after Action:  [-0.91590512 -0.02720829]\n",
            "episode 149, iteration 411\n",
            "Action:  1\n",
            "Current state after Action:  [-0.94080483 -0.02489972]\n",
            "episode 149, iteration 412\n",
            "q values:  tensor([[5.0150, 4.9824, 5.0446]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.96333082 -0.02252598]\n",
            "episode 149, iteration 413\n",
            "Action:  1\n",
            "Current state after Action:  [-0.98343551 -0.02010469]\n",
            "episode 149, iteration 414\n",
            "Action:  1\n",
            "Current state after Action:  [-1.0010858  -0.01765029]\n",
            "episode 149, iteration 415\n",
            "Action:  1\n",
            "Current state after Action:  [-1.01625998 -0.01517418]\n",
            "episode 149, iteration 416\n",
            "q values:  tensor([[5.0470, 5.0647, 5.1061]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.02794491 -0.01168494]\n",
            "episode 149, iteration 417\n",
            "Action:  2\n",
            "Current state after Action:  [-1.03613402 -0.0081891 ]\n",
            "episode 149, iteration 418\n",
            "Action:  2\n",
            "Current state after Action:  [-1.0408245  -0.00469048]\n",
            "episode 149, iteration 419\n",
            "Action:  2\n",
            "Current state after Action:  [-1.04201544 -0.00119094]\n",
            "episode 149, iteration 420\n",
            "q values:  tensor([[4.9415, 4.9294, 4.9321]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.04070668  0.00130876]\n",
            "episode 149, iteration 421\n",
            "Action:  1\n",
            "Current state after Action:  [-1.03689839  0.00380829]\n",
            "episode 149, iteration 422\n",
            "Action:  1\n",
            "Current state after Action:  [-1.0305913   0.00630709]\n",
            "episode 149, iteration 423\n",
            "Action:  1\n",
            "Current state after Action:  [-1.02178731  0.00880399]\n",
            "episode 149, iteration 424\n",
            "q values:  tensor([[4.8590, 4.7771, 4.9288]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.01049058  0.01129673]\n",
            "episode 149, iteration 425\n",
            "Action:  1\n",
            "Current state after Action:  [-0.99670899  0.01378159]\n",
            "episode 149, iteration 426\n",
            "Action:  1\n",
            "Current state after Action:  [-0.98045602  0.01625297]\n",
            "episode 149, iteration 427\n",
            "Action:  1\n",
            "Current state after Action:  [-0.961753    0.01870302]\n",
            "episode 149, iteration 428\n",
            "q values:  tensor([[5.0037, 4.9344, 5.0690]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.94163167  0.02012134]\n",
            "episode 149, iteration 429\n",
            "Action:  0\n",
            "Current state after Action:  [-0.92013466  0.02149701]\n",
            "episode 149, iteration 430\n",
            "Action:  0\n",
            "Current state after Action:  [-0.8973171   0.02281757]\n",
            "episode 149, iteration 431\n",
            "Action:  0\n",
            "Current state after Action:  [-0.87324802  0.02406907]\n",
            "episode 149, iteration 432\n",
            "q values:  tensor([[4.8928, 4.8904, 4.8120]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.8470117   0.02623632]\n",
            "episode 149, iteration 433\n",
            "Action:  1\n",
            "Current state after Action:  [-0.81871283  0.02829887]\n",
            "episode 149, iteration 434\n",
            "Action:  1\n",
            "Current state after Action:  [-0.78847863  0.0302342 ]\n",
            "episode 149, iteration 435\n",
            "Action:  1\n",
            "Current state after Action:  [-0.7564604   0.03201823]\n",
            "episode 149, iteration 436\n",
            "q values:  tensor([[4.8127, 4.9034, 4.8873]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.72283433  0.03362607]\n",
            "episode 149, iteration 437\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6878014   0.03503294]\n",
            "episode 149, iteration 438\n",
            "Action:  1\n",
            "Current state after Action:  [-0.65158615  0.03621525]\n",
            "episode 149, iteration 439\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6144344   0.03715174]\n",
            "episode 149, iteration 440\n",
            "q values:  tensor([[4.9586, 4.9578, 4.9745]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.57660979  0.03782461]\n",
            "episode 149, iteration 441\n",
            "Action:  1\n",
            "Current state after Action:  [-0.53838928  0.03822052]\n",
            "episode 149, iteration 442\n",
            "Action:  1\n",
            "Current state after Action:  [-0.50005787  0.03833141]\n",
            "episode 149, iteration 443\n",
            "Action:  1\n",
            "Current state after Action:  [-0.46190286  0.038155  ]\n",
            "episode 149, iteration 444\n",
            "q values:  tensor([[4.9466, 4.8947, 4.9560]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.42320795  0.03869492]\n",
            "episode 149, iteration 445\n",
            "Action:  2\n",
            "Current state after Action:  [-0.38425463  0.03895332]\n",
            "episode 149, iteration 446\n",
            "Action:  2\n",
            "Current state after Action:  [-0.34531622  0.03893841]\n",
            "episode 149, iteration 447\n",
            "Action:  2\n",
            "Current state after Action:  [-0.30665208  0.03866414]\n",
            "episode 149, iteration 448\n",
            "q values:  tensor([[5.0041, 5.0243, 4.9937]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.26850259  0.0381495 ]\n",
            "episode 149, iteration 449\n",
            "Action:  2\n",
            "Current state after Action:  [-0.23108495  0.03741764]\n",
            "episode 149, iteration 450\n",
            "Action:  2\n",
            "Current state after Action:  [-0.19459024  0.03649471]\n",
            "episode 149, iteration 451\n",
            "Action:  2\n",
            "Current state after Action:  [-0.15918151  0.03540873]\n",
            "episode 149, iteration 452\n",
            "q values:  tensor([[5.0286, 5.0016, 4.9841]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.12699309  0.03218842]\n",
            "episode 149, iteration 453\n",
            "Action:  0\n",
            "Current state after Action:  [-0.09812542  0.02886767]\n",
            "episode 149, iteration 454\n",
            "Action:  0\n",
            "Current state after Action:  [-0.07265021  0.02547521]\n",
            "episode 149, iteration 455\n",
            "Action:  0\n",
            "Current state after Action:  [-0.05061586  0.02203435]\n",
            "episode 149, iteration 456\n",
            "q values:  tensor([[4.7577, 4.7423, 4.7681]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.03005274  0.02056312]\n",
            "episode 149, iteration 457\n",
            "Action:  2\n",
            "Current state after Action:  [-0.01097947  0.01907327]\n",
            "episode 149, iteration 458\n",
            "Action:  2\n",
            "Current state after Action:  [0.00659516 0.01757463]\n",
            "episode 149, iteration 459\n",
            "Action:  2\n",
            "Current state after Action:  [0.02267027 0.01607512]\n",
            "episode 149, iteration 460\n",
            "q values:  tensor([[4.8678, 4.8944, 4.9746]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.03625117 0.0135809 ]\n",
            "episode 149, iteration 461\n",
            "Action:  1\n",
            "Current state after Action:  [0.04734684 0.01109567]\n",
            "episode 149, iteration 462\n",
            "Action:  1\n",
            "Current state after Action:  [0.05596768 0.00862084]\n",
            "episode 149, iteration 463\n",
            "Action:  1\n",
            "Current state after Action:  [0.06212368 0.006156  ]\n",
            "episode 149, iteration 464\n",
            "q values:  tensor([[4.9150, 4.9030, 4.9049]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.06582297 0.00369929]\n",
            "episode 149, iteration 465\n",
            "Action:  1\n",
            "Current state after Action:  [0.06707085 0.00124788]\n",
            "episode 149, iteration 466\n",
            "Action:  1\n",
            "Current state after Action:  [ 0.06586917 -0.00120169]\n",
            "episode 149, iteration 467\n",
            "Action:  1\n",
            "Current state after Action:  [ 0.06221613 -0.00365303]\n",
            "episode 149, iteration 468\n",
            "q values:  tensor([[4.9369, 5.0409, 4.9311]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.05510652 -0.00710961]\n",
            "episode 149, iteration 469\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.04453099 -0.01057553]\n",
            "episode 149, iteration 470\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.03047774 -0.01405325]\n",
            "episode 149, iteration 471\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.01293493 -0.01754281]\n",
            "episode 149, iteration 472\n",
            "q values:  tensor([[4.9619, 4.9449, 4.9901]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.00610599 -0.01904093]\n",
            "episode 149, iteration 473\n",
            "Action:  2\n",
            "Current state after Action:  [-0.0266465  -0.02054051]\n",
            "episode 149, iteration 474\n",
            "Action:  2\n",
            "Current state after Action:  [-0.04867903 -0.02203252]\n",
            "episode 149, iteration 475\n",
            "Action:  2\n",
            "Current state after Action:  [-0.07218494 -0.02350591]\n",
            "episode 149, iteration 476\n",
            "q values:  tensor([[4.9721, 4.9779, 4.9489]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.09913246 -0.02694752]\n",
            "episode 149, iteration 477\n",
            "Action:  0\n",
            "Current state after Action:  [-0.12947024 -0.03033778]\n",
            "episode 149, iteration 478\n",
            "Action:  0\n",
            "Current state after Action:  [-0.16312179 -0.03365156]\n",
            "episode 149, iteration 479\n",
            "Action:  0\n",
            "Current state after Action:  [-0.19997993 -0.03685814]\n",
            "episode 149, iteration 480\n",
            "q values:  tensor([[5.0021, 4.9998, 5.0132]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.23890149 -0.03892156]\n",
            "episode 149, iteration 481\n",
            "Action:  1\n",
            "Current state after Action:  [-0.27970799 -0.0408065 ]\n",
            "episode 149, iteration 482\n",
            "Action:  1\n",
            "Current state after Action:  [-0.32218477 -0.04247678]\n",
            "episode 149, iteration 483\n",
            "Action:  1\n",
            "Current state after Action:  [-0.3660819  -0.04389713]\n",
            "episode 149, iteration 484\n",
            "q values:  tensor([[4.9057, 4.9372, 4.9322]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.41011693 -0.04403503]\n",
            "episode 149, iteration 485\n",
            "Action:  2\n",
            "Current state after Action:  [-0.45398672 -0.04386979]\n",
            "episode 149, iteration 486\n",
            "Action:  2\n",
            "Current state after Action:  [-0.49737482 -0.0433881 ]\n",
            "episode 149, iteration 487\n",
            "Action:  2\n",
            "Current state after Action:  [-0.5399594  -0.04258458]\n",
            "episode 149, iteration 488\n",
            "q values:  tensor([[5.0992, 4.9990, 5.0449]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.58342132 -0.04346192]\n",
            "episode 149, iteration 489\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62743697 -0.04401566]\n",
            "episode 149, iteration 490\n",
            "Action:  0\n",
            "Current state after Action:  [-0.67168638 -0.0442494 ]\n",
            "episode 149, iteration 491\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7158613  -0.04417492]\n",
            "episode 149, iteration 492\n",
            "q values:  tensor([[2.6018, 2.4145, 2.2309]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.75767289 -0.04181159]\n",
            "episode 149, iteration 493\n",
            "Action:  2\n",
            "Current state after Action:  [-0.79686968 -0.0391968 ]\n",
            "episode 149, iteration 494\n",
            "Action:  2\n",
            "Current state after Action:  [-0.83323894 -0.03636925]\n",
            "episode 149, iteration 495\n",
            "Action:  2\n",
            "Current state after Action:  [-0.86660576 -0.03336682]\n",
            "episode 149, iteration 496\n",
            "q values:  tensor([[5.0864, 5.0462, 5.1871]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.89783059 -0.03122483]\n",
            "episode 149, iteration 497\n",
            "Action:  1\n",
            "Current state after Action:  [-0.92680224 -0.02897165]\n",
            "episode 149, iteration 498\n",
            "Action:  1\n",
            "Current state after Action:  [-0.9534352  -0.02663296]\n",
            "episode 149, iteration 499\n",
            "Action:  1\n",
            "Current state after Action:  [-0.97766641 -0.02423121]\n",
            "episode 149, iteration 500\n",
            "q values:  tensor([[5.0053, 4.9810, 5.0098]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.00045181 -0.0227854 ]\n",
            "episode 149, iteration 501\n",
            "Action:  0\n",
            "Current state after Action:  [-1.02176175 -0.02130994]\n",
            "episode 149, iteration 502\n",
            "Action:  0\n",
            "Current state after Action:  [-1.04157897 -0.01981722]\n",
            "episode 149, iteration 503\n",
            "Action:  0\n",
            "Current state after Action:  [-1.05989655 -0.01831757]\n",
            "episode 149, iteration 504\n",
            "q values:  tensor([[5.1792, 5.1589, 5.2042]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.07571594 -0.01581939]\n",
            "episode 149, iteration 505\n",
            "Action:  1\n",
            "Current state after Action:  [-1.08904447 -0.01332853]\n",
            "episode 149, iteration 506\n",
            "Action:  1\n",
            "Current state after Action:  [-1.09989268 -0.01084821]\n",
            "episode 149, iteration 507\n",
            "Action:  1\n",
            "Current state after Action:  [-1.10827206 -0.00837938]\n",
            "episode 149, iteration 508\n",
            "q values:  tensor([[5.2937, 5.2715, 5.3278]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.11319328 -0.00492123]\n",
            "episode 149, iteration 509\n",
            "Action:  2\n",
            "Current state after Action:  [-1.11466335 -0.00147007]\n",
            "episode 149, iteration 510\n",
            "Action:  2\n",
            "Current state after Action:  [-1.11268445  0.0019789 ]\n",
            "episode 149, iteration 511\n",
            "Action:  2\n",
            "Current state after Action:  [-1.10725364  0.00543081]\n",
            "episode 149, iteration 512\n",
            "q values:  tensor([[5.1553, 5.2672, 5.2891]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.09936329  0.00789035]\n",
            "episode 149, iteration 513\n",
            "Action:  1\n",
            "Current state after Action:  [-1.0890035   0.01035979]\n",
            "episode 149, iteration 514\n",
            "Action:  1\n",
            "Current state after Action:  [-1.07616334  0.01284016]\n",
            "episode 149, iteration 515\n",
            "Action:  1\n",
            "Current state after Action:  [-1.06083261  0.01533072]\n",
            "episode 149, iteration 516\n",
            "q values:  tensor([[4.9553, 4.9466, 4.9241]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.04200398  0.01882863]\n",
            "episode 149, iteration 517\n",
            "Action:  2\n",
            "Current state after Action:  [-1.01967565  0.02232833]\n",
            "episode 149, iteration 518\n",
            "Action:  2\n",
            "Current state after Action:  [-0.99385584  0.02581981]\n",
            "episode 149, iteration 519\n",
            "Action:  2\n",
            "Current state after Action:  [-0.96456797  0.02928787]\n",
            "episode 149, iteration 520\n",
            "q values:  tensor([[5.0014, 4.9535, 4.9060]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.93285652  0.03171145]\n",
            "episode 149, iteration 521\n",
            "Action:  1\n",
            "Current state after Action:  [-0.89879071  0.03406581]\n",
            "episode 149, iteration 522\n",
            "Action:  1\n",
            "Current state after Action:  [-0.86246861  0.0363221 ]\n",
            "episode 149, iteration 523\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82402069  0.03844792]\n",
            "episode 149, iteration 524\n",
            "q values:  tensor([[4.8912, 4.7782, 4.8904]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.78461249  0.0394082 ]\n",
            "episode 149, iteration 525\n",
            "Action:  0\n",
            "Current state after Action:  [-0.74444069  0.0401718 ]\n",
            "episode 149, iteration 526\n",
            "Action:  0\n",
            "Current state after Action:  [-0.70373112  0.04070957]\n",
            "episode 149, iteration 527\n",
            "Action:  0\n",
            "Current state after Action:  [-0.66273535  0.04099576]\n",
            "episode 149, iteration 528\n",
            "q values:  tensor([[4.9484, 5.0355, 4.9939]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.62072611  0.04200925]\n",
            "episode 149, iteration 529\n",
            "Action:  1\n",
            "Current state after Action:  [-0.57799867  0.04272744]\n",
            "episode 149, iteration 530\n",
            "Action:  1\n",
            "Current state after Action:  [-0.53486504  0.04313363]\n",
            "episode 149, iteration 531\n",
            "Action:  1\n",
            "Current state after Action:  [-0.49164693  0.04321811]\n",
            "episode 149, iteration 532\n",
            "q values:  tensor([[4.9322, 4.9812, 5.0343]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.44766809  0.04397884]\n",
            "episode 149, iteration 533\n",
            "Action:  2\n",
            "Current state after Action:  [-0.40325382  0.04441427]\n",
            "episode 149, iteration 534\n",
            "Action:  2\n",
            "Current state after Action:  [-0.35872265  0.04453116]\n",
            "episode 149, iteration 535\n",
            "Action:  2\n",
            "Current state after Action:  [-0.31437825  0.0443444 ]\n",
            "episode 149, iteration 536\n",
            "q values:  tensor([[4.8339, 5.0531, 4.9704]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.27150198  0.04287627]\n",
            "episode 149, iteration 537\n",
            "Action:  1\n",
            "Current state after Action:  [-0.23034128  0.0411607 ]\n",
            "episode 149, iteration 538\n",
            "Action:  1\n",
            "Current state after Action:  [-0.19110707  0.03923421]\n",
            "episode 149, iteration 539\n",
            "Action:  1\n",
            "Current state after Action:  [-0.15397311  0.03713395]\n",
            "episode 149, iteration 540\n",
            "q values:  tensor([[5.0158, 5.0366, 5.0377]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.12007716  0.03389596]\n",
            "episode 149, iteration 541\n",
            "Action:  0\n",
            "Current state after Action:  [-0.08952074  0.03055642]\n",
            "episode 149, iteration 542\n",
            "Action:  0\n",
            "Current state after Action:  [-0.0623747   0.02714604]\n",
            "episode 149, iteration 543\n",
            "Action:  0\n",
            "Current state after Action:  [-0.03868502  0.02368968]\n",
            "episode 149, iteration 544\n",
            "q values:  tensor([[4.8575, 4.8812, 4.8632]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.01847853  0.02020649]\n",
            "episode 149, iteration 545\n",
            "Action:  0\n",
            "Current state after Action:  [-0.00176819  0.01671033]\n",
            "episode 149, iteration 546\n",
            "Action:  0\n",
            "Current state after Action:  [0.01144218 0.01321037]\n",
            "episode 149, iteration 547\n",
            "Action:  0\n",
            "Current state after Action:  [0.02115402 0.00971184]\n",
            "episode 149, iteration 548\n",
            "q values:  tensor([[4.9963, 4.9943, 4.9453]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.02837089 0.00721688]\n",
            "episode 149, iteration 549\n",
            "Action:  1\n",
            "Current state after Action:  [0.03309682 0.00472592]\n",
            "episode 149, iteration 550\n",
            "Action:  1\n",
            "Current state after Action:  [0.03533506 0.00223824]\n",
            "episode 149, iteration 551\n",
            "Action:  1\n",
            "Current state after Action:  [ 0.03508733 -0.00024773]\n",
            "episode 149, iteration 552\n",
            "q values:  tensor([[4.8989, 4.8651, 4.8972]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.03135344 -0.00373389]\n",
            "episode 149, iteration 553\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.0241306  -0.00722284]\n",
            "episode 149, iteration 554\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.0134143  -0.01071629]\n",
            "episode 149, iteration 555\n",
            "Action:  0\n",
            "Current state after Action:  [-0.00079996 -0.01421427]\n",
            "episode 149, iteration 556\n",
            "q values:  tensor([[4.9478, 4.8550, 4.9497]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.01851423 -0.01771426]\n",
            "episode 149, iteration 557\n",
            "Action:  0\n",
            "Current state after Action:  [-0.03972463 -0.02121041]\n",
            "episode 149, iteration 558\n",
            "Action:  0\n",
            "Current state after Action:  [-0.06441731 -0.02469267]\n",
            "episode 149, iteration 559\n",
            "Action:  0\n",
            "Current state after Action:  [-0.09256344 -0.02814614]\n",
            "episode 149, iteration 560\n",
            "q values:  tensor([[5.0324, 5.0492, 5.0028]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.12311381 -0.03055036]\n",
            "episode 149, iteration 561\n",
            "Action:  1\n",
            "Current state after Action:  [-0.15599558 -0.03288178]\n",
            "episode 149, iteration 562\n",
            "Action:  1\n",
            "Current state after Action:  [-0.19110856 -0.03511297]\n",
            "episode 149, iteration 563\n",
            "Action:  1\n",
            "Current state after Action:  [-0.22832178 -0.03721323]\n",
            "episode 149, iteration 564\n",
            "q values:  tensor([[5.0150, 4.9750, 4.9866]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.26847111 -0.04014933]\n",
            "episode 149, iteration 565\n",
            "Action:  0\n",
            "Current state after Action:  [-0.31135248 -0.04288136]\n",
            "episode 149, iteration 566\n",
            "Action:  0\n",
            "Current state after Action:  [-0.35672028 -0.0453678 ]\n",
            "episode 149, iteration 567\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40428804 -0.04756776]\n",
            "episode 149, iteration 568\n",
            "q values:  tensor([[4.9256, 4.9708, 5.0061]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45273165 -0.04844361]\n",
            "episode 149, iteration 569\n",
            "Action:  1\n",
            "Current state after Action:  [-0.50170277 -0.04897112]\n",
            "episode 149, iteration 570\n",
            "Action:  1\n",
            "Current state after Action:  [-0.55083798 -0.04913522]\n",
            "episode 149, iteration 571\n",
            "Action:  1\n",
            "Current state after Action:  [-0.59976913 -0.04893115]\n",
            "episode 149, iteration 572\n",
            "q values:  tensor([[4.9617, 4.9143, 4.9233]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.64713397 -0.04736483]\n",
            "episode 149, iteration 573\n",
            "Action:  2\n",
            "Current state after Action:  [-0.69259335 -0.04545938]\n",
            "episode 149, iteration 574\n",
            "Action:  2\n",
            "Current state after Action:  [-0.73583888 -0.04324553]\n",
            "episode 149, iteration 575\n",
            "Action:  2\n",
            "Current state after Action:  [-0.776598   -0.04075912]\n",
            "episode 149, iteration 576\n",
            "q values:  tensor([[4.9809, 5.0047, 4.9921]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.81663663 -0.04003864]\n",
            "episode 149, iteration 577\n",
            "Action:  0\n",
            "Current state after Action:  [-0.85574983 -0.0391132 ]\n",
            "episode 149, iteration 578\n",
            "Action:  0\n",
            "Current state after Action:  [-0.89376416 -0.03801433]\n",
            "episode 149, iteration 579\n",
            "Action:  0\n",
            "Current state after Action:  [-0.93053869 -0.03677453]\n",
            "episode 149, iteration 580\n",
            "q values:  tensor([[4.9620, 4.9879, 4.9941]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.96396477 -0.03342608]\n",
            "episode 149, iteration 581\n",
            "Action:  2\n",
            "Current state after Action:  [-0.99396838 -0.03000361]\n",
            "episode 149, iteration 582\n",
            "Action:  2\n",
            "Current state after Action:  [-1.0205038  -0.02653542]\n",
            "episode 149, iteration 583\n",
            "Action:  2\n",
            "Current state after Action:  [-1.04354723 -0.02304343]\n",
            "episode 149, iteration 584\n",
            "q values:  tensor([[4.9951, 4.9273, 5.0122]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.06309081 -0.01954358]\n",
            "episode 149, iteration 585\n",
            "Action:  2\n",
            "Current state after Action:  [-1.07913723 -0.01604642]\n",
            "episode 149, iteration 586\n",
            "Action:  2\n",
            "Current state after Action:  [-1.09169512 -0.01255789]\n",
            "episode 149, iteration 587\n",
            "Action:  2\n",
            "Current state after Action:  [-1.10077525 -0.00908013]\n",
            "episode 149, iteration 588\n",
            "q values:  tensor([[5.3167, 5.2980, 5.3565]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.1073876  -0.00661236]\n",
            "episode 149, iteration 589\n",
            "Action:  1\n",
            "Current state after Action:  [-1.1115406 -0.004153 ]\n",
            "episode 149, iteration 590\n",
            "Action:  1\n",
            "Current state after Action:  [-1.11324004 -0.00169943]\n",
            "episode 149, iteration 591\n",
            "Action:  1\n",
            "Current state after Action:  [-1.11248838e+00  7.51659503e-04]\n",
            "episode 149, iteration 592\n",
            "q values:  tensor([[5.4420, 5.4696, 5.5232]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.11028452  0.00220386]\n",
            "episode 149, iteration 593\n",
            "Action:  0\n",
            "Current state after Action:  [-1.10662531  0.00365921]\n",
            "episode 149, iteration 594\n",
            "Action:  0\n",
            "Current state after Action:  [-1.10150572  0.00511959]\n",
            "episode 149, iteration 595\n",
            "Action:  0\n",
            "Current state after Action:  [-1.09491924  0.00658648]\n",
            "episode 149, iteration 596\n",
            "q values:  tensor([[4.9673, 5.0443, 5.1230]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.08585834  0.0090609 ]\n",
            "episode 149, iteration 597\n",
            "Action:  1\n",
            "Current state after Action:  [-1.07431423  0.01154411]\n",
            "episode 149, iteration 598\n",
            "Action:  1\n",
            "Current state after Action:  [-1.06027839  0.01403584]\n",
            "episode 149, iteration 599\n",
            "Action:  1\n",
            "Current state after Action:  [-1.04374447  0.01653392]\n",
            "episode 149, iteration 600\n",
            "q values:  tensor([[5.1210, 5.1953, 5.1097]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.02571069  0.01803378]\n",
            "episode 149, iteration 601\n",
            "Action:  0\n",
            "Current state after Action:  [-1.0061821   0.01952859]\n",
            "episode 149, iteration 602\n",
            "Action:  0\n",
            "Current state after Action:  [-0.98517241  0.02100969]\n",
            "episode 149, iteration 603\n",
            "Action:  0\n",
            "Current state after Action:  [-0.96270588  0.02246653]\n",
            "episode 149, iteration 604\n",
            "q values:  tensor([[4.9111, 4.7823, 4.8047]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.93781923  0.02488665]\n",
            "episode 149, iteration 605\n",
            "Action:  1\n",
            "Current state after Action:  [-0.91056597  0.02725326]\n",
            "episode 149, iteration 606\n",
            "Action:  1\n",
            "Current state after Action:  [-0.8810198   0.02954617]\n",
            "episode 149, iteration 607\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84927792  0.03174188]\n",
            "episode 149, iteration 608\n",
            "q values:  tensor([[5.0097, 4.9760, 5.0161]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.81646393  0.03281399]\n",
            "episode 149, iteration 609\n",
            "Action:  0\n",
            "Current state after Action:  [-0.78272533  0.0337386 ]\n",
            "episode 149, iteration 610\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7482332   0.03449213]\n",
            "episode 149, iteration 611\n",
            "Action:  0\n",
            "Current state after Action:  [-0.71318096  0.03505224]\n",
            "episode 149, iteration 612\n",
            "q values:  tensor([[5.0262, 5.0305, 5.0550]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.67678229  0.03639868]\n",
            "episode 149, iteration 613\n",
            "Action:  1\n",
            "Current state after Action:  [-0.63927475  0.03750754]\n",
            "episode 149, iteration 614\n",
            "Action:  1\n",
            "Current state after Action:  [-0.60091695  0.0383578 ]\n",
            "episode 149, iteration 615\n",
            "Action:  1\n",
            "Current state after Action:  [-0.56198445  0.0389325 ]\n",
            "episode 149, iteration 616\n",
            "q values:  tensor([[5.0148, 5.0892, 5.0154]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.52376469  0.03821976]\n",
            "episode 149, iteration 617\n",
            "Action:  0\n",
            "Current state after Action:  [-0.48654369  0.037221  ]\n",
            "episode 149, iteration 618\n",
            "Action:  0\n",
            "Current state after Action:  [-0.45060003  0.03594366]\n",
            "episode 149, iteration 619\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41619949  0.03440054]\n",
            "episode 149, iteration 620\n",
            "q values:  tensor([[5.0210, 5.0022, 4.9986]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.38259059  0.03360891]\n",
            "episode 149, iteration 621\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35000798  0.0325826 ]\n",
            "episode 149, iteration 622\n",
            "Action:  1\n",
            "Current state after Action:  [-0.31866925  0.03133873]\n",
            "episode 149, iteration 623\n",
            "Action:  1\n",
            "Current state after Action:  [-0.28877249  0.02989676]\n",
            "episode 149, iteration 624\n",
            "q values:  tensor([[5.0124, 5.0135, 5.0776]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.26049481  0.02827767]\n",
            "episode 149, iteration 625\n",
            "Action:  1\n",
            "Current state after Action:  [-0.23399181  0.026503  ]\n",
            "episode 149, iteration 626\n",
            "Action:  1\n",
            "Current state after Action:  [-0.20939773  0.02459408]\n",
            "episode 149, iteration 627\n",
            "Action:  1\n",
            "Current state after Action:  [-0.18682638  0.02257135]\n",
            "episode 149, iteration 628\n",
            "q values:  tensor([[4.8375, 4.9746, 4.8958]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.16537253  0.02145385]\n",
            "episode 149, iteration 629\n",
            "Action:  2\n",
            "Current state after Action:  [-0.14511727  0.02025526]\n",
            "episode 149, iteration 630\n",
            "Action:  2\n",
            "Current state after Action:  [-0.12612881  0.01898845]\n",
            "episode 149, iteration 631\n",
            "Action:  2\n",
            "Current state after Action:  [-0.10846351  0.0176653 ]\n",
            "episode 149, iteration 632\n",
            "q values:  tensor([[5.0702, 4.9772, 5.0851]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.09316703  0.01529649]\n",
            "episode 149, iteration 633\n",
            "Action:  1\n",
            "Current state after Action:  [-0.08027353  0.0128935 ]\n",
            "episode 149, iteration 634\n",
            "Action:  1\n",
            "Current state after Action:  [-0.06980788  0.01046565]\n",
            "episode 149, iteration 635\n",
            "Action:  1\n",
            "Current state after Action:  [-0.06178761  0.00802027]\n",
            "episode 149, iteration 636\n",
            "q values:  tensor([[4.9297, 4.9834, 5.0387]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.05622452  0.00556309]\n",
            "episode 149, iteration 637\n",
            "Action:  1\n",
            "Current state after Action:  [-0.05312594  0.00309857]\n",
            "episode 149, iteration 638\n",
            "Action:  1\n",
            "Current state after Action:  [-0.05249569  0.00063026]\n",
            "episode 149, iteration 639\n",
            "Action:  1\n",
            "Current state after Action:  [-0.05433449 -0.0018388 ]\n",
            "episode 149, iteration 640\n",
            "q values:  tensor([[4.9164, 4.9081, 4.9840]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.05764015 -0.00330566]\n",
            "episode 149, iteration 641\n",
            "Action:  2\n",
            "Current state after Action:  [-0.06240853 -0.00476838]\n",
            "episode 149, iteration 642\n",
            "Action:  2\n",
            "Current state after Action:  [-0.06863322 -0.00622469]\n",
            "episode 149, iteration 643\n",
            "Action:  2\n",
            "Current state after Action:  [-0.07630511 -0.00767188]\n",
            "episode 149, iteration 644\n",
            "q values:  tensor([[5.0747, 5.0164, 4.9905]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.08641177 -0.01010667]\n",
            "episode 149, iteration 645\n",
            "Action:  1\n",
            "Current state after Action:  [-0.09893491 -0.01252313]\n",
            "episode 149, iteration 646\n",
            "Action:  1\n",
            "Current state after Action:  [-0.11384873 -0.01491382]\n",
            "episode 149, iteration 647\n",
            "Action:  1\n",
            "Current state after Action:  [-0.13111815 -0.01726942]\n",
            "episode 149, iteration 648\n",
            "q values:  tensor([[4.9565, 4.9434, 4.9384]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.14969664 -0.01857849]\n",
            "episode 149, iteration 649\n",
            "Action:  2\n",
            "Current state after Action:  [-0.16952723 -0.0198306 ]\n",
            "episode 149, iteration 650\n",
            "Action:  2\n",
            "Current state after Action:  [-0.19054142 -0.02101419]\n",
            "episode 149, iteration 651\n",
            "Action:  2\n",
            "Current state after Action:  [-0.21265816 -0.02211674]\n",
            "episode 149, iteration 652\n",
            "q values:  tensor([[4.9456, 4.9449, 4.9268]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.23778316 -0.025125  ]\n",
            "episode 149, iteration 653\n",
            "Action:  0\n",
            "Current state after Action:  [-0.2657986  -0.02801544]\n",
            "episode 149, iteration 654\n",
            "Action:  0\n",
            "Current state after Action:  [-0.29656047 -0.03076187]\n",
            "episode 149, iteration 655\n",
            "Action:  0\n",
            "Current state after Action:  [-0.32989649 -0.03333602]\n",
            "episode 149, iteration 656\n",
            "q values:  tensor([[4.9717, 5.0848, 5.0150]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.36360488 -0.03370839]\n",
            "episode 149, iteration 657\n",
            "Action:  2\n",
            "Current state after Action:  [-0.39746768 -0.0338628 ]\n",
            "episode 149, iteration 658\n",
            "Action:  2\n",
            "Current state after Action:  [-0.43125405 -0.03378637]\n",
            "episode 149, iteration 659\n",
            "Action:  2\n",
            "Current state after Action:  [-0.46472418 -0.03347013]\n",
            "episode 149, iteration 660\n",
            "q values:  tensor([[4.9927, 4.9390, 4.9636]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.49963358 -0.0349094 ]\n",
            "episode 149, iteration 661\n",
            "Action:  0\n",
            "Current state after Action:  [-0.53572256 -0.03608898]\n",
            "episode 149, iteration 662\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57272063 -0.03699807]\n",
            "episode 149, iteration 663\n",
            "Action:  0\n",
            "Current state after Action:  [-0.61035162 -0.03763099]\n",
            "episode 149, iteration 664\n",
            "q values:  tensor([[4.8700, 4.9603, 5.0408]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.64733929 -0.03698766]\n",
            "episode 149, iteration 665\n",
            "Action:  1\n",
            "Current state after Action:  [-0.68342007 -0.03608078]\n",
            "episode 149, iteration 666\n",
            "Action:  1\n",
            "Current state after Action:  [-0.71834759 -0.03492752]\n",
            "episode 149, iteration 667\n",
            "Action:  1\n",
            "Current state after Action:  [-0.75189618 -0.03354859]\n",
            "episode 149, iteration 668\n",
            "q values:  tensor([[4.8771, 4.8268, 4.9112]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.7828633  -0.03096712]\n",
            "episode 149, iteration 669\n",
            "Action:  2\n",
            "Current state after Action:  [-0.81107615 -0.02821285]\n",
            "episode 149, iteration 670\n",
            "Action:  2\n",
            "Current state after Action:  [-0.83639043 -0.02531428]\n",
            "episode 149, iteration 671\n",
            "Action:  2\n",
            "Current state after Action:  [-0.85868821 -0.02229778]\n",
            "episode 149, iteration 672\n",
            "q values:  tensor([[4.9705, 4.9803, 4.9716]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.87887523 -0.02018702]\n",
            "episode 149, iteration 673\n",
            "Action:  1\n",
            "Current state after Action:  [-0.89687427 -0.01799904]\n",
            "episode 149, iteration 674\n",
            "Action:  1\n",
            "Current state after Action:  [-0.91262325 -0.01574898]\n",
            "episode 149, iteration 675\n",
            "Action:  1\n",
            "Current state after Action:  [-0.92607322 -0.01344997]\n",
            "episode 149, iteration 676\n",
            "q values:  tensor([[4.7953, 4.8006, 4.7984]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.93618643 -0.01011321]\n",
            "episode 149, iteration 677\n",
            "Action:  2\n",
            "Current state after Action:  [-0.942937   -0.00675057]\n",
            "episode 149, iteration 678\n",
            "Action:  2\n",
            "Current state after Action:  [-0.94630887 -0.00337187]\n",
            "episode 149, iteration 679\n",
            "Action:  2\n",
            "Current state after Action:  [-9.46294374e-01  1.44945644e-05]\n",
            "episode 149, iteration 680\n",
            "q values:  tensor([[4.9729, 4.8910, 4.8550]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.94489355  0.00140083]\n",
            "episode 149, iteration 681\n",
            "Action:  0\n",
            "Current state after Action:  [-0.94210955  0.002784  ]\n",
            "episode 149, iteration 682\n",
            "Action:  0\n",
            "Current state after Action:  [-0.93794876  0.00416079]\n",
            "episode 149, iteration 683\n",
            "Action:  0\n",
            "Current state after Action:  [-0.93242104  0.00552771]\n",
            "episode 149, iteration 684\n",
            "q values:  tensor([[5.0423, 5.0123, 5.0655]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.92454007  0.00788097]\n",
            "episode 149, iteration 685\n",
            "Action:  1\n",
            "Current state after Action:  [-0.91432646  0.01021362]\n",
            "episode 149, iteration 686\n",
            "Action:  1\n",
            "Current state after Action:  [-0.90180884  0.01251762]\n",
            "episode 149, iteration 687\n",
            "Action:  1\n",
            "Current state after Action:  [-0.88702528  0.01478356]\n",
            "episode 149, iteration 688\n",
            "q values:  tensor([[3.9289, 3.8066, 3.6688]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.87002483  0.01700045]\n",
            "episode 149, iteration 689\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85086928  0.01915555]\n",
            "episode 149, iteration 690\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82963497  0.02123431]\n",
            "episode 149, iteration 691\n",
            "Action:  1\n",
            "Current state after Action:  [-0.80641452  0.02322045]\n",
            "episode 149, iteration 692\n",
            "q values:  tensor([[4.9360, 4.9186, 4.9182]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.78231844  0.02409608]\n",
            "episode 149, iteration 693\n",
            "Action:  0\n",
            "Current state after Action:  [-0.75747099  0.02484744]\n",
            "episode 149, iteration 694\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73200992  0.02546108]\n",
            "episode 149, iteration 695\n",
            "Action:  0\n",
            "Current state after Action:  [-0.70608562  0.02592429]\n",
            "episode 149, iteration 696\n",
            "q values:  tensor([[4.9877, 5.0232, 5.0027]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.67986003  0.02622559]\n",
            "episode 149, iteration 697\n",
            "Action:  0\n",
            "Current state after Action:  [-0.65350493  0.0263551 ]\n",
            "episode 149, iteration 698\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62720002  0.02630492]\n",
            "episode 149, iteration 699\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60113054  0.02606948]\n",
            "episode 149, iteration 700\n",
            "q values:  tensor([[5.1158, 5.0313, 5.1161]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.5734848   0.02764574]\n",
            "episode 149, iteration 701\n",
            "Action:  2\n",
            "Current state after Action:  [-0.54446631  0.02901849]\n",
            "episode 149, iteration 702\n",
            "Action:  2\n",
            "Current state after Action:  [-0.51429142  0.03017489]\n",
            "episode 149, iteration 703\n",
            "Action:  2\n",
            "Current state after Action:  [-0.48318633  0.0311051 ]\n",
            "episode 149, iteration 704\n",
            "q values:  tensor([[5.0766, 4.9774, 5.0120]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.45338358  0.02980274]\n",
            "episode 149, iteration 705\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42510357  0.02828002]\n",
            "episode 149, iteration 706\n",
            "Action:  0\n",
            "Current state after Action:  [-0.39855156  0.026552  ]\n",
            "episode 149, iteration 707\n",
            "Action:  0\n",
            "Current state after Action:  [-0.37391557  0.02463599]\n",
            "episode 149, iteration 708\n",
            "q values:  tensor([[4.9894, 5.0518, 5.0118]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.35136485  0.02255072]\n",
            "episode 149, iteration 709\n",
            "Action:  0\n",
            "Current state after Action:  [-0.33104917  0.02031568]\n",
            "episode 149, iteration 710\n",
            "Action:  0\n",
            "Current state after Action:  [-0.31309862  0.01795054]\n",
            "episode 149, iteration 711\n",
            "Action:  0\n",
            "Current state after Action:  [-0.29762397  0.01547465]\n",
            "episode 149, iteration 712\n",
            "q values:  tensor([[5.0490, 4.9945, 4.9397]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.28371727  0.01390671]\n",
            "episode 149, iteration 713\n",
            "Action:  1\n",
            "Current state after Action:  [-0.27145835  0.01225891]\n",
            "episode 149, iteration 714\n",
            "Action:  1\n",
            "Current state after Action:  [-0.26091525  0.01054311]\n",
            "episode 149, iteration 715\n",
            "Action:  1\n",
            "Current state after Action:  [-0.25214459  0.00877066]\n",
            "episode 149, iteration 716\n",
            "q values:  tensor([[5.0295, 4.9975, 4.9937]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.24619215  0.00595244]\n",
            "episode 149, iteration 717\n",
            "Action:  0\n",
            "Current state after Action:  [-0.24308829  0.00310387]\n",
            "episode 149, iteration 718\n",
            "Action:  0\n",
            "Current state after Action:  [-2.42848583e-01  2.39705306e-04]\n",
            "episode 149, iteration 719\n",
            "Action:  0\n",
            "Current state after Action:  [-0.24547424 -0.00262565]\n",
            "episode 149, iteration 720\n",
            "q values:  tensor([[4.9396, 4.9500, 4.9618]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.24895208 -0.00347784]\n",
            "episode 149, iteration 721\n",
            "Action:  2\n",
            "Current state after Action:  [-0.25326449 -0.00431241]\n",
            "episode 149, iteration 722\n",
            "Action:  2\n",
            "Current state after Action:  [-0.25838935 -0.00512486]\n",
            "episode 149, iteration 723\n",
            "Action:  2\n",
            "Current state after Action:  [-0.26429997 -0.00591062]\n",
            "episode 149, iteration 724\n",
            "q values:  tensor([[5.0032, 5.1044, 4.9566]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.27296504 -0.00866507]\n",
            "episode 149, iteration 725\n",
            "Action:  0\n",
            "Current state after Action:  [-0.28433769 -0.01137265]\n",
            "episode 149, iteration 726\n",
            "Action:  0\n",
            "Current state after Action:  [-0.29835463 -0.01401694]\n",
            "episode 149, iteration 727\n",
            "Action:  0\n",
            "Current state after Action:  [-0.31493523 -0.01658061]\n",
            "episode 149, iteration 728\n",
            "q values:  tensor([[5.0136, 5.0689, 5.0282]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.33398059 -0.01904536]\n",
            "episode 149, iteration 729\n",
            "Action:  0\n",
            "Current state after Action:  [-0.35537262 -0.02139203]\n",
            "episode 149, iteration 730\n",
            "Action:  0\n",
            "Current state after Action:  [-0.37897347 -0.02360084]\n",
            "episode 149, iteration 731\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40462529 -0.02565182]\n",
            "episode 149, iteration 732\n",
            "q values:  tensor([[5.0248, 5.0152, 5.0715]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.43115058 -0.0265253 ]\n",
            "episode 149, iteration 733\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45836038 -0.0272098 ]\n",
            "episode 149, iteration 734\n",
            "Action:  1\n",
            "Current state after Action:  [-0.48605636 -0.02769597]\n",
            "episode 149, iteration 735\n",
            "Action:  1\n",
            "Current state after Action:  [-0.5140333  -0.02797695]\n",
            "episode 149, iteration 736\n",
            "q values:  tensor([[4.9534, 4.8909, 4.8605]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.54208198 -0.02804868]\n",
            "episode 149, iteration 737\n",
            "Action:  1\n",
            "Current state after Action:  [-0.56999211 -0.02791012]\n",
            "episode 149, iteration 738\n",
            "Action:  1\n",
            "Current state after Action:  [-0.5975554 -0.0275633]\n",
            "episode 149, iteration 739\n",
            "Action:  1\n",
            "Current state after Action:  [-0.62456856 -0.02701316]\n",
            "episode 149, iteration 740\n",
            "q values:  tensor([[4.9644, 4.8832, 4.9365]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.65183598 -0.02726742]\n",
            "episode 149, iteration 741\n",
            "Action:  0\n",
            "Current state after Action:  [-0.67916517 -0.02732919]\n",
            "episode 149, iteration 742\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7063695  -0.02720433]\n",
            "episode 149, iteration 743\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73327072 -0.02690121]\n",
            "episode 149, iteration 744\n",
            "q values:  tensor([[4.9463, 4.9641, 4.9909]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.75770106 -0.02443034]\n",
            "episode 149, iteration 745\n",
            "Action:  2\n",
            "Current state after Action:  [-0.77951645 -0.02181539]\n",
            "episode 149, iteration 746\n",
            "Action:  2\n",
            "Current state after Action:  [-0.79859554 -0.01907909]\n",
            "episode 149, iteration 747\n",
            "Action:  2\n",
            "Current state after Action:  [-0.81483828 -0.01624274]\n",
            "episode 149, iteration 748\n",
            "q values:  tensor([[5.0531, 4.9934, 5.0152]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.83016421 -0.01532593]\n",
            "episode 149, iteration 749\n",
            "Action:  0\n",
            "Current state after Action:  [-0.8445016  -0.01433739]\n",
            "episode 149, iteration 750\n",
            "Action:  0\n",
            "Current state after Action:  [-0.85778713 -0.01328553]\n",
            "episode 149, iteration 751\n",
            "Action:  0\n",
            "Current state after Action:  [-0.86996553 -0.0121784 ]\n",
            "episode 149, iteration 752\n",
            "q values:  tensor([[5.0357, 4.9990, 5.0149]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.87898906 -0.00902353]\n",
            "episode 149, iteration 753\n",
            "Action:  2\n",
            "Current state after Action:  [-0.8848242  -0.00583514]\n",
            "episode 149, iteration 754\n",
            "Action:  2\n",
            "Current state after Action:  [-0.88745013 -0.00262593]\n",
            "episode 149, iteration 755\n",
            "Action:  2\n",
            "Current state after Action:  [-8.86857695e-01  5.92433521e-04]\n",
            "episode 149, iteration 756\n",
            "q values:  tensor([[4.9603, 4.8903, 4.9505]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.88504895  0.00180874]\n",
            "episode 149, iteration 757\n",
            "Action:  0\n",
            "Current state after Action:  [-0.88203021  0.00301874]\n",
            "episode 149, iteration 758\n",
            "Action:  0\n",
            "Current state after Action:  [-0.87781214  0.00421807]\n",
            "episode 149, iteration 759\n",
            "Action:  0\n",
            "Current state after Action:  [-0.87240997  0.00540218]\n",
            "episode 149, iteration 760\n",
            "q values:  tensor([[5.0777, 5.0132, 5.0319]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.86484368  0.00756628]\n",
            "episode 149, iteration 761\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85514226  0.00970143]\n",
            "episode 149, iteration 762\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84334444  0.01179782]\n",
            "episode 149, iteration 763\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82949973  0.0138447 ]\n",
            "episode 149, iteration 764\n",
            "q values:  tensor([[4.9749, 4.9532, 4.9782]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.81266951  0.01683022]\n",
            "episode 149, iteration 765\n",
            "Action:  2\n",
            "Current state after Action:  [-0.79293297  0.01973654]\n",
            "episode 149, iteration 766\n",
            "Action:  2\n",
            "Current state after Action:  [-0.77038915  0.02254382]\n",
            "episode 149, iteration 767\n",
            "Action:  2\n",
            "Current state after Action:  [-0.74515893  0.02523022]\n",
            "episode 149, iteration 768\n",
            "q values:  tensor([[4.9803, 4.9898, 5.0590]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.71838669  0.02677224]\n",
            "episode 149, iteration 769\n",
            "Action:  1\n",
            "Current state after Action:  [-0.69023528  0.02815141]\n",
            "episode 149, iteration 770\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6608855   0.02934978]\n",
            "episode 149, iteration 771\n",
            "Action:  1\n",
            "Current state after Action:  [-0.63053494  0.03035056]\n",
            "episode 149, iteration 772\n",
            "q values:  tensor([[5.0158, 5.0630, 5.0936]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.59839604  0.0321389 ]\n",
            "episode 149, iteration 773\n",
            "Action:  2\n",
            "Current state after Action:  [-0.56470086  0.03369518]\n",
            "episode 149, iteration 774\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52969819  0.03500267]\n",
            "episode 149, iteration 775\n",
            "Action:  2\n",
            "Current state after Action:  [-0.49364978  0.03604841]\n",
            "episode 149, iteration 776\n",
            "q values:  tensor([[4.8174, 4.9291, 4.8705]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45782569  0.03582409]\n",
            "episode 149, iteration 777\n",
            "Action:  1\n",
            "Current state after Action:  [-0.4224917   0.03533399]\n",
            "episode 149, iteration 778\n",
            "Action:  1\n",
            "Current state after Action:  [-0.38790443  0.03458726]\n",
            "episode 149, iteration 779\n",
            "Action:  1\n",
            "Current state after Action:  [-0.354307    0.03359743]\n",
            "episode 149, iteration 780\n",
            "q values:  tensor([[4.8494, 4.9660, 5.0189]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.32092537  0.03338163]\n",
            "episode 149, iteration 781\n",
            "Action:  2\n",
            "Current state after Action:  [-0.28797186  0.03295352]\n",
            "episode 149, iteration 782\n",
            "Action:  2\n",
            "Current state after Action:  [-0.255642    0.03232986]\n",
            "episode 149, iteration 783\n",
            "Action:  2\n",
            "Current state after Action:  [-0.22411226  0.03152974]\n",
            "episode 149, iteration 784\n",
            "q values:  tensor([[4.9571, 4.9662, 5.0010]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.19353845  0.03057382]\n",
            "episode 149, iteration 785\n",
            "Action:  2\n",
            "Current state after Action:  [-0.16405494  0.0294835 ]\n",
            "episode 149, iteration 786\n",
            "Action:  2\n",
            "Current state after Action:  [-0.13577472  0.02828022]\n",
            "episode 149, iteration 787\n",
            "Action:  2\n",
            "Current state after Action:  [-0.10878996  0.02698476]\n",
            "episode 149, iteration 788\n",
            "q values:  tensor([[4.9309, 4.9153, 4.8893]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.08517323  0.02361673]\n",
            "episode 149, iteration 789\n",
            "Action:  0\n",
            "Current state after Action:  [-0.06497533  0.0201979 ]\n",
            "episode 149, iteration 790\n",
            "Action:  0\n",
            "Current state after Action:  [-0.04823008  0.01674525]\n",
            "episode 149, iteration 791\n",
            "Action:  0\n",
            "Current state after Action:  [-0.03495871  0.01327137]\n",
            "episode 149, iteration 792\n",
            "q values:  tensor([[5.0092, 4.9396, 4.9776]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.0251736   0.00978511]\n",
            "episode 149, iteration 793\n",
            "Action:  0\n",
            "Current state after Action:  [-0.01888137  0.00629223]\n",
            "episode 149, iteration 794\n",
            "Action:  0\n",
            "Current state after Action:  [-0.01608513  0.00279624]\n",
            "episode 149, iteration 795\n",
            "Action:  0\n",
            "Current state after Action:  [-0.01678598 -0.00070085]\n",
            "episode 149, iteration 796\n",
            "q values:  tensor([[5.0175, 4.9834, 4.9679]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.02098366 -0.00419768]\n",
            "episode 149, iteration 797\n",
            "Action:  0\n",
            "Current state after Action:  [-0.02867638 -0.00769273]\n",
            "episode 149, iteration 798\n",
            "Action:  0\n",
            "Current state after Action:  [-0.03985987 -0.01118348]\n",
            "episode 149, iteration 799\n",
            "Action:  0\n",
            "Current state after Action:  [-0.05452549 -0.01466563]\n",
            "episode 149, iteration 800\n",
            "q values:  tensor([[5.0449, 4.9580, 5.0039]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.07165775 -0.01713226]\n",
            "episode 149, iteration 801\n",
            "Action:  1\n",
            "Current state after Action:  [-0.09123246 -0.01957471]\n",
            "episode 149, iteration 802\n",
            "Action:  1\n",
            "Current state after Action:  [-0.11321412 -0.02198166]\n",
            "episode 149, iteration 803\n",
            "Action:  1\n",
            "Current state after Action:  [-0.13755296 -0.02433884]\n",
            "episode 149, iteration 804\n",
            "q values:  tensor([[5.0207, 4.9849, 4.9373]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.16518195 -0.02762899]\n",
            "episode 149, iteration 805\n",
            "Action:  0\n",
            "Current state after Action:  [-0.19601021 -0.03082826]\n",
            "episode 149, iteration 806\n",
            "Action:  0\n",
            "Current state after Action:  [-0.22991855 -0.03390835]\n",
            "episode 149, iteration 807\n",
            "Action:  0\n",
            "Current state after Action:  [-0.2667554  -0.03683685]\n",
            "episode 149, iteration 808\n",
            "q values:  tensor([[5.0562, 5.0449, 5.0472]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.30633354 -0.03957814]\n",
            "episode 149, iteration 809\n",
            "Action:  0\n",
            "Current state after Action:  [-0.34842822 -0.04209468]\n",
            "episode 149, iteration 810\n",
            "Action:  0\n",
            "Current state after Action:  [-0.39277704 -0.04434882]\n",
            "episode 149, iteration 811\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43908202 -0.04630498]\n",
            "episode 149, iteration 812\n",
            "q values:  tensor([[5.0178, 4.9866, 5.0339]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.48501411 -0.04593209]\n",
            "episode 149, iteration 813\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53023494 -0.04522083]\n",
            "episode 149, iteration 814\n",
            "Action:  2\n",
            "Current state after Action:  [-0.574406   -0.04417106]\n",
            "episode 149, iteration 815\n",
            "Action:  2\n",
            "Current state after Action:  [-0.61719748 -0.04279148]\n",
            "episode 149, iteration 816\n",
            "q values:  tensor([[4.9305, 4.9407, 5.0024]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.65829616 -0.04109868]\n",
            "episode 149, iteration 817\n",
            "Action:  2\n",
            "Current state after Action:  [-0.69741188 -0.03911572]\n",
            "episode 149, iteration 818\n",
            "Action:  2\n",
            "Current state after Action:  [-0.73428228 -0.0368704 ]\n",
            "episode 149, iteration 819\n",
            "Action:  2\n",
            "Current state after Action:  [-0.76867567 -0.0343934 ]\n",
            "episode 149, iteration 820\n",
            "q values:  tensor([[4.9502, 4.9514, 4.9281]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.80039217 -0.0317165 ]\n",
            "episode 149, iteration 821\n",
            "Action:  2\n",
            "Current state after Action:  [-0.8292632  -0.02887103]\n",
            "episode 149, iteration 822\n",
            "Action:  2\n",
            "Current state after Action:  [-0.85514979 -0.02588659]\n",
            "episode 149, iteration 823\n",
            "Action:  2\n",
            "Current state after Action:  [-0.87793996 -0.02279016]\n",
            "episode 149, iteration 824\n",
            "q values:  tensor([[4.9061, 4.8702, 4.8889]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.89754555 -0.01960559]\n",
            "episode 149, iteration 825\n",
            "Action:  2\n",
            "Current state after Action:  [-0.91389889 -0.01635334]\n",
            "episode 149, iteration 826\n",
            "Action:  2\n",
            "Current state after Action:  [-0.92694947 -0.01305058]\n",
            "episode 149, iteration 827\n",
            "Action:  2\n",
            "Current state after Action:  [-0.93666097 -0.0097115 ]\n",
            "episode 149, iteration 828\n",
            "q values:  tensor([[4.9808, 5.0223, 5.0282]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.94300867 -0.0063477 ]\n",
            "episode 149, iteration 829\n",
            "Action:  2\n",
            "Current state after Action:  [-0.9459775  -0.00296883]\n",
            "episode 149, iteration 830\n",
            "Action:  2\n",
            "Current state after Action:  [-9.45560713e-01  4.16789625e-04]\n",
            "episode 149, iteration 831\n",
            "Action:  2\n",
            "Current state after Action:  [-0.94175924  0.00380147]\n",
            "episode 149, iteration 832\n",
            "q values:  tensor([[5.0008, 4.9092, 4.9833]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.93458179  0.00717744]\n",
            "episode 149, iteration 833\n",
            "Action:  2\n",
            "Current state after Action:  [-0.92404567  0.01053612]\n",
            "episode 149, iteration 834\n",
            "Action:  2\n",
            "Current state after Action:  [-0.91017824  0.01386743]\n",
            "episode 149, iteration 835\n",
            "Action:  2\n",
            "Current state after Action:  [-0.89301907  0.01715918]\n",
            "episode 149, iteration 836\n",
            "q values:  tensor([[3.3232, 3.2029, 3.0670]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.87362258  0.01939649]\n",
            "episode 149, iteration 837\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85205744  0.02156513]\n",
            "episode 149, iteration 838\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82840861  0.02364883]\n",
            "episode 149, iteration 839\n",
            "Action:  1\n",
            "Current state after Action:  [-0.80277924  0.02562937]\n",
            "episode 149, iteration 840\n",
            "q values:  tensor([[4.9812, 5.0506, 5.0691]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.77529237  0.02748687]\n",
            "episode 149, iteration 841\n",
            "Action:  1\n",
            "Current state after Action:  [-0.74609213  0.02920024]\n",
            "episode 149, iteration 842\n",
            "Action:  1\n",
            "Current state after Action:  [-0.71534437  0.03074776]\n",
            "episode 149, iteration 843\n",
            "Action:  1\n",
            "Current state after Action:  [-0.68323653  0.03210784]\n",
            "episode 149, iteration 844\n",
            "q values:  tensor([[5.0391, 5.0594, 5.0644]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.65097664  0.03225988]\n",
            "episode 149, iteration 845\n",
            "Action:  0\n",
            "Current state after Action:  [-0.61878451  0.03219213]\n",
            "episode 149, iteration 846\n",
            "Action:  0\n",
            "Current state after Action:  [-0.58688814  0.03189636]\n",
            "episode 149, iteration 847\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55551996  0.03136819]\n",
            "episode 149, iteration 848\n",
            "q values:  tensor([[4.9634, 5.0207, 5.0235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52291273  0.03260723]\n",
            "episode 149, iteration 849\n",
            "Action:  2\n",
            "Current state after Action:  [-0.48931064  0.03360209]\n",
            "episode 149, iteration 850\n",
            "Action:  2\n",
            "Current state after Action:  [-0.45496526  0.03434538]\n",
            "episode 149, iteration 851\n",
            "Action:  2\n",
            "Current state after Action:  [-0.420131    0.03483426]\n",
            "episode 149, iteration 852\n",
            "q values:  tensor([[4.9319, 4.9408, 4.9656]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.38606035  0.03407065]\n",
            "episode 149, iteration 853\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35299222  0.03306813]\n",
            "episode 149, iteration 854\n",
            "Action:  1\n",
            "Current state after Action:  [-0.3211485   0.03184372]\n",
            "episode 149, iteration 855\n",
            "Action:  1\n",
            "Current state after Action:  [-0.29073151  0.03041699]\n",
            "episode 149, iteration 856\n",
            "q values:  tensor([[4.7525, 4.8348, 4.9560]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.26292239  0.02780912]\n",
            "episode 149, iteration 857\n",
            "Action:  0\n",
            "Current state after Action:  [-0.23787508  0.02504732]\n",
            "episode 149, iteration 858\n",
            "Action:  0\n",
            "Current state after Action:  [-0.21571775  0.02215733]\n",
            "episode 149, iteration 859\n",
            "Action:  0\n",
            "Current state after Action:  [-0.19655492  0.01916282]\n",
            "episode 149, iteration 860\n",
            "q values:  tensor([[4.8832, 4.9741, 5.0052]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.18046992  0.01608501]\n",
            "episode 149, iteration 861\n",
            "Action:  0\n",
            "Current state after Action:  [-0.16752737  0.01294255]\n",
            "episode 149, iteration 862\n",
            "Action:  0\n",
            "Current state after Action:  [-0.15777568  0.00975169]\n",
            "episode 149, iteration 863\n",
            "Action:  0\n",
            "Current state after Action:  [-0.15124912  0.00652655]\n",
            "episode 149, iteration 864\n",
            "q values:  tensor([[4.9382, 4.9693, 4.9680]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.1469696   0.00427953]\n",
            "episode 149, iteration 865\n",
            "Action:  1\n",
            "Current state after Action:  [-0.14495098  0.00201861]\n",
            "episode 149, iteration 866\n",
            "Action:  1\n",
            "Current state after Action:  [-0.1451997  -0.00024872]\n",
            "episode 149, iteration 867\n",
            "Action:  1\n",
            "Current state after Action:  [-0.14771496 -0.00251526]\n",
            "episode 149, iteration 868\n",
            "q values:  tensor([[5.0582, 5.0524, 5.0464]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.15148874 -0.00377378]\n",
            "episode 149, iteration 869\n",
            "Action:  2\n",
            "Current state after Action:  [-0.15650875 -0.00502002]\n",
            "episode 149, iteration 870\n",
            "Action:  2\n",
            "Current state after Action:  [-0.16275823 -0.00624947]\n",
            "episode 149, iteration 871\n",
            "Action:  2\n",
            "Current state after Action:  [-0.17021556 -0.00745733]\n",
            "episode 149, iteration 872\n",
            "q values:  tensor([[4.7996, 4.8819, 4.8937]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.17885396 -0.0086384 ]\n",
            "episode 149, iteration 873\n",
            "Action:  2\n",
            "Current state after Action:  [-0.18864104 -0.00978708]\n",
            "episode 149, iteration 874\n",
            "Action:  2\n",
            "Current state after Action:  [-0.19953836 -0.01089732]\n",
            "episode 149, iteration 875\n",
            "Action:  2\n",
            "Current state after Action:  [-0.21150097 -0.01196261]\n",
            "episode 149, iteration 876\n",
            "q values:  tensor([[4.9659, 4.9433, 4.9556]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.226477   -0.01497603]\n",
            "episode 149, iteration 877\n",
            "Action:  0\n",
            "Current state after Action:  [-0.24439785 -0.01792085]\n",
            "episode 149, iteration 878\n",
            "Action:  0\n",
            "Current state after Action:  [-0.2651763  -0.02077845]\n",
            "episode 149, iteration 879\n",
            "Action:  0\n",
            "Current state after Action:  [-0.28870452 -0.02352822]\n",
            "episode 149, iteration 880\n",
            "q values:  tensor([[4.9783, 5.0025, 4.9515]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.31485222 -0.0261477 ]\n",
            "episode 149, iteration 881\n",
            "Action:  0\n",
            "Current state after Action:  [-0.34346518 -0.02861296]\n",
            "episode 149, iteration 882\n",
            "Action:  0\n",
            "Current state after Action:  [-0.37436434 -0.03089916]\n",
            "episode 149, iteration 883\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40734573 -0.0329814 ]\n",
            "episode 149, iteration 884\n",
            "q values:  tensor([[4.9590, 4.9599, 5.0058]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.44018146 -0.03283573]\n",
            "episode 149, iteration 885\n",
            "Action:  2\n",
            "Current state after Action:  [-0.47263631 -0.03245485]\n",
            "episode 149, iteration 886\n",
            "Action:  2\n",
            "Current state after Action:  [-0.50447189 -0.03183558]\n",
            "episode 149, iteration 887\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53545084 -0.03097895]\n",
            "episode 149, iteration 888\n",
            "q values:  tensor([[5.1224, 4.9816, 5.1136]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.56734092 -0.03189008]\n",
            "episode 149, iteration 889\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59990387 -0.03256295]\n",
            "episode 149, iteration 890\n",
            "Action:  0\n",
            "Current state after Action:  [-0.63289952 -0.03299565]\n",
            "episode 149, iteration 891\n",
            "Action:  0\n",
            "Current state after Action:  [-0.66609003 -0.03319051]\n",
            "episode 149, iteration 892\n",
            "q values:  tensor([[5.0788, 5.1096, 5.0372]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6982441  -0.03215407]\n",
            "episode 149, iteration 893\n",
            "Action:  1\n",
            "Current state after Action:  [-0.72914745 -0.03090334]\n",
            "episode 149, iteration 894\n",
            "Action:  1\n",
            "Current state after Action:  [-0.75860504 -0.02945759]\n",
            "episode 149, iteration 895\n",
            "Action:  1\n",
            "Current state after Action:  [-0.7864425  -0.02783747]\n",
            "episode 149, iteration 896\n",
            "q values:  tensor([[4.9755, 5.0175, 4.9505]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.81350667 -0.02706417]\n",
            "episode 149, iteration 897\n",
            "Action:  0\n",
            "Current state after Action:  [-0.83966047 -0.02615379]\n",
            "episode 149, iteration 898\n",
            "Action:  0\n",
            "Current state after Action:  [-0.86478337 -0.0251229 ]\n",
            "episode 149, iteration 899\n",
            "Action:  0\n",
            "Current state after Action:  [-0.88877136 -0.02398799]\n",
            "episode 149, iteration 900\n",
            "q values:  tensor([[4.9196, 4.9640, 4.9703]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.90953644 -0.02076508]\n",
            "episode 149, iteration 901\n",
            "Action:  2\n",
            "Current state after Action:  [-0.9270117  -0.01747526]\n",
            "episode 149, iteration 902\n",
            "Action:  2\n",
            "Current state after Action:  [-0.94114771 -0.01413601]\n",
            "episode 149, iteration 903\n",
            "Action:  2\n",
            "Current state after Action:  [-0.95190918 -0.01076147]\n",
            "episode 149, iteration 904\n",
            "q values:  tensor([[4.9898, 4.9231, 5.0286]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.9612721  -0.00936292]\n",
            "episode 149, iteration 905\n",
            "Action:  0\n",
            "Current state after Action:  [-0.96921763 -0.00794553]\n",
            "episode 149, iteration 906\n",
            "Action:  0\n",
            "Current state after Action:  [-0.97573125 -0.00651362]\n",
            "episode 149, iteration 907\n",
            "Action:  0\n",
            "Current state after Action:  [-0.98080211 -0.00507086]\n",
            "episode 149, iteration 908\n",
            "q values:  tensor([[4.9133, 4.9884, 4.9686]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.98342241 -0.00262029]\n",
            "episode 149, iteration 909\n",
            "Action:  1\n",
            "Current state after Action:  [-9.83588319e-01 -1.65910927e-04]\n",
            "episode 149, iteration 910\n",
            "Action:  1\n",
            "Current state after Action:  [-0.98129961  0.00228871]\n",
            "episode 149, iteration 911\n",
            "Action:  1\n",
            "Current state after Action:  [-0.9765596   0.00474001]\n",
            "episode 149, iteration 912\n",
            "q values:  tensor([[4.8634, 4.9870, 4.9803]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.96837551  0.00818409]\n",
            "episode 149, iteration 913\n",
            "Action:  2\n",
            "Current state after Action:  [-0.95676099  0.01161452]\n",
            "episode 149, iteration 914\n",
            "Action:  2\n",
            "Current state after Action:  [-0.94173792  0.01502307]\n",
            "episode 149, iteration 915\n",
            "Action:  2\n",
            "Current state after Action:  [-0.92333893  0.01839899]\n",
            "episode 149, iteration 916\n",
            "q values:  tensor([[4.1727, 4.1164, 4.0225]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.90161055  0.02172838]\n",
            "episode 149, iteration 917\n",
            "Action:  2\n",
            "Current state after Action:  [-0.87661685  0.0249937 ]\n",
            "episode 149, iteration 918\n",
            "Action:  2\n",
            "Current state after Action:  [-0.84844342  0.02817343]\n",
            "episode 149, iteration 919\n",
            "Action:  2\n",
            "Current state after Action:  [-0.81720139  0.03124203]\n",
            "episode 149, iteration 920\n",
            "q values:  tensor([[4.9068, 4.8847, 4.9398]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.78403122  0.03317016]\n",
            "episode 149, iteration 921\n",
            "Action:  1\n",
            "Current state after Action:  [-0.74910056  0.03493067]\n",
            "episode 149, iteration 922\n",
            "Action:  1\n",
            "Current state after Action:  [-0.71260471  0.03649585]\n",
            "episode 149, iteration 923\n",
            "Action:  1\n",
            "Current state after Action:  [-0.67476607  0.03783864]\n",
            "episode 149, iteration 924\n",
            "q values:  tensor([[4.9497, 4.9473, 4.9650]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.63583213  0.03893393]\n",
            "episode 149, iteration 925\n",
            "Action:  1\n",
            "Current state after Action:  [-0.59607226  0.03975987]\n",
            "episode 149, iteration 926\n",
            "Action:  1\n",
            "Current state after Action:  [-0.55577311  0.04029915]\n",
            "episode 149, iteration 927\n",
            "Action:  1\n",
            "Current state after Action:  [-0.51523303  0.04054008]\n",
            "episode 149, iteration 928\n",
            "q values:  tensor([[5.1107, 4.9943, 4.9930]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47575569  0.03947735]\n",
            "episode 149, iteration 929\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43763593  0.03811975]\n",
            "episode 149, iteration 930\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40115378  0.03648215]\n",
            "episode 149, iteration 931\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36656945  0.03458433]\n",
            "episode 149, iteration 932\n",
            "q values:  tensor([[5.0137, 5.0303, 5.0251]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.33311976  0.03344969]\n",
            "episode 149, iteration 933\n",
            "Action:  1\n",
            "Current state after Action:  [-0.30102217  0.03209759]\n",
            "episode 149, iteration 934\n",
            "Action:  1\n",
            "Current state after Action:  [-0.2704726   0.03054957]\n",
            "episode 149, iteration 935\n",
            "Action:  1\n",
            "Current state after Action:  [-0.2416442  0.0288284]\n",
            "episode 149, iteration 936\n",
            "q values:  tensor([[4.9452, 4.9306, 4.9294]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.21568716  0.02595704]\n",
            "episode 149, iteration 937\n",
            "Action:  0\n",
            "Current state after Action:  [-0.19272477  0.02296239]\n",
            "episode 149, iteration 938\n",
            "Action:  0\n",
            "Current state after Action:  [-0.17285604  0.01986874]\n",
            "episode 149, iteration 939\n",
            "Action:  0\n",
            "Current state after Action:  [-0.15615863  0.01669741]\n",
            "episode 149, iteration 940\n",
            "q values:  tensor([[4.9750, 5.0320, 4.9138]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.14269186  0.01346677]\n",
            "episode 149, iteration 941\n",
            "Action:  0\n",
            "Current state after Action:  [-0.13249951  0.01019235]\n",
            "episode 149, iteration 942\n",
            "Action:  0\n",
            "Current state after Action:  [-0.12561224  0.00688727]\n",
            "episode 149, iteration 943\n",
            "Action:  0\n",
            "Current state after Action:  [-0.12204955  0.00356269]\n",
            "episode 149, iteration 944\n",
            "q values:  tensor([[4.9857, 4.9766, 4.9875]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.11982114  0.00222841]\n",
            "episode 149, iteration 945\n",
            "Action:  2\n",
            "Current state after Action:  [-0.11893295  0.00088819]\n",
            "episode 149, iteration 946\n",
            "Action:  2\n",
            "Current state after Action:  [-0.11938731 -0.00045436]\n",
            "episode 149, iteration 947\n",
            "Action:  2\n",
            "Current state after Action:  [-0.12118303 -0.00179572]\n",
            "episode 149, iteration 948\n",
            "q values:  tensor([[5.1406, 4.9262, 4.9782]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.12631534 -0.00513232]\n",
            "episode 149, iteration 949\n",
            "Action:  0\n",
            "Current state after Action:  [-0.1347703  -0.00845495]\n",
            "episode 149, iteration 950\n",
            "Action:  0\n",
            "Current state after Action:  [-0.14652369 -0.01175339]\n",
            "episode 149, iteration 951\n",
            "Action:  0\n",
            "Current state after Action:  [-0.16153941 -0.01501572]\n",
            "episode 149, iteration 952\n",
            "q values:  tensor([[4.9875, 4.9882, 4.9752]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.17776727 -0.01622786]\n",
            "episode 149, iteration 953\n",
            "Action:  2\n",
            "Current state after Action:  [-0.19514796 -0.01738069]\n",
            "episode 149, iteration 954\n",
            "Action:  2\n",
            "Current state after Action:  [-0.21361231 -0.01846436]\n",
            "episode 149, iteration 955\n",
            "Action:  2\n",
            "Current state after Action:  [-0.23308066 -0.01946835]\n",
            "episode 149, iteration 956\n",
            "q values:  tensor([[4.7125, 4.7195, 4.7011]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.25546233 -0.02238167]\n",
            "episode 149, iteration 957\n",
            "Action:  0\n",
            "Current state after Action:  [-0.28064506 -0.02518272]\n",
            "episode 149, iteration 958\n",
            "Action:  0\n",
            "Current state after Action:  [-0.30849283 -0.02784778]\n",
            "episode 149, iteration 959\n",
            "Action:  0\n",
            "Current state after Action:  [-0.33884424 -0.03035141]\n",
            "episode 149, iteration 960\n",
            "q values:  tensor([[5.0504, 5.0300, 5.0207]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.37151144 -0.0326672 ]\n",
            "episode 149, iteration 961\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40628013 -0.03476869]\n",
            "episode 149, iteration 962\n",
            "Action:  0\n",
            "Current state after Action:  [-0.44291065 -0.03663053]\n",
            "episode 149, iteration 963\n",
            "Action:  0\n",
            "Current state after Action:  [-0.48114045 -0.03822979]\n",
            "episode 149, iteration 964\n",
            "q values:  tensor([[4.9020, 4.9151, 4.9562]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.51868782 -0.03754737]\n",
            "episode 149, iteration 965\n",
            "Action:  2\n",
            "Current state after Action:  [-0.55527202 -0.0365842 ]\n",
            "episode 149, iteration 966\n",
            "Action:  2\n",
            "Current state after Action:  [-0.59061903 -0.03534701]\n",
            "episode 149, iteration 967\n",
            "Action:  2\n",
            "Current state after Action:  [-0.62446677 -0.03384774]\n",
            "episode 149, iteration 968\n",
            "q values:  tensor([[5.0392, 4.9681, 4.9968]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.65656949 -0.03210272]\n",
            "episode 149, iteration 969\n",
            "Action:  2\n",
            "Current state after Action:  [-0.68670117 -0.03013168]\n",
            "episode 149, iteration 970\n",
            "Action:  2\n",
            "Current state after Action:  [-0.71465781 -0.02795664]\n",
            "episode 149, iteration 971\n",
            "Action:  2\n",
            "Current state after Action:  [-0.7402587  -0.02560088]\n",
            "episode 149, iteration 972\n",
            "q values:  tensor([[5.0088, 5.2198, 5.0859]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.76434665 -0.02408796]\n",
            "episode 149, iteration 973\n",
            "Action:  1\n",
            "Current state after Action:  [-0.78678194 -0.02243528]\n",
            "episode 149, iteration 974\n",
            "Action:  1\n",
            "Current state after Action:  [-0.80744213 -0.02066019]\n",
            "episode 149, iteration 975\n",
            "Action:  1\n",
            "Current state after Action:  [-0.8262216  -0.01877947]\n",
            "episode 149, iteration 976\n",
            "q values:  tensor([[5.0035, 5.0137, 5.1177]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84303058 -0.01680899]\n",
            "episode 149, iteration 977\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85779404 -0.01476345]\n",
            "episode 149, iteration 978\n",
            "Action:  1\n",
            "Current state after Action:  [-0.87045033 -0.01265629]\n",
            "episode 149, iteration 979\n",
            "Action:  1\n",
            "Current state after Action:  [-0.88094991 -0.01049958]\n",
            "episode 149, iteration 980\n",
            "q values:  tensor([[4.9777, 5.0069, 5.0226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.89025402 -0.00930412]\n",
            "episode 149, iteration 981\n",
            "Action:  0\n",
            "Current state after Action:  [-0.89833016 -0.00807614]\n",
            "episode 149, iteration 982\n",
            "Action:  0\n",
            "Current state after Action:  [-0.9051515  -0.00682134]\n",
            "episode 149, iteration 983\n",
            "Action:  0\n",
            "Current state after Action:  [-0.91069641 -0.00554492]\n",
            "episode 149, iteration 984\n",
            "q values:  tensor([[4.8253, 4.8723, 4.9318]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.91294803 -0.00225162]\n",
            "episode 149, iteration 985\n",
            "Action:  2\n",
            "Current state after Action:  [-0.91189968  0.00104835]\n",
            "episode 149, iteration 986\n",
            "Action:  2\n",
            "Current state after Action:  [-0.90755446  0.00434522]\n",
            "episode 149, iteration 987\n",
            "Action:  2\n",
            "Current state after Action:  [-0.89992542  0.00762904]\n",
            "episode 149, iteration 988\n",
            "q values:  tensor([[4.9088, 4.9003, 4.8530]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.89003645  0.00988898]\n",
            "episode 149, iteration 989\n",
            "Action:  1\n",
            "Current state after Action:  [-0.87792023  0.01211622]\n",
            "episode 149, iteration 990\n",
            "Action:  1\n",
            "Current state after Action:  [-0.86361951  0.01430072]\n",
            "episode 149, iteration 991\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84718844  0.01643107]\n",
            "episode 149, iteration 992\n",
            "q values:  tensor([[4.9506, 4.9604, 4.9336]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82869407  0.01849437]\n",
            "episode 149, iteration 993\n",
            "Action:  1\n",
            "Current state after Action:  [-0.80821786  0.02047621]\n",
            "episode 149, iteration 994\n",
            "Action:  1\n",
            "Current state after Action:  [-0.78585709  0.02236076]\n",
            "episode 149, iteration 995\n",
            "Action:  1\n",
            "Current state after Action:  [-0.76172613  0.02413096]\n",
            "episode 149, iteration 996\n",
            "q values:  tensor([[4.9183, 4.9842, 4.9990]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73695729  0.02476884]\n",
            "episode 149, iteration 997\n",
            "Action:  0\n",
            "Current state after Action:  [-0.71169531  0.02526198]\n",
            "episode 149, iteration 998\n",
            "Action:  0\n",
            "Current state after Action:  [-0.68609629  0.02559902]\n",
            "episode 149, iteration 999\n",
            "Action:  0\n",
            "Current state after Action:  [-0.66032624  0.02577005]\n",
            "episode 149, iteration 1000\n",
            "q values:  tensor([[4.9084, 4.8906, 4.9034]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.63255925  0.02776699]\n",
            "episode 149, iteration 1001\n",
            "Action:  2\n",
            "Current state after Action:  [-0.60298953  0.02956972]\n",
            "episode 149, iteration 1002\n",
            "Action:  2\n",
            "Current state after Action:  [-0.57183     0.03115954]\n",
            "episode 149, iteration 1003\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53930999  0.03252001]\n",
            "episode 149, iteration 1004\n",
            "q values:  tensor([[4.9615, 4.9059, 4.9968]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.50567219  0.0336378 ]\n",
            "episode 149, iteration 1005\n",
            "Action:  2\n",
            "Current state after Action:  [-0.47116877  0.03450341]\n",
            "episode 149, iteration 1006\n",
            "Action:  2\n",
            "Current state after Action:  [-0.43605696  0.03511181]\n",
            "episode 149, iteration 1007\n",
            "Action:  2\n",
            "Current state after Action:  [-0.4005942   0.03546277]\n",
            "episode 149, iteration 1008\n",
            "q values:  tensor([[5.0230, 5.0483, 5.1662]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.36503317  0.03556103]\n",
            "episode 149, iteration 1009\n",
            "Action:  2\n",
            "Current state after Action:  [-0.32961704  0.03541613]\n",
            "episode 149, iteration 1010\n",
            "Action:  2\n",
            "Current state after Action:  [-0.29457503  0.03504201]\n",
            "episode 149, iteration 1011\n",
            "Action:  2\n",
            "Current state after Action:  [-0.26011871  0.03445632]\n",
            "episode 149, iteration 1012\n",
            "q values:  tensor([[4.9966, 4.9843, 5.0704]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.22743905  0.03267966]\n",
            "episode 149, iteration 1013\n",
            "Action:  1\n",
            "Current state after Action:  [-0.19669967  0.03073938]\n",
            "episode 149, iteration 1014\n",
            "Action:  1\n",
            "Current state after Action:  [-0.16803751  0.02866216]\n",
            "episode 149, iteration 1015\n",
            "Action:  1\n",
            "Current state after Action:  [-0.14156435  0.02647315]\n",
            "episode 149, iteration 1016\n",
            "q values:  tensor([[4.7870, 4.7672, 4.7553]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.11636911  0.02519524]\n",
            "episode 149, iteration 1017\n",
            "Action:  2\n",
            "Current state after Action:  [-0.09252307  0.02384605]\n",
            "episode 149, iteration 1018\n",
            "Action:  2\n",
            "Current state after Action:  [-0.07008133  0.02244173]\n",
            "episode 149, iteration 1019\n",
            "Action:  2\n",
            "Current state after Action:  [-0.04908455  0.02099678]\n",
            "episode 149, iteration 1020\n",
            "q values:  tensor([[4.1884, 4.2257, 4.0998]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.03156071  0.01752384]\n",
            "episode 149, iteration 1021\n",
            "Action:  0\n",
            "Current state after Action:  [-0.01752567  0.01403504]\n",
            "episode 149, iteration 1022\n",
            "Action:  0\n",
            "Current state after Action:  [-0.00698718  0.01053849]\n",
            "episode 149, iteration 1023\n",
            "Action:  0\n",
            "Current state after Action:  [5.18599575e-05 7.03904104e-03]\n",
            "episode 149, iteration 1024\n",
            "q values:  tensor([[5.0344, 5.0042, 5.0034]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.0045909  0.00453904]\n",
            "episode 149, iteration 1025\n",
            "Action:  1\n",
            "Current state after Action:  [0.00663018 0.00203928]\n",
            "episode 149, iteration 1026\n",
            "Action:  1\n",
            "Current state after Action:  [ 0.00616995 -0.00046023]\n",
            "episode 149, iteration 1027\n",
            "Action:  1\n",
            "Current state after Action:  [ 0.00321015 -0.0029598 ]\n",
            "episode 149, iteration 1028\n",
            "q values:  tensor([[4.8692, 4.9393, 5.0069]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.00324953 -0.00645968]\n",
            "episode 149, iteration 1029\n",
            "Action:  0\n",
            "Current state after Action:  [-0.01320909 -0.00995956]\n",
            "episode 149, iteration 1030\n",
            "Action:  0\n",
            "Current state after Action:  [-0.0266667 -0.0134576]\n",
            "episode 149, iteration 1031\n",
            "Action:  0\n",
            "Current state after Action:  [-0.0436163  -0.01694961]\n",
            "episode 149, iteration 1032\n",
            "q values:  tensor([[5.1004, 5.0527, 5.1042]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.06304454 -0.01942823]\n",
            "episode 149, iteration 1033\n",
            "Action:  1\n",
            "Current state after Action:  [-0.08492819 -0.02188365]\n",
            "episode 149, iteration 1034\n",
            "Action:  1\n",
            "Current state after Action:  [-0.10923114 -0.02430295]\n",
            "episode 149, iteration 1035\n",
            "Action:  1\n",
            "Current state after Action:  [-0.13590105 -0.02666992]\n",
            "episode 149, iteration 1036\n",
            "q values:  tensor([[4.9623, 4.9880, 4.9702]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.16586605 -0.029965  ]\n",
            "episode 149, iteration 1037\n",
            "Action:  0\n",
            "Current state after Action:  [-0.19902788 -0.03316183]\n",
            "episode 149, iteration 1038\n",
            "Action:  0\n",
            "Current state after Action:  [-0.23525716 -0.03622928]\n",
            "episode 149, iteration 1039\n",
            "Action:  0\n",
            "Current state after Action:  [-0.27438921 -0.03913205]\n",
            "episode 149, iteration 1040\n",
            "q values:  tensor([[5.0814, 5.0244, 5.0853]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.31622102 -0.04183181]\n",
            "episode 149, iteration 1041\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36050976 -0.04428873]\n",
            "episode 149, iteration 1042\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40697344 -0.04646368]\n",
            "episode 149, iteration 1043\n",
            "Action:  0\n",
            "Current state after Action:  [-0.45529407 -0.04832064]\n",
            "episode 149, iteration 1044\n",
            "q values:  tensor([[5.1633, 5.1786, 5.3863]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.50312342 -0.04782934]\n",
            "episode 149, iteration 1045\n",
            "Action:  2\n",
            "Current state after Action:  [-0.55010623 -0.04698281]\n",
            "episode 149, iteration 1046\n",
            "Action:  2\n",
            "Current state after Action:  [-0.59589044 -0.04578422]\n",
            "episode 149, iteration 1047\n",
            "Action:  2\n",
            "Current state after Action:  [-0.64013671 -0.04424627]\n",
            "episode 149, iteration 1048\n",
            "q values:  tensor([[4.9286, 4.9456, 4.9128]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.68452664 -0.04438993]\n",
            "episode 149, iteration 1049\n",
            "Action:  0\n",
            "Current state after Action:  [-0.72875596 -0.04422931]\n",
            "episode 149, iteration 1050\n",
            "Action:  0\n",
            "Current state after Action:  [-0.77254191 -0.04378596]\n",
            "episode 149, iteration 1051\n",
            "Action:  0\n",
            "Current state after Action:  [-0.81562958 -0.04308767]\n",
            "episode 149, iteration 1052\n",
            "q values:  tensor([[5.0675, 5.0339, 5.0261]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.85579664 -0.04016706]\n",
            "episode 149, iteration 1053\n",
            "Action:  2\n",
            "Current state after Action:  [-0.89286463 -0.03706799]\n",
            "episode 149, iteration 1054\n",
            "Action:  2\n",
            "Current state after Action:  [-0.92669583 -0.0338312 ]\n",
            "episode 149, iteration 1055\n",
            "Action:  2\n",
            "Current state after Action:  [-0.95718862 -0.03049279]\n",
            "episode 149, iteration 1056\n",
            "q values:  tensor([[4.9693, 4.9302, 4.9716]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.985272   -0.02808338]\n",
            "episode 149, iteration 1057\n",
            "Action:  1\n",
            "Current state after Action:  [-1.01089839 -0.0256264 ]\n",
            "episode 149, iteration 1058\n",
            "Action:  1\n",
            "Current state after Action:  [-1.0340396 -0.0231412]\n",
            "episode 149, iteration 1059\n",
            "Action:  1\n",
            "Current state after Action:  [-1.05468275 -0.02064315]\n",
            "episode 149, iteration 1060\n",
            "q values:  tensor([[4.9281, 4.9329, 5.0724]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.07182653 -0.01714378]\n",
            "episode 149, iteration 1061\n",
            "Action:  2\n",
            "Current state after Action:  [-1.08547714 -0.0136506 ]\n",
            "episode 149, iteration 1062\n",
            "Action:  2\n",
            "Current state after Action:  [-1.09564421 -0.01016707]\n",
            "episode 149, iteration 1063\n",
            "Action:  2\n",
            "Current state after Action:  [-1.10233763 -0.00669343]\n",
            "episode 149, iteration 1064\n",
            "q values:  tensor([[4.9706, 4.8405, 4.9709]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.10756519 -0.00522755]\n",
            "episode 149, iteration 1065\n",
            "Action:  0\n",
            "Current state after Action:  [-1.11133363 -0.00376844]\n",
            "episode 149, iteration 1066\n",
            "Action:  0\n",
            "Current state after Action:  [-1.1136482  -0.00231457]\n",
            "episode 149, iteration 1067\n",
            "Action:  0\n",
            "Current state after Action:  [-1.11451229e+00 -8.64086608e-04]\n",
            "episode 149, iteration 1068\n",
            "q values:  tensor([[5.0690, 5.0335, 5.1335]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.11292718  0.00158511]\n",
            "episode 149, iteration 1069\n",
            "Action:  1\n",
            "Current state after Action:  [-1.10889052  0.00403666]\n",
            "episode 149, iteration 1070\n",
            "Action:  1\n",
            "Current state after Action:  [-1.10239655  0.00649397]\n",
            "episode 149, iteration 1071\n",
            "Action:  1\n",
            "Current state after Action:  [-1.09343678  0.00895977]\n",
            "episode 149, iteration 1072\n",
            "q values:  tensor([[4.9539, 4.9082, 4.9923]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.08100103  0.01243575]\n",
            "episode 149, iteration 1073\n",
            "Action:  2\n",
            "Current state after Action:  [-1.06507812  0.01592291]\n",
            "episode 149, iteration 1074\n",
            "Action:  2\n",
            "Current state after Action:  [-1.04565881  0.01941931]\n",
            "episode 149, iteration 1075\n",
            "Action:  2\n",
            "Current state after Action:  [-1.02273953  0.02291929]\n",
            "episode 149, iteration 1076\n",
            "q values:  tensor([[4.8590, 4.8858, 4.9235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.99632697  0.02641256]\n",
            "episode 149, iteration 1077\n",
            "Action:  2\n",
            "Current state after Action:  [-0.96644346  0.0298835 ]\n",
            "episode 149, iteration 1078\n",
            "Action:  2\n",
            "Current state after Action:  [-0.93313297  0.0333105 ]\n",
            "episode 149, iteration 1079\n",
            "Action:  2\n",
            "Current state after Action:  [-0.89646742  0.03666555]\n",
            "episode 149, iteration 1080\n",
            "q values:  tensor([[4.9738, 5.0166, 4.9908]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.85655314  0.03991428]\n",
            "episode 149, iteration 1081\n",
            "Action:  2\n",
            "Current state after Action:  [-0.81353672  0.04301642]\n",
            "episode 149, iteration 1082\n",
            "Action:  2\n",
            "Current state after Action:  [-0.76760978  0.04592694]\n",
            "episode 149, iteration 1083\n",
            "Action:  2\n",
            "Current state after Action:  [-0.71901188  0.0485979 ]\n",
            "episode 149, iteration 1084\n",
            "q values:  tensor([[4.9738, 5.0111, 4.9864]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.6700309   0.04898098]\n",
            "episode 149, iteration 1085\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62098666  0.04904424]\n",
            "episode 149, iteration 1086\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57222236  0.0487643 ]\n",
            "episode 149, iteration 1087\n",
            "Action:  0\n",
            "Current state after Action:  [-0.52409467  0.04812768]\n",
            "episode 149, iteration 1088\n",
            "q values:  tensor([[4.8169, 4.8693, 4.8874]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47696327  0.0471314 ]\n",
            "episode 149, iteration 1089\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43118049  0.04578278]\n",
            "episode 149, iteration 1090\n",
            "Action:  0\n",
            "Current state after Action:  [-0.38708201  0.04409849]\n",
            "episode 149, iteration 1091\n",
            "Action:  0\n",
            "Current state after Action:  [-0.34497901  0.04210299]\n",
            "episode 149, iteration 1092\n",
            "q values:  tensor([[4.9876, 4.9100, 4.9910]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.30515247  0.03982654]\n",
            "episode 149, iteration 1093\n",
            "Action:  0\n",
            "Current state after Action:  [-0.26784949  0.03730297]\n",
            "episode 149, iteration 1094\n",
            "Action:  0\n",
            "Current state after Action:  [-0.23328191  0.03456758]\n",
            "episode 149, iteration 1095\n",
            "Action:  0\n",
            "Current state after Action:  [-0.20162668  0.03165523]\n",
            "episode 149, iteration 1096\n",
            "q values:  tensor([[5.0267, 5.0048, 4.9795]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.17202788  0.0295988 ]\n",
            "episode 149, iteration 1097\n",
            "Action:  1\n",
            "Current state after Action:  [-0.14460347  0.02742441]\n",
            "episode 149, iteration 1098\n",
            "Action:  1\n",
            "Current state after Action:  [-0.1194475   0.02515598]\n",
            "episode 149, iteration 1099\n",
            "Action:  1\n",
            "Current state after Action:  [-0.09663271  0.02281478]\n",
            "episode 149, iteration 1100\n",
            "q values:  tensor([[4.8162, 4.8166, 4.8427]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.07521362  0.0214191 ]\n",
            "episode 149, iteration 1101\n",
            "Action:  2\n",
            "Current state after Action:  [-0.05523114  0.01998247]\n",
            "episode 149, iteration 1102\n",
            "Action:  2\n",
            "Current state after Action:  [-0.03671443  0.01851671]\n",
            "episode 149, iteration 1103\n",
            "Action:  2\n",
            "Current state after Action:  [-0.01968257  0.01703186]\n",
            "episode 149, iteration 1104\n",
            "q values:  tensor([[4.9478, 4.9289, 4.8979]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.00414636  0.01553622]\n",
            "episode 149, iteration 1105\n",
            "Action:  2\n",
            "Current state after Action:  [0.00989005 0.01403641]\n",
            "episode 149, iteration 1106\n",
            "Action:  2\n",
            "Current state after Action:  [0.02242756 0.01253751]\n",
            "episode 149, iteration 1107\n",
            "Action:  2\n",
            "Current state after Action:  [0.03347073 0.01104317]\n",
            "episode 149, iteration 1108\n",
            "q values:  tensor([[4.9697, 5.1217, 4.9530]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.04202649 0.00855576]\n",
            "episode 149, iteration 1109\n",
            "Action:  1\n",
            "Current state after Action:  [0.04810209 0.0060756 ]\n",
            "episode 149, iteration 1110\n",
            "Action:  1\n",
            "Current state after Action:  [0.05170368 0.00360159]\n",
            "episode 149, iteration 1111\n",
            "Action:  1\n",
            "Current state after Action:  [0.05283528 0.0011316 ]\n",
            "episode 149, iteration 1112\n",
            "q values:  tensor([[5.0507, 4.9842, 5.0470]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.05049823 -0.00233706]\n",
            "episode 149, iteration 1113\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.0446898  -0.00580842]\n",
            "episode 149, iteration 1114\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.03540381 -0.00928599]\n",
            "episode 149, iteration 1115\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.02263191 -0.0127719 ]\n",
            "episode 149, iteration 1116\n",
            "q values:  tensor([[4.9722, 5.0624, 5.0007]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [ 0.00736577 -0.01526614]\n",
            "episode 149, iteration 1117\n",
            "Action:  1\n",
            "Current state after Action:  [-0.01039976 -0.01776553]\n",
            "episode 149, iteration 1118\n",
            "Action:  1\n",
            "Current state after Action:  [-0.03066408 -0.02026431]\n",
            "episode 149, iteration 1119\n",
            "Action:  1\n",
            "Current state after Action:  [-0.05341782 -0.02275374]\n",
            "episode 149, iteration 1120\n",
            "q values:  tensor([[4.9855, 4.9558, 4.9808]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.07963953 -0.02622171]\n",
            "episode 149, iteration 1121\n",
            "Action:  0\n",
            "Current state after Action:  [-0.10929023 -0.0296507 ]\n",
            "episode 149, iteration 1122\n",
            "Action:  0\n",
            "Current state after Action:  [-0.14230775 -0.03301752]\n",
            "episode 149, iteration 1123\n",
            "Action:  0\n",
            "Current state after Action:  [-0.17860089 -0.03629313]\n",
            "episode 149, iteration 1124\n",
            "q values:  tensor([[4.9975, 5.0433, 5.0599]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.21704367 -0.03844278]\n",
            "episode 149, iteration 1125\n",
            "Action:  1\n",
            "Current state after Action:  [-0.25747495 -0.04043128]\n",
            "episode 149, iteration 1126\n",
            "Action:  1\n",
            "Current state after Action:  [-0.29969678 -0.04222183]\n",
            "episode 149, iteration 1127\n",
            "Action:  1\n",
            "Current state after Action:  [-0.34347441 -0.04377763]\n",
            "episode 149, iteration 1128\n",
            "q values:  tensor([[4.9691, 4.9565, 5.0403]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.38953819 -0.04606377]\n",
            "episode 149, iteration 1129\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43758053 -0.04804234]\n",
            "episode 149, iteration 1130\n",
            "Action:  0\n",
            "Current state after Action:  [-0.48726087 -0.04968034]\n",
            "episode 149, iteration 1131\n",
            "Action:  0\n",
            "Current state after Action:  [-0.53821321 -0.05095234]\n",
            "episode 149, iteration 1132\n",
            "q values:  tensor([[4.8561, 5.0297, 4.8924]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59005597 -0.05184276]\n",
            "episode 149, iteration 1133\n",
            "Action:  0\n",
            "Current state after Action:  [-0.6424036  -0.05234763]\n",
            "episode 149, iteration 1134\n",
            "Action:  0\n",
            "Current state after Action:  [-0.69487894 -0.05247534]\n",
            "episode 149, iteration 1135\n",
            "Action:  0\n",
            "Current state after Action:  [-0.74712547 -0.05224653]\n",
            "episode 149, iteration 1136\n",
            "q values:  tensor([[4.7343, 4.6905, 4.7237]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7988184  -0.05169293]\n",
            "episode 149, iteration 1137\n",
            "Action:  0\n",
            "Current state after Action:  [-0.84967383 -0.05085544]\n",
            "episode 149, iteration 1138\n",
            "Action:  0\n",
            "Current state after Action:  [-0.8994555  -0.04978167]\n",
            "episode 149, iteration 1139\n",
            "Action:  0\n",
            "Current state after Action:  [-0.94797874 -0.04852324]\n",
            "episode 149, iteration 1140\n",
            "q values:  tensor([[4.9426, 4.9840, 4.9755]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.99411191 -0.04613317]\n",
            "episode 149, iteration 1141\n",
            "Action:  1\n",
            "Current state after Action:  [-1.03777672 -0.04366481]\n",
            "episode 149, iteration 1142\n",
            "Action:  1\n",
            "Current state after Action:  [-1.07894253 -0.04116581]\n",
            "episode 149, iteration 1143\n",
            "Action:  1\n",
            "Current state after Action:  [-1.11761966 -0.03867714]\n",
            "episode 149, iteration 1144\n",
            "q values:  tensor([[5.0512, 5.0266, 5.0291]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.15385238 -0.03623272]\n",
            "episode 149, iteration 1145\n",
            "Action:  1\n",
            "Current state after Action:  [-1.18771199 -0.0338596 ]\n",
            "episode 149, iteration 1146\n",
            "Action:  1\n",
            "Current state after Action:  [-1.2  0. ]\n",
            "episode 149, iteration 1147\n",
            "Action:  1\n",
            "Current state after Action:  [-1.1977581  0.0022419]\n",
            "episode 149, iteration 1148\n",
            "q values:  tensor([[4.7309, 4.7151, 4.8595]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.19326692  0.00449118]\n",
            "episode 149, iteration 1149\n",
            "Action:  1\n",
            "Current state after Action:  [-1.18651196  0.00675497]\n",
            "episode 149, iteration 1150\n",
            "Action:  1\n",
            "Current state after Action:  [-1.17747218  0.00903978]\n",
            "episode 149, iteration 1151\n",
            "Action:  1\n",
            "Current state after Action:  [-1.16612091  0.01135127]\n",
            "episode 149, iteration 1152\n",
            "q values:  tensor([[5.1990, 5.1627, 5.0193]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.15142707  0.01469384]\n",
            "episode 149, iteration 1153\n",
            "Action:  2\n",
            "Current state after Action:  [-1.13335445  0.01807262]\n",
            "episode 149, iteration 1154\n",
            "Action:  2\n",
            "Current state after Action:  [-1.11186487  0.02148957]\n",
            "episode 149, iteration 1155\n",
            "Action:  2\n",
            "Current state after Action:  [-1.0869222   0.02494267]\n",
            "episode 149, iteration 1156\n",
            "q values:  tensor([[4.9873, 4.9963, 5.0422]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.06049726  0.02642494]\n",
            "episode 149, iteration 1157\n",
            "Action:  0\n",
            "Current state after Action:  [-1.03257431  0.02792295]\n",
            "episode 149, iteration 1158\n",
            "Action:  0\n",
            "Current state after Action:  [-1.00315376  0.02942055]\n",
            "episode 149, iteration 1159\n",
            "Action:  0\n",
            "Current state after Action:  [-0.972255    0.03089876]\n",
            "episode 149, iteration 1160\n",
            "q values:  tensor([[4.9687, 4.9762, 4.9268]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.93891917  0.03333584]\n",
            "episode 149, iteration 1161\n",
            "Action:  1\n",
            "Current state after Action:  [-0.90321407  0.0357051 ]\n",
            "episode 149, iteration 1162\n",
            "Action:  1\n",
            "Current state after Action:  [-0.8652386   0.03797547]\n",
            "episode 149, iteration 1163\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82512644  0.04011215]\n",
            "episode 149, iteration 1164\n",
            "q values:  tensor([[4.9380, 4.9344, 4.8778]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.78204887  0.04307757]\n",
            "episode 149, iteration 1165\n",
            "Action:  2\n",
            "Current state after Action:  [-0.73622138  0.04582749]\n",
            "episode 149, iteration 1166\n",
            "Action:  2\n",
            "Current state after Action:  [-0.68790518  0.0483162 ]\n",
            "episode 149, iteration 1167\n",
            "Action:  2\n",
            "Current state after Action:  [-0.63740599  0.0504992 ]\n",
            "episode 149, iteration 1168\n",
            "q values:  tensor([[4.9651, 5.0023, 5.0166]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.58506972  0.05233626]\n",
            "episode 149, iteration 1169\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53127504  0.05379469]\n",
            "episode 149, iteration 1170\n",
            "Action:  2\n",
            "Current state after Action:  [-0.47642278  0.05485225]\n",
            "episode 149, iteration 1171\n",
            "Action:  2\n",
            "Current state after Action:  [-0.42092317  0.05549961]\n",
            "episode 149, iteration 1172\n",
            "q values:  tensor([[4.9630, 4.9031, 5.0636]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.3661815   0.05474167]\n",
            "episode 149, iteration 1173\n",
            "Action:  1\n",
            "Current state after Action:  [-0.31257706  0.05360444]\n",
            "episode 149, iteration 1174\n",
            "Action:  1\n",
            "Current state after Action:  [-0.26045167  0.05212539]\n",
            "episode 149, iteration 1175\n",
            "Action:  1\n",
            "Current state after Action:  [-0.21010119  0.05035049]\n",
            "episode 149, iteration 1176\n",
            "q values:  tensor([[8.8569, 9.2666, 9.3560]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.16077032  0.04933087]\n",
            "episode 149, iteration 1177\n",
            "Action:  2\n",
            "Current state after Action:  [-0.11265426  0.04811605]\n",
            "episode 149, iteration 1178\n",
            "Action:  2\n",
            "Current state after Action:  [-0.06589679  0.04675747]\n",
            "episode 149, iteration 1179\n",
            "Action:  2\n",
            "Current state after Action:  [-0.02059062  0.04530617]\n",
            "episode 149, iteration 1180\n",
            "q values:  tensor([[8.2079, 8.4546, 8.7543]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.02122031 0.04181093]\n",
            "episode 149, iteration 1181\n",
            "Action:  0\n",
            "Current state after Action:  [0.05953631 0.038316  ]\n",
            "episode 149, iteration 1182\n",
            "Action:  0\n",
            "Current state after Action:  [0.09439208 0.03485577]\n",
            "episode 149, iteration 1183\n",
            "Action:  0\n",
            "Current state after Action:  [0.12584742 0.03145534]\n",
            "episode 149, iteration 1184\n",
            "q values:  tensor([[9.8362, 9.8171, 9.7959]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.15497882 0.0291314 ]\n",
            "episode 149, iteration 1185\n",
            "Action:  1\n",
            "Current state after Action:  [0.1818756  0.02689678]\n",
            "episode 149, iteration 1186\n",
            "Action:  1\n",
            "Current state after Action:  [0.20663537 0.02475977]\n",
            "episode 149, iteration 1187\n",
            "Action:  1\n",
            "Current state after Action:  [0.22936031 0.02272494]\n",
            "episode 149, iteration 1188\n",
            "q values:  tensor([[8.9924, 9.1369, 9.1871]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.25115409 0.02179378]\n",
            "episode 149, iteration 1189\n",
            "Action:  2\n",
            "Current state after Action:  [0.27212455 0.02097046]\n",
            "episode 149, iteration 1190\n",
            "Action:  2\n",
            "Current state after Action:  [0.29238284 0.02025829]\n",
            "episode 149, iteration 1191\n",
            "Action:  2\n",
            "Current state after Action:  [0.31204277 0.01965993]\n",
            "episode 149, iteration 1192\n",
            "q values:  tensor([[9.1884, 9.3040, 9.2992]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.33122043 0.01917765]\n",
            "episode 149, iteration 1193\n",
            "Action:  2\n",
            "Current state after Action:  [0.35003401 0.01881359]\n",
            "episode 149, iteration 1194\n",
            "Action:  2\n",
            "Current state after Action:  [0.3686039  0.01856988]\n",
            "episode 149, iteration 1195\n",
            "Action:  2\n",
            "Current state after Action:  [0.38705276 0.01844886]\n",
            "episode 149, iteration 1196\n",
            "q values:  tensor([[9.2494, 9.2307, 9.2824]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.40450593 0.01745317]\n",
            "episode 149, iteration 1197\n",
            "Action:  1\n",
            "Current state after Action:  [0.42108478 0.01657885]\n",
            "episode 149, iteration 1198\n",
            "Action:  1\n",
            "Current state after Action:  [0.43690684 0.01582206]\n",
            "episode 149, iteration 1199\n",
            "Action:  1\n",
            "Current state after Action:  [0.45208601 0.01517918]\n",
            "episode 149, iteration 1200\n",
            "q values:  tensor([[7.3220, 7.3911, 7.3276]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.46573295 0.01364693]\n",
            "episode 149, iteration 1201\n",
            "Action:  0\n",
            "Current state after Action:  [0.47794806 0.01221512]\n",
            "episode 149, iteration 1202\n",
            "Action:  0\n",
            "Current state after Action:  [0.48882187 0.01087381]\n",
            "episode 149, iteration 1203\n",
            "Action:  0\n",
            "Current state after Action:  [0.49843532 0.00961345]\n",
            "episode 149, iteration 1204\n",
            "q values:  tensor([[ 0.0368, -0.2648, -0.6687]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.50786023 0.00942491]\n",
            "Training Complete\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxu7rHP2P_i8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "f5c97b1b-1d32-4fc9-a35e-b2d1a35268c9"
      },
      "source": [
        "plt.title('Iterations per Episode')\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Iterations')\n",
        "plt.plot(episode_durations)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff78004ba20>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "4xG5PlK44ohz",
        "outputId": "232db687-de42-4812-de1d-99fe7d931659"
      },
      "source": [
        "plt.title('Runtime(s) per Episode')\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Runtime(s)')\n",
        "plt.plot(all_episode_training_time)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff7680c7c50>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "zbtx-nG34rwF",
        "outputId": "ba137f88-7335-408e-e860-fa3d2174011e"
      },
      "source": [
        "# calculate average max q value per episode\n",
        "avg_max_qVals = []\n",
        "for vals in all_episode_max_q_vals:\n",
        "    avg_max_qVal = sum(vals)/len(vals)\n",
        "    avg_max_qVals.append(avg_max_qVal)\n",
        "plt.title('Average Max Q value per Episode')\n",
        "plt.xlabel('Episode')\n",
        "plt.ylabel('Average Max Q value')\n",
        "plt.plot(avg_max_qVals)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff768c41fd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyBn-Ucl1fjt"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Et-r2tD1n0m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3d19a6-04df-4d18-8963-abb157fe7733"
      },
      "source": [
        "# Initialize the environment and state\n",
        "test_env = gym.make('MountainCar-v0').unwrapped\n",
        "test_env.reset()\n",
        "\n",
        "# Stack 4 most recent frames\n",
        "past_screen3 = get_screen(test_env)\n",
        "past_screen2 = get_screen(test_env)\n",
        "past_screen1 = get_screen(test_env)\n",
        "current_screen = get_screen(test_env)\n",
        "state = stack_past_four_frames(current_screen, past_screen1, past_screen2, past_screen3)\n",
        "\n",
        "start = time.time()\n",
        "for t in count():\n",
        "    print(\"iteration {}\".format(t))\n",
        " \n",
        "    # Compute Q values from policy net\n",
        "    q_values = get_q_values(state)\n",
        "    print(\"q values: \", q_values)\n",
        "\n",
        "    # Choose action based on max q value\n",
        "    action = select_action(q_values)\n",
        "   \n",
        "    print(\"Action: \", action.item())\n",
        "\n",
        "    # Execute action\n",
        "    new_ob, reward, done, info = test_env.step(action.item())\n",
        "\n",
        "    # Observe new state\n",
        "    past_screen3 = past_screen2\n",
        "    past_screen2 = past_screen1\n",
        "    past_screen1 = current_screen\n",
        "    current_screen = get_screen(test_env)\n",
        "    print(\"Current state after Action: \", new_ob)\n",
        "    \n",
        "    if not done:\n",
        "        next_state = stack_past_four_frames(current_screen, past_screen1, past_screen2, past_screen3)\n",
        "    else:\n",
        "        next_state = None\n",
        "\n",
        "    # Move to the next state\n",
        "    state = next_state\n",
        "\n",
        "    if done or t > 20000:\n",
        "        end = time.time()\n",
        "        print(\"Total testing runtime in seconds: \", end - start)\n",
        "        break\n",
        "\n",
        "print('Testing Complete')\n",
        "test_env.close()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Action:  0\n",
            "Current state after Action:  [-0.25005162  0.0198311 ]\n",
            "iteration 5323\n",
            "q values:  tensor([[4.9510, 4.8357, 4.9040]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.23104949  0.01900214]\n",
            "iteration 5324\n",
            "q values:  tensor([[4.9744, 4.8579, 4.9271]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.21297044  0.01807904]\n",
            "iteration 5325\n",
            "q values:  tensor([[4.9975, 4.8867, 4.9605]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.19789826  0.01507218]\n",
            "iteration 5326\n",
            "q values:  tensor([[4.9878, 4.8886, 4.9684]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.18389828  0.01399998]\n",
            "iteration 5327\n",
            "q values:  tensor([[4.9867, 4.8864, 4.9655]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.1730274   0.01087089]\n",
            "iteration 5328\n",
            "q values:  tensor([[4.9857, 4.8835, 4.9615]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.1653272  0.0077002]\n",
            "iteration 5329\n",
            "q values:  tensor([[4.9840, 4.8824, 4.9606]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.15982575  0.00550145]\n",
            "iteration 5330\n",
            "q values:  tensor([[4.9803, 4.8789, 4.9570]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.1565424   0.00328335]\n",
            "iteration 5331\n",
            "q values:  tensor([[4.9779, 4.8736, 4.9500]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.56488385e-01  5.40119340e-05]\n",
            "iteration 5332\n",
            "q values:  tensor([[4.9748, 4.8675, 4.9419]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.1576639  -0.00117551]\n",
            "iteration 5333\n",
            "q values:  tensor([[4.9727, 4.8654, 4.9397]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.16006494 -0.00240104]\n",
            "iteration 5334\n",
            "q values:  tensor([[4.9687, 4.8637, 4.9390]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.16568324 -0.0056183 ]\n",
            "iteration 5335\n",
            "q values:  tensor([[4.9619, 4.8597, 4.9362]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.17449902 -0.00881578]\n",
            "iteration 5336\n",
            "q values:  tensor([[4.9771, 4.8692, 4.9434]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.18647999 -0.01198097]\n",
            "iteration 5337\n",
            "q values:  tensor([[4.9854, 4.8767, 4.9510]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.20157985 -0.01509985]\n",
            "iteration 5338\n",
            "q values:  tensor([[4.9820, 4.8714, 4.9444]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.21973633 -0.01815648]\n",
            "iteration 5339\n",
            "q values:  tensor([[4.8820, 4.7481, 4.8016]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.238869   -0.01913267]\n",
            "iteration 5340\n",
            "q values:  tensor([[5.0876, 4.9281, 4.9795]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.26088677 -0.02201777]\n",
            "iteration 5341\n",
            "q values:  tensor([[4.9902, 4.8553, 4.9148]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.28467714 -0.02379037]\n",
            "iteration 5342\n",
            "q values:  tensor([[4.9818, 4.8610, 4.9281]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.31010988 -0.02543274]\n",
            "iteration 5343\n",
            "q values:  tensor([[4.9727, 4.8689, 4.9451]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.33803655 -0.02792667]\n",
            "iteration 5344\n",
            "q values:  tensor([[4.9963, 4.8774, 4.9465]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.36728415 -0.02924761]\n",
            "iteration 5345\n",
            "q values:  tensor([[4.9947, 4.8421, 4.8918]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.39666162 -0.02937747]\n",
            "iteration 5346\n",
            "q values:  tensor([[4.9827, 4.8412, 4.8964]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.42596827 -0.02930665]\n",
            "iteration 5347\n",
            "q values:  tensor([[4.9969, 4.8397, 4.8869]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45599673 -0.03002846]\n",
            "iteration 5348\n",
            "q values:  tensor([[5.0126, 4.8533, 4.9003]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.48652874 -0.030532  ]\n",
            "iteration 5349\n",
            "q values:  tensor([[5.0025, 4.8655, 4.9246]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51833819 -0.03180946]\n",
            "iteration 5350\n",
            "q values:  tensor([[4.9980, 4.8579, 4.9149]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.5511871  -0.03284891]\n",
            "iteration 5351\n",
            "q values:  tensor([[4.9978, 4.8588, 4.9166]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.58282933 -0.03164223]\n",
            "iteration 5352\n",
            "q values:  tensor([[4.9880, 4.8570, 4.9186]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.61502967 -0.03220034]\n",
            "iteration 5353\n",
            "q values:  tensor([[4.9921, 4.8621, 4.9246]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.64555284 -0.03052317]\n",
            "iteration 5354\n",
            "q values:  tensor([[4.9838, 4.8503, 4.9103]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.67418163 -0.02862879]\n",
            "iteration 5355\n",
            "q values:  tensor([[4.9633, 4.8362, 4.8985]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70071907 -0.02653744]\n",
            "iteration 5356\n",
            "q values:  tensor([[4.9726, 4.8587, 4.9292]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.72698974 -0.02627067]\n",
            "iteration 5357\n",
            "q values:  tensor([[4.4140, 4.2598, 4.2729]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.75282788 -0.02583815]\n",
            "iteration 5358\n",
            "q values:  tensor([[4.9796, 4.8733, 4.9486]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.77707915 -0.02425127]\n",
            "iteration 5359\n",
            "q values:  tensor([[4.9829, 4.8589, 4.9243]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.79960732 -0.02252816]\n",
            "iteration 5360\n",
            "q values:  tensor([[4.9997, 4.8744, 4.9400]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.81929399 -0.01968667]\n",
            "iteration 5361\n",
            "q values:  tensor([[5.0054, 4.8637, 4.9203]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.83704257 -0.01774859]\n",
            "iteration 5362\n",
            "q values:  tensor([[5.0157, 4.8624, 4.9129]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85277177 -0.0157292 ]\n",
            "iteration 5363\n",
            "q values:  tensor([[5.0116, 4.8678, 4.9236]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.86641432 -0.01364255]\n",
            "iteration 5364\n",
            "q values:  tensor([[5.0138, 4.8642, 4.9167]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.87691562 -0.0105013 ]\n",
            "iteration 5365\n",
            "q values:  tensor([[4.8882, 4.7289, 4.7682]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.88423609 -0.00732047]\n",
            "iteration 5366\n",
            "q values:  tensor([[4.9696, 4.8144, 4.8611]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.89034942 -0.00611333]\n",
            "iteration 5367\n",
            "q values:  tensor([[5.0032, 4.8559, 4.9092]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.89423445 -0.00388503]\n",
            "iteration 5368\n",
            "q values:  tensor([[4.9935, 4.8524, 4.9085]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-8.94878112e-01 -6.43662723e-04]\n",
            "iteration 5369\n",
            "q values:  tensor([[4.9829, 4.8573, 4.9217]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-8.94278278e-01  5.99834024e-04]\n",
            "iteration 5370\n",
            "q values:  tensor([[4.9833, 4.8584, 4.9233]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.89243694  0.00184134]\n",
            "iteration 5371\n",
            "q values:  tensor([[4.9843, 4.8580, 4.9222]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.88936023  0.0030767 ]\n",
            "iteration 5372\n",
            "q values:  tensor([[4.9839, 4.8575, 4.9216]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.8850586   0.00430163]\n",
            "iteration 5373\n",
            "q values:  tensor([[4.9839, 4.8561, 4.9193]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.87754694  0.00751167]\n",
            "iteration 5374\n",
            "q values:  tensor([[4.9880, 4.8571, 4.9188]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.86885213  0.0086948 ]\n",
            "iteration 5375\n",
            "q values:  tensor([[5.0037, 4.8610, 4.9169]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.8590067   0.00984543]\n",
            "iteration 5376\n",
            "q values:  tensor([[5.0030, 4.8584, 4.9131]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.84604923  0.01295747]\n",
            "iteration 5377\n",
            "q values:  tensor([[4.9989, 4.8559, 4.9113]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.83203329  0.01401594]\n",
            "iteration 5378\n",
            "q values:  tensor([[5.0078, 4.8502, 4.8978]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.81702035  0.01501295]\n",
            "iteration 5379\n",
            "q values:  tensor([[5.0019, 4.8521, 4.9039]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.79908013  0.01794021]\n",
            "iteration 5380\n",
            "q values:  tensor([[4.9897, 4.8485, 4.9043]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7803011   0.01877903]\n",
            "iteration 5381\n",
            "q values:  tensor([[4.9907, 4.8591, 4.9206]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.76078154  0.01951956]\n",
            "iteration 5382\n",
            "q values:  tensor([[5.0000, 4.8568, 4.9122]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.74062946  0.02015208]\n",
            "iteration 5383\n",
            "q values:  tensor([[5.0039, 4.8661, 4.9249]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.71996224  0.02066722]\n",
            "iteration 5384\n",
            "q values:  tensor([[4.9947, 4.8644, 4.9269]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.69890601  0.02105623]\n",
            "iteration 5385\n",
            "q values:  tensor([[4.9804, 4.8668, 4.9379]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.67559475  0.02331126]\n",
            "iteration 5386\n",
            "q values:  tensor([[4.9763, 4.8649, 4.9371]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.65218262  0.02341213]\n",
            "iteration 5387\n",
            "q values:  tensor([[4.9751, 4.8608, 4.9312]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62882986  0.02335277]\n",
            "iteration 5388\n",
            "q values:  tensor([[4.9832, 4.8554, 4.9186]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6047009   0.02412896]\n",
            "iteration 5389\n",
            "q values:  tensor([[4.9921, 4.8588, 4.9194]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.58096966  0.02373124]\n",
            "iteration 5390\n",
            "q values:  tensor([[4.9856, 4.8588, 4.9227]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55781026  0.0231594 ]\n",
            "iteration 5391\n",
            "q values:  tensor([[4.9750, 4.8634, 4.9353]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53339472  0.02441554]\n",
            "iteration 5392\n",
            "q values:  tensor([[4.9758, 4.8694, 4.9445]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.50990572  0.023489  ]\n",
            "iteration 5393\n",
            "q values:  tensor([[4.9825, 4.8612, 4.9280]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.4855194   0.02438633]\n",
            "iteration 5394\n",
            "q values:  tensor([[4.9830, 4.8643, 4.9327]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.46241804  0.02310135]\n",
            "iteration 5395\n",
            "q values:  tensor([[4.9774, 4.8662, 4.9386]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.44077298  0.02164507]\n",
            "iteration 5396\n",
            "q values:  tensor([[4.9775, 4.8653, 4.9371]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.41874273  0.02203025]\n",
            "iteration 5397\n",
            "q values:  tensor([[4.9779, 4.8674, 4.9401]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.397486    0.02125673]\n",
            "iteration 5398\n",
            "q values:  tensor([[4.9731, 4.8720, 4.9498]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.3781527   0.01933329]\n",
            "iteration 5399\n",
            "q values:  tensor([[4.9815, 4.8743, 4.9491]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36087597  0.01727673]\n",
            "iteration 5400\n",
            "q values:  tensor([[4.9890, 4.8682, 4.9357]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.34577176  0.01510421]\n",
            "iteration 5401\n",
            "q values:  tensor([[4.9969, 4.8628, 4.9232]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.33193889  0.01383287]\n",
            "iteration 5402\n",
            "q values:  tensor([[5.0010, 4.8654, 4.9251]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.32046556  0.01147333]\n",
            "iteration 5403\n",
            "q values:  tensor([[4.9929, 4.8705, 4.9374]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.31142317  0.00904239]\n",
            "iteration 5404\n",
            "q values:  tensor([[4.9809, 4.8735, 4.9483]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.30386679  0.00755638]\n",
            "iteration 5405\n",
            "q values:  tensor([[4.9792, 4.8703, 4.9441]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.29884161  0.00502517]\n",
            "iteration 5406\n",
            "q values:  tensor([[4.9815, 4.8663, 4.9366]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.29537726  0.00346435]\n",
            "iteration 5407\n",
            "q values:  tensor([[4.9835, 4.8625, 4.9297]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.29449394  0.00088332]\n",
            "iteration 5408\n",
            "q values:  tensor([[4.9841, 4.8596, 4.9248]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.29519678 -0.00070284]\n",
            "iteration 5409\n",
            "q values:  tensor([[4.9829, 4.8587, 4.9238]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.2964817  -0.00128492]\n",
            "iteration 5410\n",
            "q values:  tensor([[4.9823, 4.8579, 4.9229]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.30034123 -0.00385953]\n",
            "iteration 5411\n",
            "q values:  tensor([[4.9808, 4.8581, 4.9241]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.30575278 -0.00541155]\n",
            "iteration 5412\n",
            "q values:  tensor([[4.9776, 4.8600, 4.9287]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.31368432 -0.00793155]\n",
            "iteration 5413\n",
            "q values:  tensor([[4.9701, 4.8580, 4.9294]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.32208821 -0.00840389]\n",
            "iteration 5414\n",
            "q values:  tensor([[4.9649, 4.8506, 4.9203]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.33091305 -0.00882483]\n",
            "iteration 5415\n",
            "q values:  tensor([[5.0007, 4.8616, 4.9194]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.34010387 -0.00919083]\n",
            "iteration 5416\n",
            "q values:  tensor([[5.0079, 4.8562, 4.9072]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35060245 -0.01049858]\n",
            "iteration 5417\n",
            "q values:  tensor([[5.0074, 4.8523, 4.9013]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36334103 -0.01273858]\n",
            "iteration 5418\n",
            "q values:  tensor([[4.9992, 4.8412, 4.8880]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.37723578 -0.01389475]\n",
            "iteration 5419\n",
            "q values:  tensor([[4.9949, 4.8360, 4.8821]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.39119331 -0.01395753]\n",
            "iteration 5420\n",
            "q values:  tensor([[4.9888, 4.8387, 4.8894]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.40511797 -0.01392467]\n",
            "iteration 5421\n",
            "q values:  tensor([[4.9878, 4.8363, 4.8862]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42091265 -0.01579468]\n",
            "iteration 5422\n",
            "q values:  tensor([[4.9955, 4.8447, 4.8954]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43846535 -0.0175527 ]\n",
            "iteration 5423\n",
            "q values:  tensor([[5.0017, 4.8559, 4.9099]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45664964 -0.01818428]\n",
            "iteration 5424\n",
            "q values:  tensor([[5.0025, 4.8611, 4.9176]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47633267 -0.01968303]\n",
            "iteration 5425\n",
            "q values:  tensor([[4.9968, 4.8621, 4.9222]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.49636901 -0.02003634]\n",
            "iteration 5426\n",
            "q values:  tensor([[4.9911, 4.8578, 4.9183]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51760935 -0.02124034]\n",
            "iteration 5427\n",
            "q values:  tensor([[4.9923, 4.8551, 4.9134]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.5398946  -0.02228526]\n",
            "iteration 5428\n",
            "q values:  tensor([[4.9863, 4.8613, 4.9262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.56205769 -0.02216309]\n",
            "iteration 5429\n",
            "q values:  tensor([[4.9790, 4.8613, 4.9300]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.58293297 -0.02087528]\n",
            "iteration 5430\n",
            "q values:  tensor([[4.9804, 4.8571, 4.9227]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.60236559 -0.01943262]\n",
            "iteration 5431\n",
            "q values:  tensor([[4.9881, 4.8559, 4.9169]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.62021295 -0.01784735]\n",
            "iteration 5432\n",
            "q values:  tensor([[4.9974, 4.8503, 4.9034]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6373458  -0.01713285]\n",
            "iteration 5433\n",
            "q values:  tensor([[4.9856, 4.8512, 4.9108]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.65364201 -0.01629621]\n",
            "iteration 5434\n",
            "q values:  tensor([[4.9713, 4.8465, 4.9108]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.66898745 -0.01534544]\n",
            "iteration 5435\n",
            "q values:  tensor([[4.9737, 4.8502, 4.9152]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.68327671 -0.01428927]\n",
            "iteration 5436\n",
            "q values:  tensor([[4.9775, 4.8526, 4.9171]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.69741368 -0.01413696]\n",
            "iteration 5437\n",
            "q values:  tensor([[4.9843, 4.8581, 4.9223]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.71130531 -0.01389163]\n",
            "iteration 5438\n",
            "q values:  tensor([[4.9852, 4.8597, 4.9243]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.72286237 -0.01155706]\n",
            "iteration 5439\n",
            "q values:  tensor([[4.9874, 4.8619, 4.9266]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.73201239 -0.00915002]\n",
            "iteration 5440\n",
            "q values:  tensor([[4.9808, 4.8581, 4.9241]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.73969918 -0.00768679]\n",
            "iteration 5441\n",
            "q values:  tensor([[4.9794, 4.8585, 4.9255]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.74687639 -0.00717721]\n",
            "iteration 5442\n",
            "q values:  tensor([[4.9903, 4.8651, 4.9302]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.75250145 -0.00562507]\n",
            "iteration 5443\n",
            "q values:  tensor([[4.9960, 4.8695, 4.9342]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.75754153 -0.00504008]\n",
            "iteration 5444\n",
            "q values:  tensor([[4.9984, 4.8727, 4.9380]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.76196758 -0.00442604]\n",
            "iteration 5445\n",
            "q values:  tensor([[4.9943, 4.8725, 4.9399]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.76375438 -0.0017868 ]\n",
            "iteration 5446\n",
            "q values:  tensor([[4.9895, 4.8715, 4.9407]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-7.63891837e-01 -1.37460126e-04]\n",
            "iteration 5447\n",
            "q values:  tensor([[4.9878, 4.8705, 4.9401]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.76137918  0.00251265]\n",
            "iteration 5448\n",
            "q values:  tensor([[4.9892, 4.8710, 4.9401]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.75723062  0.00414856]\n",
            "iteration 5449\n",
            "q values:  tensor([[4.9971, 4.8718, 4.9373]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.7514698   0.00576082]\n",
            "iteration 5450\n",
            "q values:  tensor([[5.0068, 4.8698, 4.9291]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.74512999  0.00633982]\n",
            "iteration 5451\n",
            "q values:  tensor([[5.0105, 4.8679, 4.9244]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73824832  0.00688166]\n",
            "iteration 5452\n",
            "q values:  tensor([[5.0084, 4.8678, 4.9252]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.72986576  0.00838256]\n",
            "iteration 5453\n",
            "q values:  tensor([[5.0014, 4.8663, 4.9264]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.72103306  0.00883271]\n",
            "iteration 5454\n",
            "q values:  tensor([[4.9941, 4.8636, 4.9259]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.71180467  0.00922839]\n",
            "iteration 5455\n",
            "q values:  tensor([[4.9827, 4.8599, 4.9258]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.70123855  0.01056612]\n",
            "iteration 5456\n",
            "q values:  tensor([[4.9824, 4.8632, 4.9312]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.68940231  0.01183625]\n",
            "iteration 5457\n",
            "q values:  tensor([[4.9768, 4.8635, 4.9347]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.67637318  0.01302912]\n",
            "iteration 5458\n",
            "q values:  tensor([[4.9730, 4.8649, 4.9387]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.66123794  0.01513524]\n",
            "iteration 5459\n",
            "q values:  tensor([[4.9736, 4.8632, 4.9358]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6450995   0.01613844]\n",
            "iteration 5460\n",
            "q values:  tensor([[4.9803, 4.8582, 4.9245]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.62806984  0.01702966]\n",
            "iteration 5461\n",
            "q values:  tensor([[4.9894, 4.8562, 4.9168]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.60926942  0.01880042]\n",
            "iteration 5462\n",
            "q values:  tensor([[4.9939, 4.8567, 4.9151]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.58983352  0.0194359 ]\n",
            "iteration 5463\n",
            "q values:  tensor([[4.9906, 4.8563, 4.9163]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57090412  0.0189294 ]\n",
            "iteration 5464\n",
            "q values:  tensor([[4.9782, 4.8590, 4.9268]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.55162111  0.019283  ]\n",
            "iteration 5465\n",
            "q values:  tensor([[4.9728, 4.8665, 4.9414]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.53312819  0.01849292]\n",
            "iteration 5466\n",
            "q values:  tensor([[4.9747, 4.8680, 4.9427]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.51356381  0.01956438]\n",
            "iteration 5467\n",
            "q values:  tensor([[4.9822, 4.8623, 4.9299]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.49507468  0.01848913]\n",
            "iteration 5468\n",
            "q values:  tensor([[4.9851, 4.8625, 4.9287]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.47579922  0.01927546]\n",
            "iteration 5469\n",
            "q values:  tensor([[4.9802, 4.8663, 4.9372]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.45588102  0.01991819]\n",
            "iteration 5470\n",
            "q values:  tensor([[4.9768, 4.8655, 4.9378]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.43646723  0.0194138 ]\n",
            "iteration 5471\n",
            "q values:  tensor([[4.9775, 4.8649, 4.9365]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.4166995   0.01976773]\n",
            "iteration 5472\n",
            "q values:  tensor([[4.9754, 4.8678, 4.9420]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.39771985  0.01897965]\n",
            "iteration 5473\n",
            "q values:  tensor([[4.9733, 4.8721, 4.9498]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.37866201  0.01905784]\n",
            "iteration 5474\n",
            "q values:  tensor([[4.9819, 4.8733, 4.9475]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36165726  0.01700475]\n",
            "iteration 5475\n",
            "q values:  tensor([[4.9894, 4.8683, 4.9358]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.34681986  0.0148374 ]\n",
            "iteration 5476\n",
            "q values:  tensor([[4.9960, 4.8619, 4.9223]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.33224702  0.01457284]\n",
            "iteration 5477\n",
            "q values:  tensor([[5.0013, 4.8652, 4.9248]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.31903178  0.01321524]\n",
            "iteration 5478\n",
            "q values:  tensor([[4.9896, 4.8714, 4.9404]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.30825628  0.01077549]\n",
            "iteration 5479\n",
            "q values:  tensor([[4.9808, 4.8733, 4.9479]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.29798584  0.01027045]\n",
            "iteration 5480\n",
            "q values:  tensor([[4.9815, 4.8690, 4.9409]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.28828122  0.00970462]\n",
            "iteration 5481\n",
            "q values:  tensor([[4.9867, 4.8651, 4.9320]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.2811985   0.00708272]\n",
            "iteration 5482\n",
            "q values:  tensor([[4.9866, 4.8622, 4.9275]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.27677773  0.00442077]\n",
            "iteration 5483\n",
            "q values:  tensor([[4.9840, 4.8607, 4.9265]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.27304354  0.00373419]\n",
            "iteration 5484\n",
            "q values:  tensor([[4.9491, 4.8235, 4.8858]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.27201649  0.00102705]\n",
            "iteration 5485\n",
            "q values:  tensor([[4.9776, 4.8544, 4.9199]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.2737022  -0.00168571]\n",
            "iteration 5486\n",
            "q values:  tensor([[4.9812, 4.8578, 4.9234]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.27709144 -0.00338924]\n",
            "iteration 5487\n",
            "q values:  tensor([[4.9815, 4.8573, 4.9224]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.28316552 -0.00607408]\n",
            "iteration 5488\n",
            "q values:  tensor([[4.9538, 4.8265, 4.8882]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.2898905  -0.00672498]\n",
            "iteration 5489\n",
            "q values:  tensor([[4.9819, 4.8565, 4.9210]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.29922817 -0.00933767]\n",
            "iteration 5490\n",
            "q values:  tensor([[4.9819, 4.8559, 4.9200]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.3091244  -0.00989623]\n",
            "iteration 5491\n",
            "q values:  tensor([[4.9678, 4.8509, 4.9194]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.32152047 -0.01239607]\n",
            "iteration 5492\n",
            "q values:  tensor([[4.9594, 4.8481, 4.9192]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.33634099 -0.01482052]\n",
            "iteration 5493\n",
            "q values:  tensor([[5.0047, 4.8652, 4.9231]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35249323 -0.01615224]\n",
            "iteration 5494\n",
            "q values:  tensor([[5.0043, 4.8479, 4.8960]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.37087313 -0.01837991]\n",
            "iteration 5495\n",
            "q values:  tensor([[4.9958, 4.8363, 4.8821]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.39135883 -0.02048569]\n",
            "iteration 5496\n",
            "q values:  tensor([[4.9893, 4.8346, 4.8828]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.41281051 -0.02145168]\n",
            "iteration 5497\n",
            "q values:  tensor([[4.9924, 4.8369, 4.8848]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.43507789 -0.02226738]\n",
            "iteration 5498\n",
            "q values:  tensor([[5.0062, 4.8509, 4.8998]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.4590014  -0.02392351]\n",
            "iteration 5499\n",
            "q values:  tensor([[5.0053, 4.8575, 4.9106]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.48440636 -0.02540496]\n",
            "iteration 5500\n",
            "q values:  tensor([[4.9971, 4.8615, 4.9211]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.51010459 -0.02569823]\n",
            "iteration 5501\n",
            "q values:  tensor([[4.9970, 4.8573, 4.9145]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.536904   -0.02679941]\n",
            "iteration 5502\n",
            "q values:  tensor([[4.9961, 4.8569, 4.9143]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.56360364 -0.02669965]\n",
            "iteration 5503\n",
            "q values:  tensor([[4.9834, 4.8598, 4.9254]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.59000397 -0.02640033]\n",
            "iteration 5504\n",
            "q values:  tensor([[4.9823, 4.8576, 4.9226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.61590955 -0.02590558]\n",
            "iteration 5505\n",
            "q values:  tensor([[4.9966, 4.8577, 4.9153]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.64113161 -0.02522206]\n",
            "iteration 5506\n",
            "q values:  tensor([[4.9848, 4.8530, 4.9140]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.66549033 -0.02435872]\n",
            "iteration 5507\n",
            "q values:  tensor([[4.9626, 4.8398, 4.9046]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.68981671 -0.02432638]\n",
            "iteration 5508\n",
            "q values:  tensor([[4.9792, 4.8545, 4.9193]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.71294748 -0.02313077]\n",
            "iteration 5509\n",
            "q values:  tensor([[4.9771, 4.8583, 4.9262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73573329 -0.02278581]\n",
            "iteration 5510\n",
            "q values:  tensor([[4.9752, 4.8658, 4.9391]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.75703333 -0.02130004]\n",
            "iteration 5511\n",
            "q values:  tensor([[4.9856, 4.8695, 4.9395]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.77572224 -0.01868891]\n",
            "iteration 5512\n",
            "q values:  tensor([[4.9806, 4.8615, 4.9295]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.79269544 -0.0169732 ]\n",
            "iteration 5513\n",
            "q values:  tensor([[4.9456, 4.8154, 4.8750]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.8088626  -0.01616716]\n",
            "iteration 5514\n",
            "q values:  tensor([[5.0130, 4.8643, 4.9173]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.82414203 -0.01527943]\n",
            "iteration 5515\n",
            "q values:  tensor([[5.0101, 4.8663, 4.9221]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.83846062 -0.01431859]\n",
            "iteration 5516\n",
            "q values:  tensor([[5.0212, 4.8675, 4.9182]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.84975357 -0.01129295]\n",
            "iteration 5517\n",
            "q values:  tensor([[5.0055, 4.8660, 4.9239]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.85797242 -0.00821885]\n",
            "iteration 5518\n",
            "q values:  tensor([[5.0155, 4.8755, 4.9336]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.86408338 -0.00611097]\n",
            "iteration 5519\n",
            "q values:  tensor([[5.0156, 4.8744, 4.9318]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.86906218 -0.0049788 ]\n",
            "iteration 5520\n",
            "q values:  tensor([[5.0190, 4.8710, 4.9248]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.87088954 -0.00182737]\n",
            "iteration 5521\n",
            "q values:  tensor([[5.0066, 4.8632, 4.9189]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-8.71558535e-01 -6.68991078e-04]\n",
            "iteration 5522\n",
            "q values:  tensor([[5.0027, 4.8627, 4.9201]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-8.71066623e-01  4.91912679e-04]\n",
            "iteration 5523\n",
            "q values:  tensor([[5.0009, 4.8636, 4.9225]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.86941566  0.00165096]\n",
            "iteration 5524\n",
            "q values:  tensor([[5.0005, 4.8644, 4.9239]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.86561193  0.00380374]\n",
            "iteration 5525\n",
            "q values:  tensor([[5.0005, 4.8652, 4.9251]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85967006  0.00594187]\n",
            "iteration 5526\n",
            "q values:  tensor([[5.0001, 4.8623, 4.9208]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.85261349  0.00705657]\n",
            "iteration 5527\n",
            "q values:  tensor([[5.0047, 4.8622, 4.9183]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84347092  0.00914257]\n",
            "iteration 5528\n",
            "q values:  tensor([[5.0095, 4.8612, 4.9143]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.83328092  0.01019   ]\n",
            "iteration 5529\n",
            "q values:  tensor([[5.0253, 4.8631, 4.9092]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82108829  0.01219262]\n",
            "iteration 5530\n",
            "q values:  tensor([[5.0024, 4.8521, 4.9035]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.80794911  0.01313918]\n",
            "iteration 5531\n",
            "q values:  tensor([[5.0028, 4.8486, 4.8979]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7939267   0.01402241]\n",
            "iteration 5532\n",
            "q values:  tensor([[4.9993, 4.8542, 4.9085]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.77709188  0.01683482]\n",
            "iteration 5533\n",
            "q values:  tensor([[4.9956, 4.8631, 4.9243]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.75953389  0.01755799]\n",
            "iteration 5534\n",
            "q values:  tensor([[4.9959, 4.8626, 4.9235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.73935047  0.02018341]\n",
            "iteration 5535\n",
            "q values:  tensor([[5.0017, 4.8670, 4.9274]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.71865956  0.02069091]\n",
            "iteration 5536\n",
            "q values:  tensor([[4.9915, 4.8639, 4.9276]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.69558777  0.02307179]\n",
            "iteration 5537\n",
            "q values:  tensor([[4.9794, 4.8674, 4.9395]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.67228255  0.02330523]\n",
            "iteration 5538\n",
            "q values:  tensor([[4.9760, 4.8644, 4.9363]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6478988   0.02438375]\n",
            "iteration 5539\n",
            "q values:  tensor([[4.9755, 4.8597, 4.9293]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62360426  0.02429454]\n",
            "iteration 5540\n",
            "q values:  tensor([[4.9852, 4.8548, 4.9166]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59957088  0.02403338]\n",
            "iteration 5541\n",
            "q values:  tensor([[4.9916, 4.8583, 4.9189]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.57497263  0.02459825]\n",
            "iteration 5542\n",
            "q values:  tensor([[4.9809, 4.8593, 4.9259]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.5489906   0.02598203]\n",
            "iteration 5543\n",
            "q values:  tensor([[4.9735, 4.8674, 4.9424]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.52381831  0.02517229]\n",
            "iteration 5544\n",
            "q values:  tensor([[4.9793, 4.8663, 4.9377]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.49864438  0.02517393]\n",
            "iteration 5545\n",
            "q values:  tensor([[4.9849, 4.8627, 4.9293]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47465743  0.02398695]\n",
            "iteration 5546\n",
            "q values:  tensor([[4.9816, 4.8654, 4.9351]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45103623  0.02362121]\n",
            "iteration 5547\n",
            "q values:  tensor([[4.9772, 4.8666, 4.9393]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42895495  0.02208127]\n",
            "iteration 5548\n",
            "q values:  tensor([[4.9792, 4.8638, 4.9338]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.40657401  0.02238095]\n",
            "iteration 5549\n",
            "q values:  tensor([[4.9742, 4.8705, 4.9469]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.38605283  0.02052118]\n",
            "iteration 5550\n",
            "q values:  tensor([[4.9774, 4.8748, 4.9520]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.36553422  0.02051861]\n",
            "iteration 5551\n",
            "q values:  tensor([[4.9879, 4.8711, 4.9408]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.34715716  0.01837706]\n",
            "iteration 5552\n",
            "q values:  tensor([[4.9935, 4.8656, 4.9294]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.32904248  0.01811468]\n",
            "iteration 5553\n",
            "q values:  tensor([[4.9992, 4.8678, 4.9298]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.31130552  0.01773696]\n",
            "iteration 5554\n",
            "q values:  tensor([[4.9857, 4.8740, 4.9466]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.29605529  0.01525023]\n",
            "iteration 5555\n",
            "q values:  tensor([[4.9822, 4.8712, 4.9439]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.28138215  0.01467314]\n",
            "iteration 5556\n",
            "q values:  tensor([[4.9873, 4.8664, 4.9338]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.26936993  0.01201222]\n",
            "iteration 5557\n",
            "q values:  tensor([[4.9844, 4.8628, 4.9297]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.26008488  0.00928505]\n",
            "iteration 5558\n",
            "q values:  tensor([[4.9612, 4.8460, 4.9151]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.25357666  0.00650822]\n",
            "iteration 5559\n",
            "q values:  tensor([[4.9624, 4.8493, 4.9196]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.24887927  0.00469738]\n",
            "iteration 5560\n",
            "q values:  tensor([[4.9655, 4.8548, 4.9267]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.24701683  0.00186244]\n",
            "iteration 5561\n",
            "q values:  tensor([[4.9672, 4.8553, 4.9265]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.24599879  0.00101804]\n",
            "iteration 5562\n",
            "q values:  tensor([[4.9712, 4.8564, 4.9262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.24683029 -0.0008315 ]\n",
            "iteration 5563\n",
            "q values:  tensor([[4.9623, 4.8438, 4.9111]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.25050713 -0.00367684]\n",
            "iteration 5564\n",
            "q values:  tensor([[4.9631, 4.8436, 4.9103]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.2570106  -0.00650347]\n",
            "iteration 5565\n",
            "q values:  tensor([[4.9715, 4.8522, 4.9196]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.26630706 -0.00929645]\n",
            "iteration 5566\n",
            "q values:  tensor([[4.9864, 4.8650, 4.9320]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.27834721 -0.01204015]\n",
            "iteration 5567\n",
            "q values:  tensor([[4.9823, 4.8610, 4.9279]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.29206523 -0.01371802]\n",
            "iteration 5568\n",
            "q values:  tensor([[4.9626, 4.8368, 4.8999]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.30638345 -0.01431822]\n",
            "iteration 5569\n",
            "q values:  tensor([[4.9662, 4.8473, 4.9146]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.3222179  -0.01583446]\n",
            "iteration 5570\n",
            "q values:  tensor([[4.9645, 4.8542, 4.9262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.3394725 -0.0172546]\n",
            "iteration 5571\n",
            "q values:  tensor([[5.0064, 4.8649, 4.9216]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.35703888 -0.01756638]\n",
            "iteration 5572\n",
            "q values:  tensor([[4.9986, 4.8401, 4.8867]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.37580313 -0.01876424]\n",
            "iteration 5573\n",
            "q values:  tensor([[4.9923, 4.8353, 4.8824]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.39463987 -0.01883675]\n",
            "iteration 5574\n",
            "q values:  tensor([[4.9887, 4.8362, 4.8856]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.41341987 -0.01877999]\n",
            "iteration 5575\n",
            "q values:  tensor([[4.9924, 4.8377, 4.8861]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43401123 -0.02059137]\n",
            "iteration 5576\n",
            "q values:  tensor([[5.0050, 4.8523, 4.9025]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45526645 -0.02125522]\n",
            "iteration 5577\n",
            "q values:  tensor([[5.0048, 4.8580, 4.9116]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47803057 -0.02276413]\n",
            "iteration 5578\n",
            "q values:  tensor([[4.9990, 4.8632, 4.9227]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.5021354  -0.02410482]\n",
            "iteration 5579\n",
            "q values:  tensor([[4.9934, 4.8586, 4.9184]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.52640109 -0.02426569]\n",
            "iteration 5580\n",
            "q values:  tensor([[4.9942, 4.8550, 4.9124]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.54964576 -0.02324467]\n",
            "iteration 5581\n",
            "q values:  tensor([[4.9828, 4.8618, 4.9288]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57369527 -0.02404952]\n",
            "iteration 5582\n",
            "q values:  tensor([[4.9798, 4.8588, 4.9258]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59837048 -0.02467521]\n",
            "iteration 5583\n",
            "q values:  tensor([[4.9850, 4.8578, 4.9214]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.62148959 -0.02311911]\n",
            "iteration 5584\n",
            "q values:  tensor([[4.9996, 4.8524, 4.9055]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.64288502 -0.02139544]\n",
            "iteration 5585\n",
            "q values:  tensor([[4.9824, 4.8531, 4.9154]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.66340479 -0.02051976]\n",
            "iteration 5586\n",
            "q values:  tensor([[4.9647, 4.8427, 4.9080]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.68390648 -0.02050169]\n",
            "iteration 5587\n",
            "q values:  tensor([[4.9800, 4.8535, 4.9172]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70225167 -0.0183452 ]\n",
            "iteration 5588\n",
            "q values:  tensor([[4.9799, 4.8570, 4.9229]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7203202  -0.01806853]\n",
            "iteration 5589\n",
            "q values:  tensor([[4.9829, 4.8597, 4.9254]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73799749 -0.01767729]\n",
            "iteration 5590\n",
            "q values:  tensor([[4.9784, 4.8653, 4.9366]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.75517539 -0.0171779 ]\n",
            "iteration 5591\n",
            "q values:  tensor([[4.9885, 4.8693, 4.9377]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.77175284 -0.01657745]\n",
            "iteration 5592\n",
            "q values:  tensor([[4.9824, 4.8625, 4.9302]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.78763635 -0.01588351]\n",
            "iteration 5593\n",
            "q values:  tensor([[4.9025, 4.7742, 4.8321]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.80074027 -0.01310392]\n",
            "iteration 5594\n",
            "q values:  tensor([[5.0104, 4.8670, 4.9230]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.81099695 -0.01025669]\n",
            "iteration 5595\n",
            "q values:  tensor([[5.0086, 4.8664, 4.9229]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.81835546 -0.0073585 ]\n",
            "iteration 5596\n",
            "q values:  tensor([[5.0118, 4.8674, 4.9228]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.82478033 -0.00642487]\n",
            "iteration 5597\n",
            "q values:  tensor([[5.0179, 4.8647, 4.9155]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82924139 -0.00446106]\n",
            "iteration 5598\n",
            "q values:  tensor([[5.0140, 4.8633, 4.9152]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.83271811 -0.00347672]\n",
            "iteration 5599\n",
            "q values:  tensor([[5.0066, 4.8600, 4.9139]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.83519473 -0.00247662]\n",
            "iteration 5600\n",
            "q values:  tensor([[5.0039, 4.8566, 4.9100]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.83666017 -0.00146544]\n",
            "iteration 5601\n",
            "q values:  tensor([[5.0069, 4.8523, 4.9017]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.83510792  0.00155225]\n",
            "iteration 5602\n",
            "q values:  tensor([[5.0061, 4.8511, 4.9001]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.83054487  0.00456305]\n",
            "iteration 5603\n",
            "q values:  tensor([[5.0033, 4.8471, 4.8953]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82399155  0.00655332]\n",
            "iteration 5604\n",
            "q values:  tensor([[5.0018, 4.8514, 4.9028]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.81647809  0.00751347]\n",
            "iteration 5605\n",
            "q values:  tensor([[5.0113, 4.8537, 4.9016]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.80603994  0.01043814]\n",
            "iteration 5606\n",
            "q values:  tensor([[5.0043, 4.8476, 4.8956]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.79272802  0.01331192]\n",
            "iteration 5607\n",
            "q values:  tensor([[4.9992, 4.8564, 4.9119]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.77860989  0.01411813]\n",
            "iteration 5608\n",
            "q values:  tensor([[4.9947, 4.8607, 4.9210]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.76376036  0.01484953]\n",
            "iteration 5609\n",
            "q values:  tensor([[4.9908, 4.8645, 4.9290]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.74826145  0.01549891]\n",
            "iteration 5610\n",
            "q values:  tensor([[5.0021, 4.8694, 4.9310]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73220228  0.01605917]\n",
            "iteration 5611\n",
            "q values:  tensor([[5.0076, 4.8637, 4.9192]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.71567872  0.01652356]\n",
            "iteration 5612\n",
            "q values:  tensor([[4.9892, 4.8640, 4.9290]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.69879298  0.01688575]\n",
            "iteration 5613\n",
            "q values:  tensor([[4.9799, 4.8657, 4.9365]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.68165294  0.01714004]\n",
            "iteration 5614\n",
            "q values:  tensor([[4.9764, 4.8645, 4.9364]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.66237142  0.01928152]\n",
            "iteration 5615\n",
            "q values:  tensor([[4.9737, 4.8627, 4.9350]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.64307891  0.01929251]\n",
            "iteration 5616\n",
            "q values:  tensor([[4.9791, 4.8586, 4.9257]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62390936  0.01916955]\n",
            "iteration 5617\n",
            "q values:  tensor([[4.9887, 4.8566, 4.9176]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.60299879  0.02091057]\n",
            "iteration 5618\n",
            "q values:  tensor([[4.9932, 4.8578, 4.9173]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.58149833  0.02150046]\n",
            "iteration 5619\n",
            "q values:  tensor([[4.9857, 4.8579, 4.9213]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.56056581  0.02093252]\n",
            "iteration 5620\n",
            "q values:  tensor([[4.9750, 4.8625, 4.9339]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.5393566   0.02120921]\n",
            "iteration 5621\n",
            "q values:  tensor([[4.9748, 4.8696, 4.9453]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51902925  0.02032735]\n",
            "iteration 5622\n",
            "q values:  tensor([[4.9802, 4.8634, 4.9327]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.49773618  0.02129308]\n",
            "iteration 5623\n",
            "q values:  tensor([[4.9874, 4.8625, 4.9276]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47763687  0.0200993 ]\n",
            "iteration 5624\n",
            "q values:  tensor([[4.9807, 4.8667, 4.9377]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45788119  0.01975568]\n",
            "iteration 5625\n",
            "q values:  tensor([[4.9781, 4.8660, 4.9379]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.43861521  0.01926598]\n",
            "iteration 5626\n",
            "q values:  tensor([[4.9763, 4.8649, 4.9370]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42097972  0.01763549]\n",
            "iteration 5627\n",
            "q values:  tensor([[4.9756, 4.8661, 4.9393]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40510177  0.01587795]\n",
            "iteration 5628\n",
            "q values:  tensor([[4.9730, 4.8706, 4.9478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.39009395  0.01500782]\n",
            "iteration 5629\n",
            "q values:  tensor([[4.9769, 4.8733, 4.9501]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.37506086  0.01503309]\n",
            "iteration 5630\n",
            "q values:  tensor([[4.9864, 4.8705, 4.9407]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.3601053   0.01495556]\n",
            "iteration 5631\n",
            "q values:  tensor([[4.9912, 4.8639, 4.9278]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.34732737  0.01277794]\n",
            "iteration 5632\n",
            "q values:  tensor([[4.9965, 4.8600, 4.9191]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.33481071  0.01251666]\n",
            "iteration 5633\n",
            "q values:  tensor([[5.0032, 4.8641, 4.9221]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.32463546  0.01017524]\n",
            "iteration 5634\n",
            "q values:  tensor([[4.9980, 4.8681, 4.9311]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.3168654   0.00777006]\n",
            "iteration 5635\n",
            "q values:  tensor([[4.9891, 4.8713, 4.9406]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.31154834  0.00531707]\n",
            "iteration 5636\n",
            "q values:  tensor([[4.9800, 4.8719, 4.9462]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.30871653  0.00283181]\n",
            "iteration 5637\n",
            "q values:  tensor([[4.9773, 4.8697, 4.9441]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.30838702  0.00032951]\n",
            "iteration 5638\n",
            "q values:  tensor([[4.9768, 4.8674, 4.9407]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.31056177 -0.00217475]\n",
            "iteration 5639\n",
            "q values:  tensor([[4.9765, 4.8661, 4.9388]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.31522772 -0.00466596]\n",
            "iteration 5640\n",
            "q values:  tensor([[4.9774, 4.8656, 4.9376]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.32035665 -0.00512893]\n",
            "iteration 5641\n",
            "q values:  tensor([[4.9716, 4.8579, 4.9284]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.32791719 -0.00756054]\n",
            "iteration 5642\n",
            "q values:  tensor([[4.9919, 4.8581, 4.9184]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.33586248 -0.00794529]\n",
            "iteration 5643\n",
            "q values:  tensor([[5.0060, 4.8562, 4.9082]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.34514253 -0.00928005]\n",
            "iteration 5644\n",
            "q values:  tensor([[5.0100, 4.8556, 4.9051]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35569797 -0.01055544]\n",
            "iteration 5645\n",
            "q values:  tensor([[5.0022, 4.8474, 4.8962]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.3684601  -0.01276212]\n",
            "iteration 5646\n",
            "q values:  tensor([[4.9993, 4.8401, 4.8862]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.38234421 -0.01388411]\n",
            "iteration 5647\n",
            "q values:  tensor([[4.9919, 4.8371, 4.8854]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.3972563  -0.01491209]\n",
            "iteration 5648\n",
            "q values:  tensor([[4.9879, 4.8378, 4.8885]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41409344 -0.01683714]\n",
            "iteration 5649\n",
            "q values:  tensor([[4.9925, 4.8380, 4.8865]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43273717 -0.01864373]\n",
            "iteration 5650\n",
            "q values:  tensor([[5.0012, 4.8521, 4.9043]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45205396 -0.01931679]\n",
            "iteration 5651\n",
            "q values:  tensor([[5.0035, 4.8598, 4.9151]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.47190323 -0.01984926]\n",
            "iteration 5652\n",
            "q values:  tensor([[4.9998, 4.8631, 4.9223]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.49313866 -0.02123543]\n",
            "iteration 5653\n",
            "q values:  tensor([[4.9924, 4.8583, 4.9185]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51560222 -0.02246356]\n",
            "iteration 5654\n",
            "q values:  tensor([[4.9929, 4.8553, 4.9135]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53712575 -0.02152353]\n",
            "iteration 5655\n",
            "q values:  tensor([[4.9875, 4.8598, 4.9233]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.55754785 -0.02042211]\n",
            "iteration 5656\n",
            "q values:  tensor([[4.9782, 4.8626, 4.9325]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57871578 -0.02116793]\n",
            "iteration 5657\n",
            "q values:  tensor([[4.9786, 4.8584, 4.9257]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.59847221 -0.01975643]\n",
            "iteration 5658\n",
            "q values:  tensor([[4.9862, 4.8559, 4.9179]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.6186718  -0.02019959]\n",
            "iteration 5659\n",
            "q values:  tensor([[4.9984, 4.8503, 4.9028]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.63716797 -0.01849617]\n",
            "iteration 5660\n",
            "q values:  tensor([[4.9861, 4.8512, 4.9105]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.65382876 -0.01666079]\n",
            "iteration 5661\n",
            "q values:  tensor([[4.9696, 4.8462, 4.9111]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.66953748 -0.01570872]\n",
            "iteration 5662\n",
            "q values:  tensor([[4.9742, 4.8501, 4.9149]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.68318629 -0.01364881]\n",
            "iteration 5663\n",
            "q values:  tensor([[4.9762, 4.8511, 4.9155]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.69568341 -0.01249711]\n",
            "iteration 5664\n",
            "q values:  tensor([[4.9830, 4.8589, 4.9242]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70594645 -0.01026305]\n",
            "iteration 5665\n",
            "q values:  tensor([[4.9826, 4.8618, 4.9290]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.71390909 -0.00796264]\n",
            "iteration 5666\n",
            "q values:  tensor([[4.9845, 4.8614, 4.9273]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.72052068 -0.0066116 ]\n",
            "iteration 5667\n",
            "q values:  tensor([[4.9953, 4.8648, 4.9272]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.72673979 -0.0062191 ]\n",
            "iteration 5668\n",
            "q values:  tensor([[4.9889, 4.8606, 4.9238]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73252791 -0.00578812]\n",
            "iteration 5669\n",
            "q values:  tensor([[4.9820, 4.8552, 4.9189]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73784966 -0.00532175]\n",
            "iteration 5670\n",
            "q values:  tensor([[4.9781, 4.8555, 4.9214]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.74067291 -0.00282325]\n",
            "iteration 5671\n",
            "q values:  tensor([[4.9855, 4.8586, 4.9224]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.74198076 -0.00130785]\n",
            "iteration 5672\n",
            "q values:  tensor([[4.9909, 4.8641, 4.9284]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.74076543  0.00121533]\n",
            "iteration 5673\n",
            "q values:  tensor([[4.9949, 4.8657, 4.9287]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73903415  0.00173128]\n",
            "iteration 5674\n",
            "q values:  tensor([[4.9946, 4.8654, 4.9285]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.73579726  0.00323689]\n",
            "iteration 5675\n",
            "q values:  tensor([[4.9939, 4.8647, 4.9278]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73207422  0.00372304]\n",
            "iteration 5676\n",
            "q values:  tensor([[4.9906, 4.8616, 4.9246]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.72788757  0.00418665]\n",
            "iteration 5677\n",
            "q values:  tensor([[4.9864, 4.8574, 4.9202]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.72326288  0.00462468]\n",
            "iteration 5678\n",
            "q values:  tensor([[4.9899, 4.8564, 4.9168]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.71722867  0.00603421]\n",
            "iteration 5679\n",
            "q values:  tensor([[4.9891, 4.8592, 4.9216]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.71082254  0.00640613]\n",
            "iteration 5680\n",
            "q values:  tensor([[4.9868, 4.8644, 4.9309]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70208491  0.00873763]\n",
            "iteration 5681\n",
            "q values:  tensor([[4.9824, 4.8635, 4.9317]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.69307168  0.00901322]\n",
            "iteration 5682\n",
            "q values:  tensor([[4.9788, 4.8638, 4.9340]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.68284147  0.01023021]\n",
            "iteration 5683\n",
            "q values:  tensor([[4.9742, 4.8645, 4.9375]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.67246185  0.01037962]\n",
            "iteration 5684\n",
            "q values:  tensor([[4.9723, 4.8657, 4.9403]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6610025   0.01145935]\n",
            "iteration 5685\n",
            "q values:  tensor([[4.9744, 4.8616, 4.9329]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.64954156  0.01146094]\n",
            "iteration 5686\n",
            "q values:  tensor([[4.9824, 4.8572, 4.9219]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.63715836  0.0123832 ]\n",
            "iteration 5687\n",
            "q values:  tensor([[4.9886, 4.8560, 4.9168]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.62393984  0.01321852]\n",
            "iteration 5688\n",
            "q values:  tensor([[4.9923, 4.8546, 4.9127]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.60998008  0.01395976]\n",
            "iteration 5689\n",
            "q values:  tensor([[4.9957, 4.8545, 4.9108]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.59437969  0.01560039]\n",
            "iteration 5690\n",
            "q values:  tensor([[4.9916, 4.8546, 4.9130]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.57725242  0.01712727]\n",
            "iteration 5691\n",
            "q values:  tensor([[4.9821, 4.8574, 4.9223]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.56072449  0.01652794]\n",
            "iteration 5692\n",
            "q values:  tensor([[4.9749, 4.8626, 4.9342]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.54491868  0.0158058 ]\n",
            "iteration 5693\n",
            "q values:  tensor([[4.9726, 4.8682, 4.9441]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.52995309  0.01496559]\n",
            "iteration 5694\n",
            "q values:  tensor([[4.9759, 4.8673, 4.9411]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51593984  0.01401325]\n",
            "iteration 5695\n",
            "q values:  tensor([[4.9820, 4.8620, 4.9295]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.50298403  0.01295581]\n",
            "iteration 5696\n",
            "q values:  tensor([[4.9855, 4.8615, 4.9270]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.49118273  0.0118013 ]\n",
            "iteration 5697\n",
            "q values:  tensor([[4.9835, 4.8635, 4.9311]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.47862417  0.01255856]\n",
            "iteration 5698\n",
            "q values:  tensor([[4.9817, 4.8647, 4.9341]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.46740189  0.01122227]\n",
            "iteration 5699\n",
            "q values:  tensor([[4.9801, 4.8640, 4.9338]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.4565991   0.01080279]\n",
            "iteration 5700\n",
            "q values:  tensor([[4.9756, 4.8643, 4.9364]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.44629543  0.01030367]\n",
            "iteration 5701\n",
            "q values:  tensor([[4.9755, 4.8642, 4.9364]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43756635  0.00872908]\n",
            "iteration 5702\n",
            "q values:  tensor([[4.9784, 4.8623, 4.9319]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.42847537  0.00909098]\n",
            "iteration 5703\n",
            "q values:  tensor([[4.9810, 4.8618, 4.9297]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42108818  0.00738719]\n",
            "iteration 5704\n",
            "q values:  tensor([[4.9785, 4.8641, 4.9346]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41545775  0.00563043]\n",
            "iteration 5705\n",
            "q values:  tensor([[4.9770, 4.8658, 4.9381]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41162423  0.00383352]\n",
            "iteration 5706\n",
            "q values:  tensor([[4.9799, 4.8666, 4.9378]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.40861481  0.00300942]\n",
            "iteration 5707\n",
            "q values:  tensor([[4.9807, 4.8660, 4.9365]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.40645078  0.00216404]\n",
            "iteration 5708\n",
            "q values:  tensor([[4.9798, 4.8649, 4.9353]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.40414737  0.0023034 ]\n",
            "iteration 5709\n",
            "q values:  tensor([[4.9794, 4.8637, 4.9336]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.4037208   0.00042657]\n",
            "iteration 5710\n",
            "q values:  tensor([[4.9780, 4.8618, 4.9313]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40517406 -0.00145326]\n",
            "iteration 5711\n",
            "q values:  tensor([[4.9787, 4.8595, 4.9274]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40849693 -0.00332288]\n",
            "iteration 5712\n",
            "q values:  tensor([[4.9805, 4.8570, 4.9224]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.41166602 -0.00316909]\n",
            "iteration 5713\n",
            "q values:  tensor([[4.9833, 4.8578, 4.9223]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.41565892 -0.00399289]\n",
            "iteration 5714\n",
            "q values:  tensor([[4.9846, 4.8592, 4.9239]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.41944729 -0.00378837]\n",
            "iteration 5715\n",
            "q values:  tensor([[4.9860, 4.8603, 4.9249]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.42300414 -0.00355686]\n",
            "iteration 5716\n",
            "q values:  tensor([[4.9871, 4.8611, 4.9255]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.42730406 -0.00429992]\n",
            "iteration 5717\n",
            "q values:  tensor([[4.9878, 4.8608, 4.9247]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43331618 -0.00601212]\n",
            "iteration 5718\n",
            "q values:  tensor([[4.9914, 4.8584, 4.9191]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.44099718 -0.007681  ]\n",
            "iteration 5719\n",
            "q values:  tensor([[4.9941, 4.8558, 4.9137]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.45029137 -0.00929419]\n",
            "iteration 5720\n",
            "q values:  tensor([[4.9921, 4.8581, 4.9182]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.46113094 -0.01083957]\n",
            "iteration 5721\n",
            "q values:  tensor([[4.9923, 4.8593, 4.9201]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47343628 -0.01230534]\n",
            "iteration 5722\n",
            "q values:  tensor([[4.9935, 4.8600, 4.9205]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.48511642 -0.01168014]\n",
            "iteration 5723\n",
            "q values:  tensor([[4.9859, 4.8567, 4.9193]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.49708454 -0.01196812]\n",
            "iteration 5724\n",
            "q values:  tensor([[4.9863, 4.8558, 4.9176]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.5102513  -0.01316677]\n",
            "iteration 5725\n",
            "q values:  tensor([[4.9895, 4.8561, 4.9165]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.52451815 -0.01426685]\n",
            "iteration 5726\n",
            "q values:  tensor([[4.9837, 4.8602, 4.9259]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.5397781  -0.01525995]\n",
            "iteration 5727\n",
            "q values:  tensor([[4.9781, 4.8637, 4.9342]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55591675 -0.01613865]\n",
            "iteration 5728\n",
            "q values:  tensor([[4.9748, 4.8642, 4.9367]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.5728134  -0.01689665]\n",
            "iteration 5729\n",
            "q values:  tensor([[4.9784, 4.8598, 4.9280]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.58934228 -0.01652888]\n",
            "iteration 5730\n",
            "q values:  tensor([[4.9835, 4.8554, 4.9184]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.60538127 -0.01603899]\n",
            "iteration 5731\n",
            "q values:  tensor([[4.9922, 4.8528, 4.9099]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.61981303 -0.01443176]\n",
            "iteration 5732\n",
            "q values:  tensor([[4.9955, 4.8503, 4.9043]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.63253316 -0.01272013]\n",
            "iteration 5733\n",
            "q values:  tensor([[4.9884, 4.8505, 4.9082]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.64545075 -0.01291759]\n",
            "iteration 5734\n",
            "q values:  tensor([[4.9793, 4.8541, 4.9186]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.65847466 -0.01302392]\n",
            "iteration 5735\n",
            "q values:  tensor([[4.9733, 4.8491, 4.9138]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.67151439 -0.01303972]\n",
            "iteration 5736\n",
            "q values:  tensor([[4.9739, 4.8487, 4.9128]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.68248079 -0.01096641]\n",
            "iteration 5737\n",
            "q values:  tensor([[4.9787, 4.8514, 4.9146]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6923002 -0.0098194]\n",
            "iteration 5738\n",
            "q values:  tensor([[4.9821, 4.8599, 4.9262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.70090767 -0.00860747]\n",
            "iteration 5739\n",
            "q values:  tensor([[4.9800, 4.8632, 4.9324]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70724715 -0.00633948]\n",
            "iteration 5740\n",
            "q values:  tensor([[4.9783, 4.8641, 4.9347]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7132779  -0.00603075]\n",
            "iteration 5741\n",
            "q values:  tensor([[4.9866, 4.8626, 4.9282]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7189616 -0.0056837]\n",
            "iteration 5742\n",
            "q values:  tensor([[4.9936, 4.8649, 4.9282]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.72426253 -0.00530093]\n",
            "iteration 5743\n",
            "q values:  tensor([[4.9933, 4.8625, 4.9246]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.72814775 -0.00388522]\n",
            "iteration 5744\n",
            "q values:  tensor([[4.9871, 4.8564, 4.9182]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73159334 -0.00344559]\n",
            "iteration 5745\n",
            "q values:  tensor([[4.9821, 4.8533, 4.9159]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.73257825 -0.00098491]\n",
            "iteration 5746\n",
            "q values:  tensor([[4.9812, 4.8527, 4.9154]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-7.33096484e-01 -5.18235406e-04]\n",
            "iteration 5747\n",
            "q values:  tensor([[4.9801, 4.8521, 4.9150]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.7321449   0.00095158]\n",
            "iteration 5748\n",
            "q values:  tensor([[4.9802, 4.8526, 4.9158]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73072928  0.00141562]\n",
            "iteration 5749\n",
            "q values:  tensor([[4.9806, 4.8525, 4.9153]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.72685825  0.00387104]\n",
            "iteration 5750\n",
            "q values:  tensor([[4.9865, 4.8548, 4.9159]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7225555   0.00430275]\n",
            "iteration 5751\n",
            "q values:  tensor([[4.9911, 4.8572, 4.9173]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.71684761  0.00570789]\n",
            "iteration 5752\n",
            "q values:  tensor([[4.9904, 4.8609, 4.9236]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70877019  0.00807742]\n",
            "iteration 5753\n",
            "q values:  tensor([[4.9849, 4.8639, 4.9310]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.69837431  0.01039587]\n",
            "iteration 5754\n",
            "q values:  tensor([[4.9806, 4.8638, 4.9331]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.68772687  0.01064745]\n",
            "iteration 5755\n",
            "q values:  tensor([[4.9763, 4.8639, 4.9354]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.6748976   0.01282927]\n",
            "iteration 5756\n",
            "q values:  tensor([[4.9722, 4.8654, 4.9400]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.65997215  0.01492545]\n",
            "iteration 5757\n",
            "q values:  tensor([[4.9749, 4.8621, 4.9333]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6440522   0.01591995]\n",
            "iteration 5758\n",
            "q values:  tensor([[4.9806, 4.8581, 4.9242]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62824838  0.01580382]\n",
            "iteration 5759\n",
            "q values:  tensor([[4.9899, 4.8560, 4.9162]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.61167252  0.01657586]\n",
            "iteration 5760\n",
            "q values:  tensor([[4.9950, 4.8557, 4.9130]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59544377  0.01622875]\n",
            "iteration 5761\n",
            "q values:  tensor([[4.9930, 4.8551, 4.9131]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57968034  0.01576343]\n",
            "iteration 5762\n",
            "q values:  tensor([[4.9844, 4.8561, 4.9191]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.56349828  0.01618206]\n",
            "iteration 5763\n",
            "q values:  tensor([[4.9751, 4.8617, 4.9326]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.54701769  0.01648059]\n",
            "iteration 5764\n",
            "q values:  tensor([[4.9720, 4.8679, 4.9439]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.5313616   0.01565609]\n",
            "iteration 5765\n",
            "q values:  tensor([[4.9750, 4.8680, 4.9426]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51664729  0.01471431]\n",
            "iteration 5766\n",
            "q values:  tensor([[4.9814, 4.8631, 4.9317]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.50198512  0.01466217]\n",
            "iteration 5767\n",
            "q values:  tensor([[4.9864, 4.8614, 4.9264]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.48848494  0.01350018]\n",
            "iteration 5768\n",
            "q values:  tensor([[4.9831, 4.8648, 4.9334]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47624762  0.01223732]\n",
            "iteration 5769\n",
            "q values:  tensor([[4.9817, 4.8651, 4.9345]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.46536424  0.01088338]\n",
            "iteration 5770\n",
            "q values:  tensor([[4.9792, 4.8634, 4.9333]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45491541  0.01044884]\n",
            "iteration 5771\n",
            "q values:  tensor([[4.9751, 4.8645, 4.9371]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.44597806  0.00893735]\n",
            "iteration 5772\n",
            "q values:  tensor([[4.9755, 4.8638, 4.9357]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43861762  0.00736044]\n",
            "iteration 5773\n",
            "q values:  tensor([[4.9789, 4.8617, 4.9307]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.43088766  0.00772996]\n",
            "iteration 5774\n",
            "q values:  tensor([[4.9821, 4.8613, 4.9283]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.4248441   0.00604356]\n",
            "iteration 5775\n",
            "q values:  tensor([[4.9825, 4.8618, 4.9291]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42053041  0.00431369]\n",
            "iteration 5776\n",
            "q values:  tensor([[4.9802, 4.8632, 4.9325]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41797748  0.00255293]\n",
            "iteration 5777\n",
            "q values:  tensor([[4.9799, 4.8648, 4.9350]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41720351  0.00077396]\n",
            "iteration 5778\n",
            "q values:  tensor([[4.9822, 4.8643, 4.9331]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41821403 -0.00101052]\n",
            "iteration 5779\n",
            "q values:  tensor([[4.9844, 4.8633, 4.9305]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42100184 -0.00278781]\n",
            "iteration 5780\n",
            "q values:  tensor([[4.9859, 4.8619, 4.9275]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.42354703 -0.00254519]\n",
            "iteration 5781\n",
            "q values:  tensor([[4.9868, 4.8619, 4.9270]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42783139 -0.00428436]\n",
            "iteration 5782\n",
            "q values:  tensor([[4.9881, 4.8605, 4.9242]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.43282417 -0.00499278]\n",
            "iteration 5783\n",
            "q values:  tensor([[4.9911, 4.8584, 4.9193]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.43748937 -0.0046652 ]\n",
            "iteration 5784\n",
            "q values:  tensor([[4.9914, 4.8576, 4.9179]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.44379323 -0.00630386]\n",
            "iteration 5785\n",
            "q values:  tensor([[4.9901, 4.8572, 4.9179]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.44968994 -0.0058967 ]\n",
            "iteration 5786\n",
            "q values:  tensor([[4.9888, 4.8569, 4.9180]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.45513643 -0.00544649]\n",
            "iteration 5787\n",
            "q values:  tensor([[4.9892, 4.8559, 4.9163]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.46009278 -0.00495635]\n",
            "iteration 5788\n",
            "q values:  tensor([[4.9896, 4.8580, 4.9194]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.46552255 -0.00542977]\n",
            "iteration 5789\n",
            "q values:  tensor([[4.9885, 4.8610, 4.9247]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.4723857  -0.00686314]\n",
            "iteration 5790\n",
            "q values:  tensor([[4.9854, 4.8619, 4.9276]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.47863143 -0.00624573]\n",
            "iteration 5791\n",
            "q values:  tensor([[4.9826, 4.8602, 4.9264]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.4842134  -0.00558197]\n",
            "iteration 5792\n",
            "q values:  tensor([[4.9822, 4.8584, 4.9238]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.48909007 -0.00487667]\n",
            "iteration 5793\n",
            "q values:  tensor([[4.9856, 4.8572, 4.9203]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.49522509 -0.00613502]\n",
            "iteration 5794\n",
            "q values:  tensor([[4.9873, 4.8565, 4.9183]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.50257266 -0.00734757]\n",
            "iteration 5795\n",
            "q values:  tensor([[4.9891, 4.8576, 4.9191]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.50907782 -0.00650516]\n",
            "iteration 5796\n",
            "q values:  tensor([[4.9890, 4.8579, 4.9196]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.51569185 -0.00661403]\n",
            "iteration 5797\n",
            "q values:  tensor([[4.9847, 4.8587, 4.9229]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52136518 -0.00567333]\n",
            "iteration 5798\n",
            "q values:  tensor([[4.9819, 4.8593, 4.9254]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.52705526 -0.00569008]\n",
            "iteration 5799\n",
            "q values:  tensor([[4.9799, 4.8607, 4.9287]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.53371942 -0.00666416]\n",
            "iteration 5800\n",
            "q values:  tensor([[4.9761, 4.8641, 4.9360]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53930769 -0.00558826]\n",
            "iteration 5801\n",
            "q values:  tensor([[4.9747, 4.8667, 4.9407]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.54477818 -0.00547049]\n",
            "iteration 5802\n",
            "q values:  tensor([[4.9732, 4.8678, 4.9431]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.55008993 -0.00531175]\n",
            "iteration 5803\n",
            "q values:  tensor([[4.9734, 4.8678, 4.9430]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.55520321 -0.00511328]\n",
            "iteration 5804\n",
            "q values:  tensor([[4.9754, 4.8659, 4.9391]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.55907981 -0.0038766 ]\n",
            "iteration 5805\n",
            "q values:  tensor([[4.9751, 4.8656, 4.9387]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.5636908  -0.00461099]\n",
            "iteration 5806\n",
            "q values:  tensor([[4.9758, 4.8646, 4.9369]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.56700183 -0.00331103]\n",
            "iteration 5807\n",
            "q values:  tensor([[4.9764, 4.8633, 4.9344]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57098826 -0.00398642]\n",
            "iteration 5808\n",
            "q values:  tensor([[4.9758, 4.8621, 4.9329]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57562046 -0.0046322 ]\n",
            "iteration 5809\n",
            "q values:  tensor([[4.9767, 4.8593, 4.9281]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.57886408 -0.00324362]\n",
            "iteration 5810\n",
            "q values:  tensor([[4.9769, 4.8592, 4.9278]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.5816951  -0.00283103]\n",
            "iteration 5811\n",
            "q values:  tensor([[4.9791, 4.8579, 4.9246]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.58509261 -0.00339751]\n",
            "iteration 5812\n",
            "q values:  tensor([[4.9801, 4.8570, 4.9226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.58703152 -0.00193891]\n",
            "iteration 5813\n",
            "q values:  tensor([[4.9812, 4.8569, 4.9219]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.58849756 -0.00146603]\n",
            "iteration 5814\n",
            "q values:  tensor([[4.9818, 4.8570, 4.9219]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.58947992 -0.00098236]\n",
            "iteration 5815\n",
            "q values:  tensor([[4.9821, 4.8569, 4.9215]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59097138 -0.00149146]\n",
            "iteration 5816\n",
            "q values:  tensor([[4.9834, 4.8560, 4.9193]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-5.90960987e-01  1.03964112e-05]\n",
            "iteration 5817\n",
            "q values:  tensor([[4.9838, 4.8562, 4.9195]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.58944881  0.00151218]\n",
            "iteration 5818\n",
            "q values:  tensor([[4.9834, 4.8568, 4.9208]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.58644595  0.00300285]\n",
            "iteration 5819\n",
            "q values:  tensor([[4.9819, 4.8572, 4.9221]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.58297454  0.00347142]\n",
            "iteration 5820\n",
            "q values:  tensor([[4.9797, 4.8584, 4.9252]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.58006015  0.00291438]\n",
            "iteration 5821\n",
            "q values:  tensor([[4.9776, 4.8594, 4.9277]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.57572433  0.00433582]\n",
            "iteration 5822\n",
            "q values:  tensor([[4.9748, 4.8606, 4.9311]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.57099916  0.00472517]\n",
            "iteration 5823\n",
            "q values:  tensor([[4.9725, 4.8627, 4.9355]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.56591968  0.00507948]\n",
            "iteration 5824\n",
            "q values:  tensor([[4.9723, 4.8636, 4.9370]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.56152365  0.00439603]\n",
            "iteration 5825\n",
            "q values:  tensor([[4.9728, 4.8650, 4.9390]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55784379  0.00367986]\n",
            "iteration 5826\n",
            "q values:  tensor([[4.9733, 4.8665, 4.9412]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55490755  0.00293624]\n",
            "iteration 5827\n",
            "q values:  tensor([[4.9747, 4.8669, 4.9410]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.55073684  0.00417071]\n",
            "iteration 5828\n",
            "q values:  tensor([[4.9747, 4.8681, 4.9428]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.54536281  0.00537402]\n",
            "iteration 5829\n",
            "q values:  tensor([[4.9753, 4.8686, 4.9434]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.54082568  0.00453714]\n",
            "iteration 5830\n",
            "q values:  tensor([[4.9764, 4.8693, 4.9439]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.53615939  0.00466628]\n",
            "iteration 5831\n",
            "q values:  tensor([[4.9762, 4.8685, 4.9428]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.53139893  0.00476046]\n",
            "iteration 5832\n",
            "q values:  tensor([[4.9758, 4.8680, 4.9422]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.52657997  0.00481896]\n",
            "iteration 5833\n",
            "q values:  tensor([[4.9794, 4.8651, 4.9358]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.52273865  0.00384132]\n",
            "iteration 5834\n",
            "q values:  tensor([[4.9790, 4.8634, 4.9333]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51990378  0.00283487]\n",
            "iteration 5835\n",
            "q values:  tensor([[4.9796, 4.8605, 4.9285]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51809662  0.00180716]\n",
            "iteration 5836\n",
            "q values:  tensor([[4.9807, 4.8590, 4.9255]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.51533073  0.00276589]\n",
            "iteration 5837\n",
            "q values:  tensor([[4.9817, 4.8585, 4.9243]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51362684  0.00170389]\n",
            "iteration 5838\n",
            "q values:  tensor([[4.9828, 4.8585, 4.9237]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51299774  0.00062911]\n",
            "iteration 5839\n",
            "q values:  tensor([[4.9830, 4.8584, 4.9235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.51244812  0.00054962]\n",
            "iteration 5840\n",
            "q values:  tensor([[4.9828, 4.8584, 4.9235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51298212 -0.000534  ]\n",
            "iteration 5841\n",
            "q values:  tensor([[4.9830, 4.8584, 4.9234]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51459573 -0.00161361]\n",
            "iteration 5842\n",
            "q values:  tensor([[4.9833, 4.8584, 4.9233]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51727685 -0.00268113]\n",
            "iteration 5843\n",
            "q values:  tensor([[4.9825, 4.8583, 4.9235]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.51900539 -0.00172854]\n",
            "iteration 5844\n",
            "q values:  tensor([[4.9818, 4.8586, 4.9243]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.52176838 -0.00276299]\n",
            "iteration 5845\n",
            "q values:  tensor([[4.9803, 4.8596, 4.9266]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.52554509 -0.00377671]\n",
            "iteration 5846\n",
            "q values:  tensor([[4.9795, 4.8607, 4.9288]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.52930721 -0.00376212]\n",
            "iteration 5847\n",
            "q values:  tensor([[4.9777, 4.8624, 4.9324]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.53402651 -0.00471931]\n",
            "iteration 5848\n",
            "q values:  tensor([[4.9758, 4.8653, 4.9380]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53766762 -0.00364111]\n",
            "iteration 5849\n",
            "q values:  tensor([[4.9746, 4.8672, 4.9416]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.54220325 -0.00453563]\n",
            "iteration 5850\n",
            "q values:  tensor([[4.9740, 4.8683, 4.9435]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.54759941 -0.00539616]\n",
            "iteration 5851\n",
            "q values:  tensor([[4.9731, 4.8681, 4.9438]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55381573 -0.00621631]\n",
            "iteration 5852\n",
            "q values:  tensor([[4.9750, 4.8665, 4.9403]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.55980572 -0.00599   ]\n",
            "iteration 5853\n",
            "q values:  tensor([[4.9754, 4.8654, 4.9382]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.5665247  -0.00671898]\n",
            "iteration 5854\n",
            "q values:  tensor([[4.9768, 4.8630, 4.9339]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.57292263 -0.00639792]\n",
            "iteration 5855\n",
            "q values:  tensor([[4.9767, 4.8612, 4.9311]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57995197 -0.00702934]\n",
            "iteration 5856\n",
            "q values:  tensor([[4.9787, 4.8579, 4.9249]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.58556068 -0.00560871]\n",
            "iteration 5857\n",
            "q values:  tensor([[4.9812, 4.8567, 4.9216]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59170734 -0.00614666]\n",
            "iteration 5858\n",
            "q values:  tensor([[4.9836, 4.8558, 4.9190]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59834673 -0.0066394 ]\n",
            "iteration 5859\n",
            "q values:  tensor([[4.9873, 4.8541, 4.9145]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.60343021 -0.00508347]\n",
            "iteration 5860\n",
            "q values:  tensor([[4.9920, 4.8524, 4.9093]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60892065 -0.00549044]\n",
            "iteration 5861\n",
            "q values:  tensor([[4.9975, 4.8519, 4.9057]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.61277814 -0.00385749]\n",
            "iteration 5862\n",
            "q values:  tensor([[4.9991, 4.8525, 4.9059]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.61697474 -0.0041966 ]\n",
            "iteration 5863\n",
            "q values:  tensor([[4.9982, 4.8518, 4.9053]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62148015 -0.0045054 ]\n",
            "iteration 5864\n",
            "q values:  tensor([[4.9954, 4.8509, 4.9052]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.62526194 -0.0037818 ]\n",
            "iteration 5865\n",
            "q values:  tensor([[4.9940, 4.8505, 4.9053]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62929303 -0.00403109]\n",
            "iteration 5866\n",
            "q values:  tensor([[4.9910, 4.8505, 4.9069]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.63354463 -0.0042516 ]\n",
            "iteration 5867\n",
            "q values:  tensor([[4.9869, 4.8514, 4.9105]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.63698651 -0.00344188]\n",
            "iteration 5868\n",
            "q values:  tensor([[4.9848, 4.8521, 4.9126]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.63959428 -0.00260777]\n",
            "iteration 5869\n",
            "q values:  tensor([[4.9839, 4.8523, 4.9133]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.64034954 -0.00075526]\n",
            "iteration 5870\n",
            "q values:  tensor([[4.9835, 4.8524, 4.9136]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.64124696 -0.00089742]\n",
            "iteration 5871\n",
            "q values:  tensor([[4.9840, 4.8524, 4.9135]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.64228023 -0.00103327]\n",
            "iteration 5872\n",
            "q values:  tensor([[4.9845, 4.8526, 4.9135]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-6.42442074e-01 -1.61842805e-04]\n",
            "iteration 5873\n",
            "q values:  tensor([[4.9845, 4.8528, 4.9139]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.64073136  0.00171072]\n",
            "iteration 5874\n",
            "q values:  tensor([[4.9844, 4.8534, 4.9148]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.63716011  0.00357124]\n",
            "iteration 5875\n",
            "q values:  tensor([[4.9867, 4.8525, 4.9122]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.63275354  0.00440657]\n",
            "iteration 5876\n",
            "q values:  tensor([[4.9874, 4.8519, 4.9110]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.62754286  0.00521068]\n",
            "iteration 5877\n",
            "q values:  tensor([[4.9887, 4.8510, 4.9089]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62256517  0.00497769]\n",
            "iteration 5878\n",
            "q values:  tensor([[4.9915, 4.8512, 4.9078]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.61685608  0.00570908]\n",
            "iteration 5879\n",
            "q values:  tensor([[4.9940, 4.8520, 4.9077]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.60945666  0.00739942]\n",
            "iteration 5880\n",
            "q values:  tensor([[4.9955, 4.8530, 4.9086]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6014204   0.00803626]\n",
            "iteration 5881\n",
            "q values:  tensor([[4.9966, 4.8534, 4.9086]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.59180577  0.00961463]\n",
            "iteration 5882\n",
            "q values:  tensor([[4.9947, 4.8541, 4.9107]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.58068315  0.01112262]\n",
            "iteration 5883\n",
            "q values:  tensor([[4.9852, 4.8571, 4.9202]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.56913448  0.01154867]\n",
            "iteration 5884\n",
            "q values:  tensor([[4.9746, 4.8615, 4.9325]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55824536  0.01088912]\n",
            "iteration 5885\n",
            "q values:  tensor([[4.9728, 4.8649, 4.9389]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.54609685  0.01214851]\n",
            "iteration 5886\n",
            "q values:  tensor([[4.9729, 4.8684, 4.9443]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.53477974  0.01131711]\n",
            "iteration 5887\n",
            "q values:  tensor([[4.9769, 4.8685, 4.9424]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.52337878  0.01140095]\n",
            "iteration 5888\n",
            "q values:  tensor([[4.9812, 4.8644, 4.9338]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.51097948  0.0123993 ]\n",
            "iteration 5889\n",
            "q values:  tensor([[4.9843, 4.8607, 4.9263]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.4976748   0.01330468]\n",
            "iteration 5890\n",
            "q values:  tensor([[4.9835, 4.8621, 4.9289]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.48556435  0.01211045]\n",
            "iteration 5891\n",
            "q values:  tensor([[4.9830, 4.8647, 4.9334]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47473854  0.01082581]\n",
            "iteration 5892\n",
            "q values:  tensor([[4.9818, 4.8649, 4.9342]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.46427787  0.01046067]\n",
            "iteration 5893\n",
            "q values:  tensor([[4.9782, 4.8635, 4.9338]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45425977  0.01001811]\n",
            "iteration 5894\n",
            "q values:  tensor([[4.9752, 4.8644, 4.9368]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.44575796  0.00850181]\n",
            "iteration 5895\n",
            "q values:  tensor([[4.9763, 4.8636, 4.9349]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43883467  0.00692329]\n",
            "iteration 5896\n",
            "q values:  tensor([[4.9792, 4.8612, 4.9298]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.43154028  0.00729439]\n",
            "iteration 5897\n",
            "q values:  tensor([[4.9823, 4.8611, 4.9280]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.42492759  0.00661269]\n",
            "iteration 5898\n",
            "q values:  tensor([[4.9825, 4.8621, 4.9294]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.41804416  0.00688342]\n",
            "iteration 5899\n",
            "q values:  tensor([[4.9782, 4.8652, 4.9366]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.41193924  0.00610493]\n",
            "iteration 5900\n",
            "q values:  tensor([[4.9775, 4.8674, 4.9403]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40765619  0.00428305]\n",
            "iteration 5901\n",
            "q values:  tensor([[4.9800, 4.8671, 4.9387]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40522527  0.00243091]\n",
            "iteration 5902\n",
            "q values:  tensor([[4.9794, 4.8655, 4.9365]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.40366362  0.00156165]\n",
            "iteration 5903\n",
            "q values:  tensor([[4.9791, 4.8628, 4.9324]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-4.03982196e-01 -3.18576637e-04]\n",
            "iteration 5904\n",
            "q values:  tensor([[4.9782, 4.8608, 4.9296]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40617877 -0.00219657]\n",
            "iteration 5905\n",
            "q values:  tensor([[4.9792, 4.8583, 4.9252]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.40823789 -0.00205912]\n",
            "iteration 5906\n",
            "q values:  tensor([[4.9813, 4.8579, 4.9234]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.41014504 -0.00190716]\n",
            "iteration 5907\n",
            "q values:  tensor([[4.9802, 4.8594, 4.9264]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41388677 -0.00374173]\n",
            "iteration 5908\n",
            "q values:  tensor([[4.9842, 4.8597, 4.9248]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41943656 -0.00554979]\n",
            "iteration 5909\n",
            "q values:  tensor([[4.9861, 4.8584, 4.9219]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.42475492 -0.00531836]\n",
            "iteration 5910\n",
            "q values:  tensor([[4.9897, 4.8597, 4.9219]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43180379 -0.00704887]\n",
            "iteration 5911\n",
            "q values:  tensor([[4.9926, 4.8579, 4.9177]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.43853245 -0.00672866]\n",
            "iteration 5912\n",
            "q values:  tensor([[4.9935, 4.8566, 4.9153]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.44689221 -0.00835976]\n",
            "iteration 5913\n",
            "q values:  tensor([[4.9914, 4.8574, 4.9176]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.4568222  -0.00992999]\n",
            "iteration 5914\n",
            "q values:  tensor([[4.9918, 4.8584, 4.9190]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.46824967 -0.01142747]\n",
            "iteration 5915\n",
            "q values:  tensor([[4.9933, 4.8599, 4.9205]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.47909036 -0.01084069]\n",
            "iteration 5916\n",
            "q values:  tensor([[4.9892, 4.8587, 4.9208]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.48926387 -0.01017351]\n",
            "iteration 5917\n",
            "q values:  tensor([[4.9828, 4.8571, 4.9215]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.49969443 -0.01043057]\n",
            "iteration 5918\n",
            "q values:  tensor([[4.9874, 4.8557, 4.9169]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51130412 -0.01160969]\n",
            "iteration 5919\n",
            "q values:  tensor([[4.9895, 4.8565, 4.9171]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.52400601 -0.01270188]\n",
            "iteration 5920\n",
            "q values:  tensor([[4.9835, 4.8596, 4.9250]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53570484 -0.01169883]\n",
            "iteration 5921\n",
            "q values:  tensor([[4.9778, 4.8636, 4.9343]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.54831289 -0.01260805]\n",
            "iteration 5922\n",
            "q values:  tensor([[4.9729, 4.8661, 4.9407]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.56173576 -0.01342287]\n",
            "iteration 5923\n",
            "q values:  tensor([[4.9760, 4.8638, 4.9355]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.57387322 -0.01213746]\n",
            "iteration 5924\n",
            "q values:  tensor([[4.9779, 4.8596, 4.9280]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.58663505 -0.01276183]\n",
            "iteration 5925\n",
            "q values:  tensor([[4.9831, 4.8554, 4.9186]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.59892693 -0.01229187]\n",
            "iteration 5926\n",
            "q values:  tensor([[4.9880, 4.8537, 4.9134]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.61165864 -0.01273171]\n",
            "iteration 5927\n",
            "q values:  tensor([[4.9952, 4.8503, 4.9043]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.62373755 -0.01207892]\n",
            "iteration 5928\n",
            "q values:  tensor([[4.9944, 4.8497, 4.9039]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.63407667 -0.01033912]\n",
            "iteration 5929\n",
            "q values:  tensor([[4.9874, 4.8508, 4.9092]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6436023  -0.00952562]\n",
            "iteration 5930\n",
            "q values:  tensor([[4.9806, 4.8537, 4.9173]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.65224721 -0.00864491]\n",
            "iteration 5931\n",
            "q values:  tensor([[4.9768, 4.8513, 4.9155]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.66095103 -0.00870383]\n",
            "iteration 5932\n",
            "q values:  tensor([[4.9749, 4.8480, 4.9112]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.66865362 -0.00770259]\n",
            "iteration 5933\n",
            "q values:  tensor([[4.9737, 4.8473, 4.9107]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.67630231 -0.00764869]\n",
            "iteration 5934\n",
            "q values:  tensor([[4.9771, 4.8490, 4.9116]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.68384536 -0.00754305]\n",
            "iteration 5935\n",
            "q values:  tensor([[4.9823, 4.8590, 4.9247]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.69123233 -0.00738697]\n",
            "iteration 5936\n",
            "q values:  tensor([[4.9792, 4.8625, 4.9318]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.69641437 -0.00518204]\n",
            "iteration 5937\n",
            "q values:  tensor([[4.9773, 4.8647, 4.9362]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.70135759 -0.00494321]\n",
            "iteration 5938\n",
            "q values:  tensor([[4.9772, 4.8644, 4.9358]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70402991 -0.00267232]\n",
            "iteration 5939\n",
            "q values:  tensor([[4.9770, 4.8647, 4.9363]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.70541411 -0.00138421]\n",
            "iteration 5940\n",
            "q values:  tensor([[4.9793, 4.8642, 4.9345]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70450132  0.00091279]\n",
            "iteration 5941\n",
            "q values:  tensor([[4.9794, 4.8647, 4.9351]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70129739  0.00320393]\n",
            "iteration 5942\n",
            "q values:  tensor([[4.9792, 4.8651, 4.9358]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.69582295  0.00547444]\n",
            "iteration 5943\n",
            "q values:  tensor([[4.9773, 4.8651, 4.9368]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.69011354  0.00570941]\n",
            "iteration 5944\n",
            "q values:  tensor([[4.9762, 4.8648, 4.9370]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.68220656  0.00790698]\n",
            "iteration 5945\n",
            "q values:  tensor([[4.9727, 4.8662, 4.9410]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.67315441  0.00905215]\n",
            "iteration 5946\n",
            "q values:  tensor([[4.9724, 4.8655, 4.9400]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.66401785  0.00913656]\n",
            "iteration 5947\n",
            "q values:  tensor([[4.9735, 4.8620, 4.9339]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.65285901  0.01115883]\n",
            "iteration 5948\n",
            "q values:  tensor([[4.9801, 4.8579, 4.9240]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.64175484  0.01110417]\n",
            "iteration 5949\n",
            "q values:  tensor([[4.9880, 4.8565, 4.9178]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.62978294  0.0119719 ]\n",
            "iteration 5950\n",
            "q values:  tensor([[4.9906, 4.8551, 4.9143]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.61602806  0.01375488]\n",
            "iteration 5951\n",
            "q values:  tensor([[4.9940, 4.8537, 4.9104]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.60158881  0.01443925]\n",
            "iteration 5952\n",
            "q values:  tensor([[4.9945, 4.8542, 4.9109]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.58756996  0.01401885]\n",
            "iteration 5953\n",
            "q values:  tensor([[4.9907, 4.8545, 4.9133]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.57207426  0.0154957 ]\n",
            "iteration 5954\n",
            "q values:  tensor([[4.9786, 4.8594, 4.9273]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.55521627  0.01685798]\n",
            "iteration 5955\n",
            "q values:  tensor([[4.9736, 4.8658, 4.9398]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.53812151  0.01709476]\n",
            "iteration 5956\n",
            "q values:  tensor([[4.9738, 4.8689, 4.9447]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.52091787  0.01720365]\n",
            "iteration 5957\n",
            "q values:  tensor([[4.9797, 4.8650, 4.9356]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.50373433  0.01718354]\n",
            "iteration 5958\n",
            "q values:  tensor([[4.9868, 4.8623, 4.9276]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.48669968  0.01703464]\n",
            "iteration 5959\n",
            "q values:  tensor([[4.9829, 4.8646, 4.9332]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47094122  0.01575847]\n",
            "iteration 5960\n",
            "q values:  tensor([[4.9805, 4.8660, 4.9367]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.45457604  0.01636518]\n",
            "iteration 5961\n",
            "q values:  tensor([[4.9762, 4.8651, 4.9374]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43972484  0.0148512 ]\n",
            "iteration 5962\n",
            "q values:  tensor([[4.9753, 4.8655, 4.9385]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.42549609  0.01422876]\n",
            "iteration 5963\n",
            "q values:  tensor([[4.9777, 4.8645, 4.9357]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41299252  0.01250356]\n",
            "iteration 5964\n",
            "q values:  tensor([[4.9742, 4.8682, 4.9433]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.40030336  0.01268916]\n",
            "iteration 5965\n",
            "q values:  tensor([[4.9756, 4.8714, 4.9477]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.38951798  0.01078538]\n",
            "iteration 5966\n",
            "q values:  tensor([[4.9780, 4.8710, 4.9458]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.38071131  0.00880668]\n",
            "iteration 5967\n",
            "q values:  tensor([[4.9842, 4.8658, 4.9345]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.37194377  0.00876754]\n",
            "iteration 5968\n",
            "q values:  tensor([[4.9909, 4.8616, 4.9244]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.3652748   0.00666896]\n",
            "iteration 5969\n",
            "q values:  tensor([[4.9901, 4.8551, 4.9146]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.35874912  0.00652568]\n",
            "iteration 5970\n",
            "q values:  tensor([[4.9960, 4.8545, 4.9107]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.35441003  0.00433909]\n",
            "iteration 5971\n",
            "q values:  tensor([[5.0015, 4.8549, 4.9084]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.35228607  0.00212396]\n",
            "iteration 5972\n",
            "q values:  tensor([[5.0085, 4.8557, 4.9061]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-3.52391133e-01 -1.05063394e-04]\n",
            "iteration 5973\n",
            "q values:  tensor([[5.0100, 4.8529, 4.9010]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.35472454 -0.0023334 ]\n",
            "iteration 5974\n",
            "q values:  tensor([[5.0091, 4.8514, 4.8990]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.35727101 -0.00254647]\n",
            "iteration 5975\n",
            "q values:  tensor([[5.0075, 4.8494, 4.8967]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.36001381 -0.0027428 ]\n",
            "iteration 5976\n",
            "q values:  tensor([[5.0064, 4.8493, 4.8971]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36493484 -0.00492103]\n",
            "iteration 5977\n",
            "q values:  tensor([[5.0020, 4.8481, 4.8975]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.37100143 -0.00606658]\n",
            "iteration 5978\n",
            "q values:  tensor([[5.0002, 4.8458, 4.8949]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.37717293 -0.0061715 ]\n",
            "iteration 5979\n",
            "q values:  tensor([[4.9959, 4.8451, 4.8959]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.38440765 -0.00723472]\n",
            "iteration 5980\n",
            "q values:  tensor([[4.9893, 4.8432, 4.8964]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.39365623 -0.00924858]\n",
            "iteration 5981\n",
            "q values:  tensor([[4.9839, 4.8408, 4.8953]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.40285488 -0.00919865]\n",
            "iteration 5982\n",
            "q values:  tensor([[4.9859, 4.8412, 4.8949]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.41293943 -0.01008456]\n",
            "iteration 5983\n",
            "q values:  tensor([[4.9866, 4.8453, 4.9010]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.42383877 -0.01089934]\n",
            "iteration 5984\n",
            "q values:  tensor([[4.9926, 4.8529, 4.9098]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.43547519 -0.01163642]\n",
            "iteration 5985\n",
            "q values:  tensor([[4.9984, 4.8557, 4.9114]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.44676487 -0.01128968]\n",
            "iteration 5986\n",
            "q values:  tensor([[4.9968, 4.8577, 4.9153]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.45862571 -0.01186084]\n",
            "iteration 5987\n",
            "q values:  tensor([[4.9947, 4.8598, 4.9197]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.47097077 -0.01234506]\n",
            "iteration 5988\n",
            "q values:  tensor([[4.9926, 4.8598, 4.9207]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.4847089  -0.01373813]\n",
            "iteration 5989\n",
            "q values:  tensor([[4.9881, 4.8571, 4.9188]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.49973804 -0.01502914]\n",
            "iteration 5990\n",
            "q values:  tensor([[4.9862, 4.8561, 4.9182]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.51494599 -0.01520795]\n",
            "iteration 5991\n",
            "q values:  tensor([[4.9892, 4.8562, 4.9168]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52921882 -0.01427283]\n",
            "iteration 5992\n",
            "q values:  tensor([[4.9823, 4.8601, 4.9264]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.54444951 -0.01523069]\n",
            "iteration 5993\n",
            "q values:  tensor([[4.9758, 4.8647, 4.9370]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.56052392 -0.01607441]\n",
            "iteration 5994\n",
            "q values:  tensor([[4.9751, 4.8630, 4.9347]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.57632195 -0.01579804]\n",
            "iteration 5995\n",
            "q values:  tensor([[4.9788, 4.8584, 4.9256]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.59172621 -0.01540426]\n",
            "iteration 5996\n",
            "q values:  tensor([[4.9845, 4.8549, 4.9171]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60762306 -0.01589685]\n",
            "iteration 5997\n",
            "q values:  tensor([[4.9931, 4.8520, 4.9082]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62389638 -0.01627332]\n",
            "iteration 5998\n",
            "q values:  tensor([[4.9951, 4.8498, 4.9037]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.64042877 -0.01653239]\n",
            "iteration 5999\n",
            "q values:  tensor([[4.9836, 4.8520, 4.9130]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.65610277 -0.01567399]\n",
            "iteration 6000\n",
            "q values:  tensor([[4.9700, 4.8462, 4.9108]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.67180895 -0.01570618]\n",
            "iteration 6001\n",
            "q values:  tensor([[4.9749, 4.8496, 4.9137]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.68643982 -0.01463087]\n",
            "iteration 6002\n",
            "q values:  tensor([[4.9787, 4.8524, 4.9162]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.69889739 -0.01245756]\n",
            "iteration 6003\n",
            "q values:  tensor([[4.9836, 4.8594, 4.9247]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.70909998 -0.01020259]\n",
            "iteration 6004\n",
            "q values:  tensor([[4.9828, 4.8616, 4.9285]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.71898202 -0.00988204]\n",
            "iteration 6005\n",
            "q values:  tensor([[4.9902, 4.8626, 4.9263]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.72748117 -0.00849915]\n",
            "iteration 6006\n",
            "q values:  tensor([[4.9880, 4.8604, 4.9240]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.73354478 -0.00606361]\n",
            "iteration 6007\n",
            "q values:  tensor([[4.9795, 4.8568, 4.9227]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.73713585 -0.00359107]\n",
            "iteration 6008\n",
            "q values:  tensor([[4.9801, 4.8551, 4.9197]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.73823271 -0.00109686]\n",
            "iteration 6009\n",
            "q values:  tensor([[4.9831, 4.8566, 4.9206]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-7.38828767e-01 -5.96057133e-04]\n",
            "iteration 6010\n",
            "q values:  tensor([[4.9840, 4.8584, 4.9229]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.73792045  0.00090832]\n",
            "iteration 6011\n",
            "q values:  tensor([[4.9875, 4.8606, 4.9245]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.73551321  0.00240724]\n",
            "iteration 6012\n",
            "q values:  tensor([[4.9878, 4.8610, 4.9251]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.73162152  0.00389168]\n",
            "iteration 6013\n",
            "q values:  tensor([[4.9886, 4.8597, 4.9226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.72626898  0.00535254]\n",
            "iteration 6014\n",
            "q values:  tensor([[4.9884, 4.8581, 4.9202]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.72048836  0.00578063]\n",
            "iteration 6015\n",
            "q values:  tensor([[4.9910, 4.8582, 4.9189]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.71331544  0.00717292]\n",
            "iteration 6016\n",
            "q values:  tensor([[4.9865, 4.8613, 4.9262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.70579523  0.00752021]\n",
            "iteration 6017\n",
            "q values:  tensor([[4.9844, 4.8636, 4.9308]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.69797558  0.00781965]\n",
            "iteration 6018\n",
            "q values:  tensor([[4.9812, 4.8636, 4.9326]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.68990694  0.00806864]\n",
            "iteration 6019\n",
            "q values:  tensor([[4.9768, 4.8640, 4.9354]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.6806421   0.00926484]\n",
            "iteration 6020\n",
            "q values:  tensor([[4.9731, 4.8656, 4.9397]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.67124253  0.00939957]\n",
            "iteration 6021\n",
            "q values:  tensor([[4.9726, 4.8654, 4.9398]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.66177148  0.00947105]\n",
            "iteration 6022\n",
            "q values:  tensor([[4.9735, 4.8597, 4.9303]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.65129356  0.01047792]\n",
            "iteration 6023\n",
            "q values:  tensor([[4.9821, 4.8572, 4.9219]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.63988119  0.01141238]\n",
            "iteration 6024\n",
            "q values:  tensor([[4.9887, 4.8561, 4.9169]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62861427  0.01126691]\n",
            "iteration 6025\n",
            "q values:  tensor([[4.9913, 4.8547, 4.9134]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.61657271  0.01204157]\n",
            "iteration 6026\n",
            "q values:  tensor([[4.9943, 4.8534, 4.9097]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60484284  0.01172986]\n",
            "iteration 6027\n",
            "q values:  tensor([[4.9957, 4.8538, 4.9096]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.59150966  0.01333318]\n",
            "iteration 6028\n",
            "q values:  tensor([[4.9919, 4.8542, 4.9122]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.57767067  0.01383899]\n",
            "iteration 6029\n",
            "q values:  tensor([[4.9821, 4.8574, 4.9222]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.56242791  0.01524276]\n",
            "iteration 6030\n",
            "q values:  tensor([[4.9748, 4.8630, 4.9349]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.54789459  0.01453332]\n",
            "iteration 6031\n",
            "q values:  tensor([[4.9721, 4.8675, 4.9433]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.53317922  0.01471538]\n",
            "iteration 6032\n",
            "q values:  tensor([[4.9746, 4.8681, 4.9430]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.517392    0.01578722]\n",
            "iteration 6033\n",
            "q values:  tensor([[4.9823, 4.8630, 4.9309]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.50165133  0.01574067]\n",
            "iteration 6034\n",
            "q values:  tensor([[4.9861, 4.8612, 4.9262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.48707514  0.01457618]\n",
            "iteration 6035\n",
            "q values:  tensor([[4.9831, 4.8647, 4.9332]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.47377234  0.0133028 ]\n",
            "iteration 6036\n",
            "q values:  tensor([[4.9813, 4.8655, 4.9355]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.45984184  0.0139305 ]\n",
            "iteration 6037\n",
            "q values:  tensor([[4.9774, 4.8640, 4.9350]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.44538661  0.01445523]\n",
            "iteration 6038\n",
            "q values:  tensor([[4.9750, 4.8652, 4.9382]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43251261  0.01287401]\n",
            "iteration 6039\n",
            "q values:  tensor([[4.9772, 4.8639, 4.9351]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.42031328  0.01219933]\n",
            "iteration 6040\n",
            "q values:  tensor([[4.9770, 4.8658, 4.9381]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40987625  0.01043702]\n",
            "iteration 6041\n",
            "q values:  tensor([[4.9744, 4.8679, 4.9428]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.3992757   0.01060056]\n",
            "iteration 6042\n",
            "q values:  tensor([[4.9768, 4.8712, 4.9467]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.3885861  0.0106896]\n",
            "iteration 6043\n",
            "q values:  tensor([[4.9789, 4.8695, 4.9429]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.37988163  0.00870447]\n",
            "iteration 6044\n",
            "q values:  tensor([[4.9847, 4.8654, 4.9336]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.37222196  0.00765967]\n",
            "iteration 6045\n",
            "q values:  tensor([[4.9910, 4.8605, 4.9226]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36665898  0.00556297]\n",
            "iteration 6046\n",
            "q values:  tensor([[4.9898, 4.8547, 4.9141]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36323006  0.00342893]\n",
            "iteration 6047\n",
            "q values:  tensor([[4.9943, 4.8534, 4.9097]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.35995803  0.00327203]\n",
            "iteration 6048\n",
            "q values:  tensor([[4.9997, 4.8536, 4.9073]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.3588646   0.00109343]\n",
            "iteration 6049\n",
            "q values:  tensor([[5.0028, 4.8527, 4.9043]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.35795699  0.00090761]\n",
            "iteration 6050\n",
            "q values:  tensor([[5.0049, 4.8528, 4.9034]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-3.58241197e-01 -2.84206624e-04]\n",
            "iteration 6051\n",
            "q values:  tensor([[5.0063, 4.8524, 4.9020]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.35971534 -0.00147415]\n",
            "iteration 6052\n",
            "q values:  tensor([[5.0066, 4.8507, 4.8993]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36336969 -0.00365435]\n",
            "iteration 6053\n",
            "q values:  tensor([[5.0036, 4.8485, 4.8974]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36918001 -0.00581032]\n",
            "iteration 6054\n",
            "q values:  tensor([[5.0013, 4.8467, 4.8956]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.37610749 -0.00692748]\n",
            "iteration 6055\n",
            "q values:  tensor([[4.9971, 4.8448, 4.8948]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.38410541 -0.00799792]\n",
            "iteration 6056\n",
            "q values:  tensor([[4.9904, 4.8432, 4.8957]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.39311926 -0.00901385]\n",
            "iteration 6057\n",
            "q values:  tensor([[4.9850, 4.8409, 4.8949]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.40408691 -0.01096765]\n",
            "iteration 6058\n",
            "q values:  tensor([[4.9863, 4.8396, 4.8922]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41693181 -0.01284491]\n",
            "iteration 6059\n",
            "q values:  tensor([[4.9919, 4.8440, 4.8963]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43156314 -0.01463132]\n",
            "iteration 6060\n",
            "q values:  tensor([[4.9942, 4.8551, 4.9125]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.44687599 -0.01531285]\n",
            "iteration 6061\n",
            "q values:  tensor([[5.0025, 4.8587, 4.9139]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.4637592  -0.01688321]\n",
            "iteration 6062\n",
            "q values:  tensor([[4.9993, 4.8628, 4.9219]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.48008879 -0.0163296 ]\n",
            "iteration 6063\n",
            "q values:  tensor([[4.9944, 4.8602, 4.9204]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.49774379 -0.017655  ]\n",
            "iteration 6064\n",
            "q values:  tensor([[4.9890, 4.8568, 4.9179]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51659251 -0.01884871]\n",
            "iteration 6065\n",
            "q values:  tensor([[4.9914, 4.8552, 4.9140]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53449376 -0.01790126]\n",
            "iteration 6066\n",
            "q values:  tensor([[4.9835, 4.8606, 4.9267]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55331332 -0.01881956]\n",
            "iteration 6067\n",
            "q values:  tensor([[4.9765, 4.8643, 4.9360]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57291032 -0.019597  ]\n",
            "iteration 6068\n",
            "q values:  tensor([[4.9775, 4.8597, 4.9283]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59313883 -0.02022851]\n",
            "iteration 6069\n",
            "q values:  tensor([[4.9837, 4.8562, 4.9196]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.61384956 -0.02071073]\n",
            "iteration 6070\n",
            "q values:  tensor([[4.9972, 4.8530, 4.9077]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.63489165 -0.02104209]\n",
            "iteration 6071\n",
            "q values:  tensor([[4.9885, 4.8516, 4.9099]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.65611446 -0.02122282]\n",
            "iteration 6072\n",
            "q values:  tensor([[4.9664, 4.8421, 4.9063]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.67536938 -0.01925492]\n",
            "iteration 6073\n",
            "q values:  tensor([[4.9772, 4.8518, 4.9160]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.69452495 -0.01915556]\n",
            "iteration 6074\n",
            "q values:  tensor([[4.9801, 4.8550, 4.9196]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.71345401 -0.01892906]\n",
            "iteration 6075\n",
            "q values:  tensor([[4.9841, 4.8572, 4.9210]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73203491 -0.0185809 ]\n",
            "iteration 6076\n",
            "q values:  tensor([[4.9772, 4.8657, 4.9379]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.75015244 -0.01811753]\n",
            "iteration 6077\n",
            "q values:  tensor([[4.9853, 4.8698, 4.9402]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.76769865 -0.01754621]\n",
            "iteration 6078\n",
            "q values:  tensor([[4.9866, 4.8638, 4.9300]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7845734  -0.01687475]\n",
            "iteration 6079\n",
            "q values:  tensor([[4.9597, 4.8407, 4.9075]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.79968476 -0.01511136]\n",
            "iteration 6080\n",
            "q values:  tensor([[5.0098, 4.8708, 4.9293]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.81195424 -0.01226948]\n",
            "iteration 6081\n",
            "q values:  tensor([[5.0087, 4.8635, 4.9183]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82232087 -0.01036663]\n",
            "iteration 6082\n",
            "q values:  tensor([[5.0120, 4.8685, 4.9245]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.83173516 -0.00941429]\n",
            "iteration 6083\n",
            "q values:  tensor([[5.0160, 4.8669, 4.9198]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.83815379 -0.00641862]\n",
            "iteration 6084\n",
            "q values:  tensor([[5.0079, 4.8635, 4.9188]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84254813 -0.00439434]\n",
            "iteration 6085\n",
            "q values:  tensor([[4.9983, 4.8593, 4.9170]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84489902 -0.00235089]\n",
            "iteration 6086\n",
            "q values:  tensor([[5.0033, 4.8578, 4.9121]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-8.45196350e-01 -2.97333524e-04]\n",
            "iteration 6087\n",
            "q values:  tensor([[5.0013, 4.8595, 4.9158]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84343886  0.00175749]\n",
            "iteration 6088\n",
            "q values:  tensor([[5.0036, 4.8586, 4.9133]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.83963407  0.00380478]\n",
            "iteration 6089\n",
            "q values:  tensor([[5.0102, 4.8573, 4.9078]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.83279851  0.00683557]\n",
            "iteration 6090\n",
            "q values:  tensor([[5.0100, 4.8517, 4.8991]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82396249  0.00883602]\n",
            "iteration 6091\n",
            "q values:  tensor([[5.0025, 4.8507, 4.9013]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.81316645  0.01079603]\n",
            "iteration 6092\n",
            "q values:  tensor([[5.0083, 4.8506, 4.8982]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.80046169  0.01270476]\n",
            "iteration 6093\n",
            "q values:  tensor([[4.9989, 4.8486, 4.8998]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.78491111  0.01555058]\n",
            "iteration 6094\n",
            "q values:  tensor([[4.9940, 4.8589, 4.9185]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.76659534  0.01831577]\n",
            "iteration 6095\n",
            "q values:  tensor([[4.9920, 4.8592, 4.9200]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.74561428  0.02098106]\n",
            "iteration 6096\n",
            "q values:  tensor([[5.0018, 4.8690, 4.9305]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.72208852  0.02352576]\n",
            "iteration 6097\n",
            "q values:  tensor([[4.9929, 4.8646, 4.9281]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.69616051  0.02592801]\n",
            "iteration 6098\n",
            "q values:  tensor([[4.9800, 4.8669, 4.9383]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.66799533  0.02816518]\n",
            "iteration 6099\n",
            "q values:  tensor([[4.9764, 4.8629, 4.9338]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.63878073  0.0292146 ]\n",
            "iteration 6100\n",
            "q values:  tensor([[4.9766, 4.8578, 4.9257]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60971935  0.02906138]\n",
            "iteration 6101\n",
            "q values:  tensor([[4.9889, 4.8582, 4.9200]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.58101923  0.02870012]\n",
            "iteration 6102\n",
            "q values:  tensor([[4.9829, 4.8605, 4.9268]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55289059  0.02812865]\n",
            "iteration 6103\n",
            "q values:  tensor([[4.9742, 4.8657, 4.9393]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.52554254  0.02734805]\n",
            "iteration 6104\n",
            "q values:  tensor([[4.9798, 4.8665, 4.9377]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.49917991  0.02636263]\n",
            "iteration 6105\n",
            "q values:  tensor([[4.9851, 4.8623, 4.9285]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.47300025  0.02617965]\n",
            "iteration 6106\n",
            "q values:  tensor([[4.9803, 4.8658, 4.9364]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.44719863  0.02580162]\n",
            "iteration 6107\n",
            "q values:  tensor([[4.9780, 4.8663, 4.9384]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.42096501  0.02623362]\n",
            "iteration 6108\n",
            "q values:  tensor([[4.9816, 4.8669, 4.9375]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.39548904  0.02547597]\n",
            "iteration 6109\n",
            "q values:  tensor([[4.9738, 4.8725, 4.9503]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.37195041  0.02353863]\n",
            "iteration 6110\n",
            "q values:  tensor([[4.9834, 4.8736, 4.9471]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.34851031  0.0234401 ]\n",
            "iteration 6111\n",
            "q values:  tensor([[4.9909, 4.8697, 4.9371]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.32732382  0.02118649]\n",
            "iteration 6112\n",
            "q values:  tensor([[4.9988, 4.8694, 4.9327]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.30752579  0.01979803]\n",
            "iteration 6113\n",
            "q values:  tensor([[4.9872, 4.8740, 4.9459]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.28823718  0.01928861]\n",
            "iteration 6114\n",
            "q values:  tensor([[4.9846, 4.8711, 4.9426]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.27057071  0.01766646]\n",
            "iteration 6115\n",
            "q values:  tensor([[4.9862, 4.8650, 4.9322]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.25462489  0.01594582]\n",
            "iteration 6116\n",
            "q values:  tensor([[4.9542, 4.8395, 4.9084]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.24048448  0.01414042]\n",
            "iteration 6117\n",
            "q values:  tensor([[4.9567, 4.8437, 4.9137]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.22922118  0.0112633 ]\n",
            "iteration 6118\n",
            "q values:  tensor([[4.9912, 4.8762, 4.9471]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.22088971  0.00833147]\n",
            "iteration 6119\n",
            "q values:  tensor([[5.0140, 4.8897, 4.9568]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.21452912  0.00636059]\n",
            "iteration 6120\n",
            "q values:  tensor([[5.0080, 4.8850, 4.9524]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.2111684   0.00336072]\n",
            "iteration 6121\n",
            "q values:  tensor([[4.9980, 4.8796, 4.9491]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.21082257  0.00034583]\n",
            "iteration 6122\n",
            "q values:  tensor([[4.9899, 4.8743, 4.9449]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.21249317 -0.0016706 ]\n",
            "iteration 6123\n",
            "q values:  tensor([[4.9877, 4.8726, 4.9433]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.21617277 -0.0036796 ]\n",
            "iteration 6124\n",
            "q values:  tensor([[4.9584, 4.8279, 4.8881]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.22084482 -0.00467205]\n",
            "iteration 6125\n",
            "q values:  tensor([[4.9266, 4.7742, 4.8198]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.22848796 -0.00764314]\n",
            "iteration 6126\n",
            "q values:  tensor([[4.9346, 4.7686, 4.8069]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.23706641 -0.00857845]\n",
            "iteration 6127\n",
            "q values:  tensor([[4.8893, 4.7214, 4.7559]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.24853881 -0.0114724 ]\n",
            "iteration 6128\n",
            "q values:  tensor([[4.9394, 4.8017, 4.8566]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.26084788 -0.01230907]\n",
            "iteration 6129\n",
            "q values:  tensor([[4.9900, 4.8656, 4.9312]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.27592976 -0.01508188]\n",
            "iteration 6130\n",
            "q values:  tensor([[4.9460, 4.8163, 4.8761]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.29170291 -0.01577314]\n",
            "iteration 6131\n",
            "q values:  tensor([[4.8524, 4.7172, 4.7681]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.31007834 -0.01837543]\n",
            "iteration 6132\n",
            "q values:  tensor([[4.9768, 4.8647, 4.9365]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.32994788 -0.01986954]\n",
            "iteration 6133\n",
            "q values:  tensor([[4.9877, 4.8708, 4.9405]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.35018947 -0.02024159]\n",
            "iteration 6134\n",
            "q values:  tensor([[5.0042, 4.8541, 4.9058]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.37167376 -0.02148429]\n",
            "iteration 6135\n",
            "q values:  tensor([[4.9928, 4.8353, 4.8821]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.39425844 -0.02258468]\n",
            "iteration 6136\n",
            "q values:  tensor([[4.9877, 4.8364, 4.8864]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.41778902 -0.02353058]\n",
            "iteration 6137\n",
            "q values:  tensor([[4.9973, 4.8380, 4.8841]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.44309991 -0.02531089]\n",
            "iteration 6138\n",
            "q values:  tensor([[5.0081, 4.8541, 4.9037]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.46900869 -0.02590878]\n",
            "iteration 6139\n",
            "q values:  tensor([[5.0052, 4.8592, 4.9133]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.49632507 -0.02731638]\n",
            "iteration 6140\n",
            "q values:  tensor([[4.9919, 4.8592, 4.9200]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52284577 -0.0265207 ]\n",
            "iteration 6141\n",
            "q values:  tensor([[4.9976, 4.8551, 4.9108]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55037212 -0.02752635]\n",
            "iteration 6142\n",
            "q values:  tensor([[4.9853, 4.8610, 4.9263]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57869789 -0.02832577]\n",
            "iteration 6143\n",
            "q values:  tensor([[4.9837, 4.8577, 4.9220]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.60761229 -0.0289144 ]\n",
            "iteration 6144\n",
            "q values:  tensor([[4.9888, 4.8597, 4.9225]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.63690324 -0.02929095]\n",
            "iteration 6145\n",
            "q values:  tensor([[4.9898, 4.8528, 4.9111]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.66436068 -0.02745744]\n",
            "iteration 6146\n",
            "q values:  tensor([[4.9656, 4.8430, 4.9081]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.6917935  -0.02743282]\n",
            "iteration 6147\n",
            "q values:  tensor([[4.9782, 4.8538, 4.9186]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.71701771 -0.02522421]\n",
            "iteration 6148\n",
            "q values:  tensor([[4.1520, 3.9703, 3.9516]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.74187133 -0.02485362]\n",
            "iteration 6149\n",
            "q values:  tensor([[4.9779, 4.8678, 4.9409]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.76620241 -0.02433108]\n",
            "iteration 6150\n",
            "q values:  tensor([[4.9839, 4.8631, 4.9303]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.78787039 -0.02166799]\n",
            "iteration 6151\n",
            "q values:  tensor([[4.9821, 4.8662, 4.9362]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.80775755 -0.01988716]\n",
            "iteration 6152\n",
            "q values:  tensor([[5.0039, 4.8617, 4.9178]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82576243 -0.01800488]\n",
            "iteration 6153\n",
            "q values:  tensor([[5.0073, 4.8657, 4.9225]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.84279894 -0.01703651]\n",
            "iteration 6154\n",
            "q values:  tensor([[5.0178, 4.8662, 4.9180]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85779092 -0.01499198]\n",
            "iteration 6155\n",
            "q values:  tensor([[5.0166, 4.8690, 4.9229]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.87167575 -0.01388483]\n",
            "iteration 6156\n",
            "q values:  tensor([[4.9560, 4.8046, 4.8527]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.88439924 -0.01272348]\n",
            "iteration 6157\n",
            "q values:  tensor([[4.7054, 4.5297, 4.5484]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.895915   -0.01151577]\n",
            "iteration 6158\n",
            "q values:  tensor([[4.9068, 4.7502, 4.7922]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.90618385 -0.01026885]\n",
            "iteration 6159\n",
            "q values:  tensor([[5.0024, 4.8564, 4.9104]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.91517309 -0.00898924]\n",
            "iteration 6160\n",
            "q values:  tensor([[4.9886, 4.8586, 4.9208]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.92185587 -0.00668278]\n",
            "iteration 6161\n",
            "q values:  tensor([[4.9319, 4.7856, 4.8350]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.92721332 -0.00535745]\n",
            "iteration 6162\n",
            "q values:  tensor([[4.9204, 4.7583, 4.7980]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.93023099 -0.00301767]\n",
            "iteration 6163\n",
            "q values:  tensor([[5.0189, 4.8645, 4.9146]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.931901   -0.00167001]\n",
            "iteration 6164\n",
            "q values:  tensor([[5.0148, 4.8631, 4.9145]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-9.32219073e-01 -3.18072590e-04]\n",
            "iteration 6165\n",
            "q values:  tensor([[5.0154, 4.8606, 4.9103]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.9311844   0.00103467]\n",
            "iteration 6166\n",
            "q values:  tensor([[5.0299, 4.8679, 4.9144]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.92879962  0.00238478]\n",
            "iteration 6167\n",
            "q values:  tensor([[5.1047, 4.9459, 4.9988]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.9240709   0.00472873]\n",
            "iteration 6168\n",
            "q values:  tensor([[5.1335, 4.9759, 5.0312]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.91801079  0.0060601 ]\n",
            "iteration 6169\n",
            "q values:  tensor([[5.0282, 4.8662, 4.9125]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.9106361   0.00737469]\n",
            "iteration 6170\n",
            "q values:  tensor([[4.9979, 4.8474, 4.8985]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.9019683   0.00866781]\n",
            "iteration 6171\n",
            "q values:  tensor([[4.9823, 4.8547, 4.9180]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.89003404  0.01193426]\n",
            "iteration 6172\n",
            "q values:  tensor([[4.2707, 4.0968, 4.0899]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.87587255  0.01416149]\n",
            "iteration 6173\n",
            "q values:  tensor([[4.9924, 4.8518, 4.9082]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.86053408  0.01533848]\n",
            "iteration 6174\n",
            "q values:  tensor([[5.0065, 4.8554, 4.9066]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.84207745  0.01845663]\n",
            "iteration 6175\n",
            "q values:  tensor([[4.9933, 4.8556, 4.9137]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.8215794   0.02049804]\n",
            "iteration 6176\n",
            "q values:  tensor([[4.9913, 4.8438, 4.8962]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.79813249  0.02344691]\n",
            "iteration 6177\n",
            "q values:  tensor([[4.9859, 4.8524, 4.9126]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.77285159  0.02528091]\n",
            "iteration 6178\n",
            "q values:  tensor([[5.0098, 4.8779, 4.9403]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.74487069  0.0279809 ]\n",
            "iteration 6179\n",
            "q values:  tensor([[4.9997, 4.8624, 4.9212]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.71634947  0.02852121]\n",
            "iteration 6180\n",
            "q values:  tensor([[4.9855, 4.8656, 4.9334]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.68746186  0.02888762]\n",
            "iteration 6181\n",
            "q values:  tensor([[4.9791, 4.8666, 4.9383]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.65639417  0.03106769]\n",
            "iteration 6182\n",
            "q values:  tensor([[4.9772, 4.8624, 4.9326]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.62335666  0.03303751]\n",
            "iteration 6183\n",
            "q values:  tensor([[4.9783, 4.8571, 4.9238]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59058208  0.03277458]\n",
            "iteration 6184\n",
            "q values:  tensor([[4.9855, 4.8612, 4.9265]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.5573085   0.03327358]\n",
            "iteration 6185\n",
            "q values:  tensor([[4.9752, 4.8662, 4.9397]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52278252  0.03452597]\n",
            "iteration 6186\n",
            "q values:  tensor([[4.9806, 4.8675, 4.9390]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.48826267  0.03451985]\n",
            "iteration 6187\n",
            "q values:  tensor([[4.9870, 4.8624, 4.9277]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.45500735  0.03325533]\n",
            "iteration 6188\n",
            "q values:  tensor([[4.9796, 4.8690, 4.9418]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.42326283  0.03174451]\n",
            "iteration 6189\n",
            "q values:  tensor([[4.9848, 4.8673, 4.9364]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.39325953  0.03000331]\n",
            "iteration 6190\n",
            "q values:  tensor([[4.9768, 4.8724, 4.9486]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36520904  0.02805048]\n",
            "iteration 6191\n",
            "q values:  tensor([[4.9844, 4.8728, 4.9453]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.33930228  0.02590676]\n",
            "iteration 6192\n",
            "q values:  tensor([[4.9901, 4.8695, 4.9373]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.3137084   0.02559389]\n",
            "iteration 6193\n",
            "q values:  tensor([[4.9919, 4.8722, 4.9406]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.2885867   0.02512169]\n",
            "iteration 6194\n",
            "q values:  tensor([[4.9864, 4.8738, 4.9459]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.26508517  0.02350154]\n",
            "iteration 6195\n",
            "q values:  tensor([[4.9866, 4.8657, 4.9331]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.24233388  0.02275128]\n",
            "iteration 6196\n",
            "q values:  tensor([[4.9490, 4.8361, 4.9056]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.22245053  0.01988336]\n",
            "iteration 6197\n",
            "q values:  tensor([[5.0042, 4.8842, 4.9532]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.20553083  0.0169197 ]\n",
            "iteration 6198\n",
            "q values:  tensor([[4.9923, 4.8865, 4.9628]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.19065077  0.01488006]\n",
            "iteration 6199\n",
            "q values:  tensor([[4.9862, 4.8880, 4.9683]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.17787282  0.01277795]\n",
            "iteration 6200\n",
            "q values:  tensor([[4.9864, 4.8844, 4.9626]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.1672473   0.01062552]\n",
            "iteration 6201\n",
            "q values:  tensor([[4.9851, 4.8838, 4.9622]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.15881365  0.00843365]\n",
            "iteration 6202\n",
            "q values:  tensor([[4.9852, 4.8826, 4.9603]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.15160158  0.00721207]\n",
            "iteration 6203\n",
            "q values:  tensor([[4.9794, 4.8726, 4.9477]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.14663538  0.0049662 ]\n",
            "iteration 6204\n",
            "q values:  tensor([[4.9735, 4.8589, 4.9291]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.14393115  0.00270422]\n",
            "iteration 6205\n",
            "q values:  tensor([[4.9729, 4.8505, 4.9162]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.14349747  0.00043368]\n",
            "iteration 6206\n",
            "q values:  tensor([[4.9691, 4.8465, 4.9118]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.14633569 -0.00283822]\n",
            "iteration 6207\n",
            "q values:  tensor([[4.9709, 4.8533, 4.9215]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.15043684 -0.00410115]\n",
            "iteration 6208\n",
            "q values:  tensor([[4.9727, 4.8596, 4.9305]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.15778769 -0.00735084]\n",
            "iteration 6209\n",
            "q values:  tensor([[4.9716, 4.8648, 4.9394]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.16836363 -0.01057594]\n",
            "iteration 6210\n",
            "q values:  tensor([[4.9558, 4.8515, 4.9265]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.1821274  -0.01376377]\n",
            "iteration 6211\n",
            "q values:  tensor([[4.9849, 4.8701, 4.9408]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.1990272 -0.0168998]\n",
            "iteration 6212\n",
            "q values:  tensor([[4.9836, 4.8713, 4.9433]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.21699444 -0.01796725]\n",
            "iteration 6213\n",
            "q values:  tensor([[4.8910, 4.7574, 4.8116]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.23795041 -0.02095597]\n",
            "iteration 6214\n",
            "q values:  tensor([[5.0595, 4.8988, 4.9478]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.25979599 -0.02184558]\n",
            "iteration 6215\n",
            "q values:  tensor([[4.9912, 4.8558, 4.9152]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.28241993 -0.02262394]\n",
            "iteration 6216\n",
            "q values:  tensor([[4.9830, 4.8609, 4.9274]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.30769897 -0.02527904]\n",
            "iteration 6217\n",
            "q values:  tensor([[4.9728, 4.8670, 4.9421]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.33548639 -0.02778742]\n",
            "iteration 6218\n",
            "q values:  tensor([[4.9925, 4.8800, 4.9526]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36561096 -0.03012456]\n",
            "iteration 6219\n",
            "q values:  tensor([[4.9950, 4.8439, 4.8945]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.39787656 -0.0322656 ]\n",
            "iteration 6220\n",
            "q values:  tensor([[4.9818, 4.8404, 4.8957]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.43206288 -0.03418632]\n",
            "iteration 6221\n",
            "q values:  tensor([[4.9961, 4.8408, 4.8891]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.46792713 -0.03586425]\n",
            "iteration 6222\n",
            "q values:  tensor([[5.0113, 4.8515, 4.8981]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.50520697 -0.03727984]\n",
            "iteration 6223\n",
            "q values:  tensor([[4.9950, 4.8605, 4.9205]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.54362468 -0.03841771]\n",
            "iteration 6224\n",
            "q values:  tensor([[5.0040, 4.8571, 4.9107]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.58289229 -0.03926761]\n",
            "iteration 6225\n",
            "q values:  tensor([[4.9965, 4.8593, 4.9179]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.62271754 -0.03982525]\n",
            "iteration 6226\n",
            "q values:  tensor([[4.9941, 4.8638, 4.9263]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.66181031 -0.03909277]\n",
            "iteration 6227\n",
            "q values:  tensor([[4.9768, 4.8395, 4.8969]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.70089594 -0.03908563]\n",
            "iteration 6228\n",
            "q values:  tensor([[2.1643, 1.8859, 1.6986]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.73871365 -0.03781772]\n",
            "iteration 6229\n",
            "q values:  tensor([[3.2589, 3.0218, 2.9168]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.77602768 -0.03731403]\n",
            "iteration 6230\n",
            "q values:  tensor([[4.9830, 4.8661, 4.9356]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.81062433 -0.03459665]\n",
            "iteration 6231\n",
            "q values:  tensor([[4.9955, 4.8738, 4.9413]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84332462 -0.03270029]\n",
            "iteration 6232\n",
            "q values:  tensor([[5.0140, 4.8566, 4.9047]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.87497811 -0.03165349]\n",
            "iteration 6233\n",
            "q values:  tensor([[5.0092, 4.8463, 4.8910]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.90345792 -0.0284798 ]\n",
            "iteration 6234\n",
            "q values:  tensor([[4.7108, 4.5779, 4.6214]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.92866658 -0.02520866]\n",
            "iteration 6235\n",
            "q values:  tensor([[5.0039, 4.8817, 4.9494]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.95253164 -0.02386506]\n",
            "iteration 6236\n",
            "q values:  tensor([[5.0033, 4.8766, 4.9417]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.97399684 -0.0214652 ]\n",
            "iteration 6237\n",
            "q values:  tensor([[5.0046, 4.8575, 4.9110]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.99402208 -0.02002524]\n",
            "iteration 6238\n",
            "q values:  tensor([[4.9962, 4.8458, 4.8968]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.01257907 -0.01855699]\n",
            "iteration 6239\n",
            "q values:  tensor([[5.0167, 4.8578, 4.9053]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.02864953 -0.01607046]\n",
            "iteration 6240\n",
            "q values:  tensor([[5.0873, 4.9278, 4.9792]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.04322385 -0.01457433]\n",
            "iteration 6241\n",
            "q values:  tensor([[5.0078, 4.8625, 4.9172]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.05629835 -0.0130745 ]\n",
            "iteration 6242\n",
            "q values:  tensor([[5.0040, 4.8601, 4.9153]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.06587379 -0.00957543]\n",
            "iteration 6243\n",
            "q values:  tensor([[4.9992, 4.8507, 4.9030]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.07395315 -0.00807936]\n",
            "iteration 6244\n",
            "q values:  tensor([[5.0142, 4.8621, 4.9132]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.08054055 -0.00658741]\n",
            "iteration 6245\n",
            "q values:  tensor([[4.9435, 4.7920, 4.8392]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.08464046 -0.0040999 ]\n",
            "iteration 6246\n",
            "q values:  tensor([[5.0011, 4.8606, 4.9175]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.08625612 -0.00161566]\n",
            "iteration 6247\n",
            "q values:  tensor([[5.0239, 4.8749, 4.9284]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.08438892  0.0018672 ]\n",
            "iteration 6248\n",
            "q values:  tensor([[5.0256, 4.8739, 4.9261]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.07903727  0.00535165]\n",
            "iteration 6249\n",
            "q values:  tensor([[5.0226, 4.8737, 4.9272]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.07219701  0.00684026]\n",
            "iteration 6250\n",
            "q values:  tensor([[5.0108, 4.8687, 4.9255]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.06286378  0.00933323]\n",
            "iteration 6251\n",
            "q values:  tensor([[4.9875, 4.8487, 4.9058]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.05203331  0.01083047]\n",
            "iteration 6252\n",
            "q values:  tensor([[4.9989, 4.8541, 4.9085]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.03970311  0.01233021]\n",
            "iteration 6253\n",
            "q values:  tensor([[4.9909, 4.8579, 4.9186]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.02387354  0.01582957]\n",
            "iteration 6254\n",
            "q values:  tensor([[4.9888, 4.8516, 4.9098]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.00455008  0.01932346]\n",
            "iteration 6255\n",
            "q values:  tensor([[4.9823, 4.8557, 4.9196]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.98374706  0.02080302]\n",
            "iteration 6256\n",
            "q values:  tensor([[4.9724, 4.8613, 4.9334]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.96048919  0.02325787]\n",
            "iteration 6257\n",
            "q values:  tensor([[4.9964, 4.8691, 4.9333]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.93381543  0.02667376]\n",
            "iteration 6258\n",
            "q values:  tensor([[2.9811, 2.7322, 2.6034]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.9057849   0.02803053]\n",
            "iteration 6259\n",
            "q values:  tensor([[3.1679, 2.9270, 2.8141]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.874476    0.03130891]\n",
            "iteration 6260\n",
            "q values:  tensor([[4.9843, 4.8700, 4.9410]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84099527  0.03348073]\n",
            "iteration 6261\n",
            "q values:  tensor([[4.9749, 4.8444, 4.9056]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.80647782  0.03451745]\n",
            "iteration 6262\n",
            "q values:  tensor([[4.9397, 4.8150, 4.8773]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.77108442  0.0353934 ]\n",
            "iteration 6263\n",
            "q values:  tensor([[5.0353, 4.9114, 4.9801]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.73400077  0.03708365]\n",
            "iteration 6264\n",
            "q values:  tensor([[4.9849, 4.8682, 4.9378]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.69444182  0.03955895]\n",
            "iteration 6265\n",
            "q values:  tensor([[4.9811, 4.8666, 4.9373]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.65465691  0.0397849 ]\n",
            "iteration 6266\n",
            "q values:  tensor([[4.9775, 4.8630, 4.9335]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.6149142   0.03974271]\n",
            "iteration 6267\n",
            "q values:  tensor([[4.9792, 4.8599, 4.9277]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.57549516  0.03941904]\n",
            "iteration 6268\n",
            "q values:  tensor([[4.9782, 4.8638, 4.9344]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53468846  0.0408067 ]\n",
            "iteration 6269\n",
            "q values:  tensor([[4.9773, 4.8725, 4.9484]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.49279861  0.04188985]\n",
            "iteration 6270\n",
            "q values:  tensor([[4.9827, 4.8601, 4.9262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.45213943  0.04065918]\n",
            "iteration 6271\n",
            "q values:  tensor([[4.9764, 4.8705, 4.9458]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.4130121   0.03912733]\n",
            "iteration 6272\n",
            "q values:  tensor([[4.9850, 4.8706, 4.9416]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.37469904  0.03831306]\n",
            "iteration 6273\n",
            "q values:  tensor([[4.9878, 4.8766, 4.9496]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.33646596  0.03823308]\n",
            "iteration 6274\n",
            "q values:  tensor([[4.9868, 4.8772, 4.9510]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.3005638   0.03590216]\n",
            "iteration 6275\n",
            "q values:  tensor([[4.9862, 4.8745, 4.9471]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.26621235  0.03435145]\n",
            "iteration 6276\n",
            "q values:  tensor([[4.9912, 4.8747, 4.9449]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.23460511  0.03160724]\n",
            "iteration 6277\n",
            "q values:  tensor([[4.9521, 4.8344, 4.9014]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.20590382  0.02870129]\n",
            "iteration 6278\n",
            "q values:  tensor([[5.0002, 4.8869, 4.9594]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.17824055  0.02766328]\n",
            "iteration 6279\n",
            "q values:  tensor([[4.9914, 4.8787, 4.9511]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.1517283   0.02651225]\n",
            "iteration 6280\n",
            "q values:  tensor([[5.0105, 4.8844, 4.9503]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.1264615  0.0252668]\n",
            "iteration 6281\n",
            "q values:  tensor([[4.9769, 4.8520, 4.9165]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.10351693  0.02294457]\n",
            "iteration 6282\n",
            "q values:  tensor([[4.9630, 4.8533, 4.9256]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.08195277  0.02156415]\n",
            "iteration 6283\n",
            "q values:  tensor([[4.9518, 4.8209, 4.8805]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.06381344  0.01813933]\n",
            "iteration 6284\n",
            "q values:  tensor([[5.0024, 4.8601, 4.9161]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.04712843  0.01668501]\n",
            "iteration 6285\n",
            "q values:  tensor([[4.9917, 4.8499, 4.9057]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.03391848  0.01320995]\n",
            "iteration 6286\n",
            "q values:  tensor([[4.9970, 4.8611, 4.9204]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.0231956   0.01072288]\n",
            "iteration 6287\n",
            "q values:  tensor([[4.9887, 4.8577, 4.9193]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.01496667  0.00822893]\n",
            "iteration 6288\n",
            "q values:  tensor([[4.9880, 4.8642, 4.9299]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.00923522  0.00573145]\n",
            "iteration 6289\n",
            "q values:  tensor([[4.9897, 4.8643, 4.9292]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.0070028   0.00223241]\n",
            "iteration 6290\n",
            "q values:  tensor([[4.9875, 4.8619, 4.9266]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.00726984 -0.00026704]\n",
            "iteration 6291\n",
            "q values:  tensor([[4.9836, 4.8596, 4.9249]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.01103628 -0.00376644]\n",
            "iteration 6292\n",
            "q values:  tensor([[4.9881, 4.8638, 4.9293]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.01630135 -0.00526507]\n",
            "iteration 6293\n",
            "q values:  tensor([[4.9897, 4.8623, 4.9261]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.02406344 -0.00776208]\n",
            "iteration 6294\n",
            "q values:  tensor([[4.9903, 4.8551, 4.9145]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.03531901 -0.01125557]\n",
            "iteration 6295\n",
            "q values:  tensor([[5.0028, 4.8397, 4.8838]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.04806056 -0.01274155]\n",
            "iteration 6296\n",
            "q values:  tensor([[5.1560, 4.9994, 5.0566]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.06427617 -0.01621561]\n",
            "iteration 6297\n",
            "q values:  tensor([[5.0250, 4.8903, 4.9522]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.08394545 -0.01966928]\n",
            "iteration 6298\n",
            "q values:  tensor([[4.9767, 4.8473, 4.9092]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.10703586 -0.02309042]\n",
            "iteration 6299\n",
            "q values:  tensor([[4.9711, 4.8555, 4.9249]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.1334985  -0.02646263]\n",
            "iteration 6300\n",
            "q values:  tensor([[4.9346, 4.8192, 4.8865]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.1612633 -0.0277648]\n",
            "iteration 6301\n",
            "q values:  tensor([[4.9635, 4.8481, 4.9172]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.1912412 -0.0299779]\n",
            "iteration 6302\n",
            "q values:  tensor([[4.9266, 4.8047, 4.8678]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.22431881 -0.03307761]\n",
            "iteration 6303\n",
            "q values:  tensor([[4.9036, 4.7886, 4.8542]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.25835138 -0.03403257]\n",
            "iteration 6304\n",
            "q values:  tensor([[4.9857, 4.8529, 4.9134]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.29316991 -0.03481853]\n",
            "iteration 6305\n",
            "q values:  tensor([[4.9735, 4.8685, 4.9442]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.32958226 -0.03641235]\n",
            "iteration 6306\n",
            "q values:  tensor([[4.9770, 4.8703, 4.9452]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.36836895 -0.03878669]\n",
            "iteration 6307\n",
            "q values:  tensor([[4.9939, 4.8537, 4.9105]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.40827824 -0.03990929]\n",
            "iteration 6308\n",
            "q values:  tensor([[4.9810, 4.8485, 4.9089]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.44903528 -0.04075704]\n",
            "iteration 6309\n",
            "q values:  tensor([[5.0096, 4.8507, 4.8976]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.4893469  -0.04031162]\n",
            "iteration 6310\n",
            "q values:  tensor([[5.0006, 4.8567, 4.9117]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.52891496 -0.03956805]\n",
            "iteration 6311\n",
            "q values:  tensor([[4.9968, 4.8600, 4.9189]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.56944314 -0.04052819]\n",
            "iteration 6312\n",
            "q values:  tensor([[4.9951, 4.8573, 4.9154]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.61062858 -0.04118544]\n",
            "iteration 6313\n",
            "q values:  tensor([[4.9954, 4.8627, 4.9239]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.65216868 -0.0415401 ]\n",
            "iteration 6314\n",
            "q values:  tensor([[4.9843, 4.8473, 4.9052]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.69376824 -0.04159956]\n",
            "iteration 6315\n",
            "q values:  tensor([[1.9373, 1.7058, 1.6262]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.73514625 -0.04137801]\n",
            "iteration 6316\n",
            "q values:  tensor([[2.9332, 2.6824, 2.5495]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.77604203 -0.04089578]\n",
            "iteration 6317\n",
            "q values:  tensor([[4.9834, 4.8700, 4.9414]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.81522036 -0.03917833]\n",
            "iteration 6318\n",
            "q values:  tensor([[4.9911, 4.8718, 4.9403]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.85248004 -0.03725968]\n",
            "iteration 6319\n",
            "q values:  tensor([[4.9159, 4.7549, 4.7902]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.88665428 -0.03417423]\n",
            "iteration 6320\n",
            "q values:  tensor([[4.5411, 4.3584, 4.3630]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.91961291 -0.03295863]\n",
            "iteration 6321\n",
            "q values:  tensor([[4.8688, 4.7615, 4.8294]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.94925244 -0.02963953]\n",
            "iteration 6322\n",
            "q values:  tensor([[5.0005, 4.8749, 4.9404]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.97549912 -0.02624668]\n",
            "iteration 6323\n",
            "q values:  tensor([[5.0037, 4.8689, 4.9294]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.99830341 -0.02280429]\n",
            "iteration 6324\n",
            "q values:  tensor([[4.9980, 4.8517, 4.9052]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.01863455 -0.02033114]\n",
            "iteration 6325\n",
            "q values:  tensor([[5.0917, 4.9364, 4.9872]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.03547486 -0.01684031]\n",
            "iteration 6326\n",
            "q values:  tensor([[5.0351, 4.8733, 4.9202]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.04981672 -0.01434186]\n",
            "iteration 6327\n",
            "q values:  tensor([[5.0082, 4.8594, 4.9121]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.06165865 -0.01184193]\n",
            "iteration 6328\n",
            "q values:  tensor([[4.9998, 4.8566, 4.9119]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.07200294 -0.01034429]\n",
            "iteration 6329\n",
            "q values:  tensor([[5.0053, 4.8537, 4.9047]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.07885414 -0.00685121]\n",
            "iteration 6330\n",
            "q values:  tensor([[5.0104, 4.8590, 4.9103]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.08421661 -0.00536247]\n",
            "iteration 6331\n",
            "q values:  tensor([[4.9690, 4.8270, 4.8812]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.08709449 -0.00287787]\n",
            "iteration 6332\n",
            "q values:  tensor([[5.0184, 4.8715, 4.9260]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.08849024 -0.00139576]\n",
            "iteration 6333\n",
            "q values:  tensor([[5.0265, 4.8676, 4.9156]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.08640516  0.00208508]\n",
            "iteration 6334\n",
            "q values:  tensor([[5.0287, 4.8689, 4.9165]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.08183735  0.00456781]\n",
            "iteration 6335\n",
            "q values:  tensor([[5.0281, 4.8732, 4.9236]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.07478303  0.00705432]\n",
            "iteration 6336\n",
            "q values:  tensor([[5.0122, 4.8693, 4.9256]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.06523726  0.00954577]\n",
            "iteration 6337\n",
            "q values:  tensor([[4.9869, 4.8512, 4.9101]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.05319515  0.01204211]\n",
            "iteration 6338\n",
            "q values:  tensor([[4.9926, 4.8500, 4.9053]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.03865345  0.0145417 ]\n",
            "iteration 6339\n",
            "q values:  tensor([[4.9897, 4.8574, 4.9185]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.02161257  0.01704088]\n",
            "iteration 6340\n",
            "q values:  tensor([[4.9889, 4.8496, 4.9065]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.00207905  0.01953352]\n",
            "iteration 6341\n",
            "q values:  tensor([[4.9809, 4.8576, 4.9233]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.97906839  0.02301065]\n",
            "iteration 6342\n",
            "q values:  tensor([[4.9759, 4.8746, 4.9525]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.95360977  0.02545862]\n",
            "iteration 6343\n",
            "q values:  tensor([[4.4637, 4.2810, 4.2809]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.92674904  0.02686073]\n",
            "iteration 6344\n",
            "q values:  tensor([[2.1853, 1.9027, 1.7058]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.89654976  0.03019928]\n",
            "iteration 6345\n",
            "q values:  tensor([[4.9766, 4.8669, 4.9401]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.86510148  0.03144828]\n",
            "iteration 6346\n",
            "q values:  tensor([[4.9981, 4.8622, 4.9217]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.83051705  0.03458443]\n",
            "iteration 6347\n",
            "q values:  tensor([[4.8866, 4.7610, 4.8194]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.79494247  0.03557458]\n",
            "iteration 6348\n",
            "q values:  tensor([[4.9870, 4.8757, 4.9486]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.75655024  0.03839223]\n",
            "iteration 6349\n",
            "q values:  tensor([[5.0243, 4.8928, 4.9563]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.71554966  0.04100058]\n",
            "iteration 6350\n",
            "q values:  tensor([[4.9766, 4.8748, 4.9524]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.6741877   0.04136196]\n",
            "iteration 6351\n",
            "q values:  tensor([[4.9793, 4.8679, 4.9403]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.63273435  0.04145335]\n",
            "iteration 6352\n",
            "q values:  tensor([[4.9747, 4.8656, 4.9389]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.59147704  0.04125732]\n",
            "iteration 6353\n",
            "q values:  tensor([[4.9778, 4.8631, 4.9335]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55071414  0.04076289]\n",
            "iteration 6354\n",
            "q values:  tensor([[4.9728, 4.8691, 4.9455]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.50974811  0.04096603]\n",
            "iteration 6355\n",
            "q values:  tensor([[4.9825, 4.8632, 4.9311]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.46788592  0.04186218]\n",
            "iteration 6356\n",
            "q values:  tensor([[4.9784, 4.8643, 4.9351]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.42543964  0.04244628]\n",
            "iteration 6357\n",
            "q values:  tensor([[4.9852, 4.8687, 4.9384]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.38271896  0.04272068]\n",
            "iteration 6358\n",
            "q values:  tensor([[4.9900, 4.8767, 4.9486]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.3420237   0.04069526]\n",
            "iteration 6359\n",
            "q values:  tensor([[4.9883, 4.8811, 4.9564]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.3016239  0.0403998]\n",
            "iteration 6360\n",
            "q values:  tensor([[4.9829, 4.8747, 4.9491]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.26376856  0.03785534]\n",
            "iteration 6361\n",
            "q values:  tensor([[4.9947, 4.8764, 4.9458]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.22867052  0.03509804]\n",
            "iteration 6362\n",
            "q values:  tensor([[4.9421, 4.8224, 4.8877]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.19450693  0.0341636 ]\n",
            "iteration 6363\n",
            "q values:  tensor([[4.9844, 4.8736, 4.9466]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.16242965  0.03207728]\n",
            "iteration 6364\n",
            "q values:  tensor([[4.9920, 4.8726, 4.9411]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.13356139  0.02886826]\n",
            "iteration 6365\n",
            "q values:  tensor([[5.0028, 4.8754, 4.9400]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.10599511  0.02756628]\n",
            "iteration 6366\n",
            "q values:  tensor([[4.9660, 4.8491, 4.9175]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.07980351  0.02619161]\n",
            "iteration 6367\n",
            "q values:  tensor([[5.0161, 4.8779, 4.9372]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.05704059  0.02276291]\n",
            "iteration 6368\n",
            "q values:  tensor([[5.0154, 4.8718, 4.9279]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.03674117  0.02029943]\n",
            "iteration 6369\n",
            "q values:  tensor([[4.7977, 4.6664, 4.7014]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.01992657  0.0168146 ]\n",
            "iteration 6370\n",
            "q values:  tensor([[4.9876, 4.8632, 4.9286]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.00460751  0.01531906]\n",
            "iteration 6371\n",
            "q values:  tensor([[4.9815, 4.8607, 4.9278]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.0082118 0.0128193]\n",
            "iteration 6372\n",
            "q values:  tensor([[4.9765, 4.8481, 4.9105]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.01953186 0.01132006]\n",
            "iteration 6373\n",
            "q values:  tensor([[4.9735, 4.8524, 4.9188]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.02835621 0.00882435]\n",
            "iteration 6374\n",
            "q values:  tensor([[4.9660, 4.8452, 4.9114]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.0346896  0.00633339]\n",
            "iteration 6375\n",
            "q values:  tensor([[4.9712, 4.8500, 4.9163]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.03953652 0.00484692]\n",
            "iteration 6376\n",
            "q values:  tensor([[4.9729, 4.8439, 4.9057]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.040901   0.00136448]\n",
            "iteration 6377\n",
            "q values:  tensor([[4.9703, 4.8318, 4.8881]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [ 0.04078428 -0.00011672]\n",
            "iteration 6378\n",
            "q values:  tensor([[4.9708, 4.8318, 4.8879]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [ 0.03818625 -0.00259803]\n",
            "iteration 6379\n",
            "q values:  tensor([[4.9712, 4.8332, 4.8898]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [ 0.03410461 -0.00408164]\n",
            "iteration 6380\n",
            "q values:  tensor([[4.9688, 4.8303, 4.8865]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [ 0.02653603 -0.00756857]\n",
            "iteration 6381\n",
            "q values:  tensor([[5.0339, 4.8879, 4.9438]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [ 0.01747538 -0.00906065]\n",
            "iteration 6382\n",
            "q values:  tensor([[4.9718, 4.8502, 4.9163]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [ 0.00591816 -0.01155722]\n",
            "iteration 6383\n",
            "q values:  tensor([[4.9765, 4.8473, 4.9093]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.00713866 -0.01305682]\n",
            "iteration 6384\n",
            "q values:  tensor([[4.9889, 4.8451, 4.8994]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.02369491 -0.01655625]\n",
            "iteration 6385\n",
            "q values:  tensor([[4.9839, 4.8437, 4.8999]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.04174485 -0.01804994]\n",
            "iteration 6386\n",
            "q values:  tensor([[4.9914, 4.8302, 4.8747]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.06227521 -0.02053036]\n",
            "iteration 6387\n",
            "q values:  tensor([[5.0285, 4.8936, 4.9555]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.08626207 -0.02398686]\n",
            "iteration 6388\n",
            "q values:  tensor([[4.9579, 4.8269, 4.8868]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.11166568 -0.02540361]\n",
            "iteration 6389\n",
            "q values:  tensor([[4.8573, 4.7774, 4.8602]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.13943031 -0.02776464]\n",
            "iteration 6390\n",
            "q values:  tensor([[4.8328, 4.7028, 4.7555]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.16847941 -0.0290491 ]\n",
            "iteration 6391\n",
            "q values:  tensor([[4.9496, 4.8416, 4.9141]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.19971592 -0.0312365 ]\n",
            "iteration 6392\n",
            "q values:  tensor([[4.9334, 4.8017, 4.8596]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.23401696 -0.03430105]\n",
            "iteration 6393\n",
            "q values:  tensor([[4.9063, 4.7492, 4.7908]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.26922681 -0.03520984]\n",
            "iteration 6394\n",
            "q values:  tensor([[4.9982, 4.8477, 4.8988]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.30516459 -0.03593779]\n",
            "iteration 6395\n",
            "q values:  tensor([[4.9694, 4.8714, 4.9508]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.34262588 -0.03746128]\n",
            "iteration 6396\n",
            "q values:  tensor([[4.9834, 4.8745, 4.9485]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.38237875 -0.03975288]\n",
            "iteration 6397\n",
            "q values:  tensor([[4.9895, 4.8494, 4.9060]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.42215938 -0.03978063]\n",
            "iteration 6398\n",
            "q values:  tensor([[4.9826, 4.8402, 4.8950]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.46268911 -0.04052973]\n",
            "iteration 6399\n",
            "q values:  tensor([[5.0335, 4.8728, 4.9202]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.50367313 -0.04098402]\n",
            "iteration 6400\n",
            "q values:  tensor([[4.9996, 4.8634, 4.9228]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.5458065  -0.04213337]\n",
            "iteration 6401\n",
            "q values:  tensor([[5.0005, 4.8573, 4.9128]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.58777343 -0.04196694]\n",
            "iteration 6402\n",
            "q values:  tensor([[5.0022, 4.8620, 4.9193]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.62826203 -0.04048859]\n",
            "iteration 6403\n",
            "q values:  tensor([[4.9900, 4.8615, 4.9247]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.66797848 -0.03971645]\n",
            "iteration 6404\n",
            "q values:  tensor([[4.9713, 4.8320, 4.8878]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.70664563 -0.03866715]\n",
            "iteration 6405\n",
            "q values:  tensor([[2.0025, 1.8170, 1.8404]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.74300789 -0.03636226]\n",
            "iteration 6406\n",
            "q values:  tensor([[3.2968, 3.0613, 2.9595]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.77884087 -0.03583297]\n",
            "iteration 6407\n",
            "q values:  tensor([[4.9848, 4.8675, 4.9369]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.81394119 -0.03510032]\n",
            "iteration 6408\n",
            "q values:  tensor([[4.9953, 4.8720, 4.9385]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.84812904 -0.03418785]\n",
            "iteration 6409\n",
            "q values:  tensor([[5.0398, 4.8782, 4.9256]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.88024961 -0.03212057]\n",
            "iteration 6410\n",
            "q values:  tensor([[4.8621, 4.6930, 4.7251]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.90917723 -0.02892763]\n",
            "iteration 6411\n",
            "q values:  tensor([[4.7612, 4.6369, 4.6885]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.93481612 -0.02563889]\n",
            "iteration 6412\n",
            "q values:  tensor([[4.9949, 4.8769, 4.9463]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.95709575 -0.02227963]\n",
            "iteration 6413\n",
            "q values:  tensor([[5.0001, 4.8743, 4.9397]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.97796616 -0.02087041]\n",
            "iteration 6414\n",
            "q values:  tensor([[4.9983, 4.8480, 4.8992]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.99739029 -0.01942414]\n",
            "iteration 6415\n",
            "q values:  tensor([[4.9979, 4.8509, 4.9039]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.01434229 -0.01695199]\n",
            "iteration 6416\n",
            "q values:  tensor([[5.0807, 4.9209, 4.9717]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.02980641 -0.01546413]\n",
            "iteration 6417\n",
            "q values:  tensor([[5.0467, 4.8855, 4.9334]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.04377394 -0.01396753]\n",
            "iteration 6418\n",
            "q values:  tensor([[5.0073, 4.8611, 4.9153]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.0562416  -0.01246766]\n",
            "iteration 6419\n",
            "q values:  tensor([[5.0040, 4.8602, 4.9156]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.06521018 -0.00896858]\n",
            "iteration 6420\n",
            "q values:  tensor([[4.9985, 4.8503, 4.9028]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.07268241 -0.00747223]\n",
            "iteration 6421\n",
            "q values:  tensor([[5.0127, 4.8614, 4.9130]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.07866194 -0.00597953]\n",
            "iteration 6422\n",
            "q values:  tensor([[4.9942, 4.8432, 4.8939]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.0831526  -0.00449066]\n",
            "iteration 6423\n",
            "q values:  tensor([[4.9595, 4.8157, 4.8683]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.08615779 -0.00300519]\n",
            "iteration 6424\n",
            "q values:  tensor([[5.0196, 4.8724, 4.9266]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.08668004e+00 -5.22247979e-04]\n",
            "iteration 6425\n",
            "q values:  tensor([[5.0250, 4.8714, 4.9224]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.08571981e+00  9.60235261e-04]\n",
            "iteration 6426\n",
            "q values:  tensor([[5.0301, 4.8718, 4.9203]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.08327625  0.00244356]\n",
            "iteration 6427\n",
            "q values:  tensor([[5.0304, 4.8749, 4.9251]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.07934732  0.00392893]\n",
            "iteration 6428\n",
            "q values:  tensor([[5.0262, 4.8766, 4.9300]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.07393001  0.00541731]\n",
            "iteration 6429\n",
            "q values:  tensor([[5.0171, 4.8725, 4.9281]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.06602073  0.00790928]\n",
            "iteration 6430\n",
            "q values:  tensor([[4.9924, 4.8510, 4.9069]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.05561544  0.01040529]\n",
            "iteration 6431\n",
            "q values:  tensor([[4.9958, 4.8513, 4.9056]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.04271095  0.01290449]\n",
            "iteration 6432\n",
            "q values:  tensor([[4.9908, 4.8558, 4.9153]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.02830668  0.01440427]\n",
            "iteration 6433\n",
            "q values:  tensor([[4.9897, 4.8557, 4.9157]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.01140643  0.01690025]\n",
            "iteration 6434\n",
            "q values:  tensor([[4.9863, 4.8479, 4.9051]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.99302057  0.01838586]\n",
            "iteration 6435\n",
            "q values:  tensor([[4.9779, 4.8556, 4.9217]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.97116766  0.02185291]\n",
            "iteration 6436\n",
            "q values:  tensor([[4.9818, 4.8793, 4.9569]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.94687951  0.02428816]\n",
            "iteration 6437\n",
            "q values:  tensor([[4.2105, 4.0138, 3.9902]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.91920371  0.02767579]\n",
            "iteration 6438\n",
            "q values:  tensor([[1.9434, 1.7161, 1.6461]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.89020997  0.02899374]\n",
            "iteration 6439\n",
            "q values:  tensor([[4.9765, 4.8683, 4.9423]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.85998839  0.03022157]\n",
            "iteration 6440\n",
            "q values:  tensor([[4.9980, 4.8607, 4.9194]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.82765084  0.03233755]\n",
            "iteration 6441\n",
            "q values:  tensor([[4.8967, 4.7652, 4.8209]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.79433623  0.03331461]\n",
            "iteration 6442\n",
            "q values:  tensor([[4.9883, 4.8765, 4.9492]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7602071   0.03412914]\n",
            "iteration 6443\n",
            "q values:  tensor([[5.0468, 4.9037, 4.9621]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.7254487   0.03475839]\n",
            "iteration 6444\n",
            "q values:  tensor([[4.9816, 4.8725, 4.9464]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.68926728  0.03618143]\n",
            "iteration 6445\n",
            "q values:  tensor([[4.9820, 4.8679, 4.9389]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.65089386  0.03837342]\n",
            "iteration 6446\n",
            "q values:  tensor([[4.9769, 4.8635, 4.9345]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.61258877  0.03830509]\n",
            "iteration 6447\n",
            "q values:  tensor([[4.9811, 4.8587, 4.9249]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.57362416  0.03896462]\n",
            "iteration 6448\n",
            "q values:  tensor([[4.9776, 4.8639, 4.9349]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.53328576  0.0403384 ]\n",
            "iteration 6449\n",
            "q values:  tensor([[4.9775, 4.8724, 4.9482]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.49287471  0.04041104]\n",
            "iteration 6450\n",
            "q values:  tensor([[4.9837, 4.8593, 4.9244]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.45369378  0.03918094]\n",
            "iteration 6451\n",
            "q values:  tensor([[4.9775, 4.8701, 4.9447]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.41403329  0.03966048]\n",
            "iteration 6452\n",
            "q values:  tensor([[4.9857, 4.8708, 4.9415]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.37517983  0.03885346]\n",
            "iteration 6453\n",
            "q values:  tensor([[4.9867, 4.8762, 4.9495]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.33740309  0.03777674]\n",
            "iteration 6454\n",
            "q values:  tensor([[4.9873, 4.8769, 4.9503]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.30095133  0.03645177]\n",
            "iteration 6455\n",
            "q values:  tensor([[4.9849, 4.8739, 4.9467]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.26504799  0.03590334]\n",
            "iteration 6456\n",
            "q values:  tensor([[4.9923, 4.8755, 4.9455]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.22989511  0.03515288]\n",
            "iteration 6457\n",
            "q values:  tensor([[4.9473, 4.8301, 4.8972]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.19667085  0.03322427]\n",
            "iteration 6458\n",
            "q values:  tensor([[4.9859, 4.8745, 4.9473]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.16452391  0.03214693]\n",
            "iteration 6459\n",
            "q values:  tensor([[4.9881, 4.8698, 4.9388]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.1335786   0.03094532]\n",
            "iteration 6460\n",
            "q values:  tensor([[5.0137, 4.8881, 4.9545]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.10593522  0.02764338]\n",
            "iteration 6461\n",
            "q values:  tensor([[4.9658, 4.8489, 4.9173]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.08166665  0.02426857]\n",
            "iteration 6462\n",
            "q values:  tensor([[4.9887, 4.8565, 4.9175]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.05982342  0.02184323]\n",
            "iteration 6463\n",
            "q values:  tensor([[5.0163, 4.8725, 4.9286]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.04144004  0.01838338]\n",
            "iteration 6464\n",
            "q values:  tensor([[4.9508, 4.8095, 4.8593]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.02653736  0.01490268]\n",
            "iteration 6465\n",
            "q values:  tensor([[4.9875, 4.8557, 4.9168]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.01512677  0.01141059]\n",
            "iteration 6466\n",
            "q values:  tensor([[4.9880, 4.8657, 4.9324]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.0072136   0.00791317]\n",
            "iteration 6467\n",
            "q values:  tensor([[4.9854, 4.8622, 4.9281]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.00179984  0.00541375]\n",
            "iteration 6468\n",
            "q values:  tensor([[4.9808, 4.8556, 4.9202]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.00111395 0.00291379]\n",
            "iteration 6469\n",
            "q values:  tensor([[4.9761, 4.8534, 4.9190]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.00152775 0.0004138 ]\n",
            "iteration 6470\n",
            "q values:  tensor([[4.9712, 4.8499, 4.9161]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [ 0.00044158 -0.00108617]\n",
            "iteration 6471\n",
            "q values:  tensor([[4.9715, 4.8492, 4.9148]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.00414459 -0.00458617]\n",
            "iteration 6472\n",
            "q values:  tensor([[4.9726, 4.8492, 4.9143]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.01223056 -0.00808597]\n",
            "iteration 6473\n",
            "q values:  tensor([[4.9866, 4.8569, 4.9192]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.02281485 -0.01058429]\n",
            "iteration 6474\n",
            "q values:  tensor([[4.9887, 4.8518, 4.9101]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.03589329 -0.01307844]\n",
            "iteration 6475\n",
            "q values:  tensor([[4.9941, 4.8365, 4.8833]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.05145725 -0.01556396]\n",
            "iteration 6476\n",
            "q values:  tensor([[5.0834, 4.9237, 4.9747]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.07049148 -0.01903423]\n",
            "iteration 6477\n",
            "q values:  tensor([[5.0137, 4.8834, 4.9470]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.09297001 -0.02247854]\n",
            "iteration 6478\n",
            "q values:  tensor([[4.9615, 4.8317, 4.8924]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.11885194 -0.02588193]\n",
            "iteration 6479\n",
            "q values:  tensor([[4.7821, 4.7289, 4.8225]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.14807662 -0.02922469]\n",
            "iteration 6480\n",
            "q values:  tensor([[4.7088, 4.5658, 4.6034]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.17955866 -0.03148204]\n",
            "iteration 6481\n",
            "q values:  tensor([[4.9397, 4.8284, 4.8984]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.21318668 -0.03362801]\n",
            "iteration 6482\n",
            "q values:  tensor([[4.9055, 4.7911, 4.8572]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.24882059 -0.03563391]\n",
            "iteration 6483\n",
            "q values:  tensor([[4.9666, 4.8233, 4.8766]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.28728974 -0.03846915]\n",
            "iteration 6484\n",
            "q values:  tensor([[4.9869, 4.8623, 4.9275]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.32838644 -0.0410967 ]\n",
            "iteration 6485\n",
            "q values:  tensor([[4.9753, 4.8685, 4.9433]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.37186496 -0.04347852]\n",
            "iteration 6486\n",
            "q values:  tensor([[4.9898, 4.8563, 4.9167]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.41744259 -0.04557763]\n",
            "iteration 6487\n",
            "q values:  tensor([[4.9837, 4.8504, 4.9105]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.46480301 -0.04736041]\n",
            "iteration 6488\n",
            "q values:  tensor([[5.0444, 4.8869, 4.9368]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.51360211 -0.0487991 ]\n",
            "iteration 6489\n",
            "q values:  tensor([[5.0008, 4.8614, 4.9190]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.56247617 -0.04887406]\n",
            "iteration 6490\n",
            "q values:  tensor([[4.9968, 4.8559, 4.9125]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.61005931 -0.04758314]\n",
            "iteration 6491\n",
            "q values:  tensor([[5.0013, 4.8657, 4.9255]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.65800125 -0.04794194]\n",
            "iteration 6492\n",
            "q values:  tensor([[4.9856, 4.8428, 4.8976]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.70596226 -0.04796101]\n",
            "iteration 6493\n",
            "q values:  tensor([[2.4596, 2.1887, 2.0153]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.75362276 -0.0476605 ]\n",
            "iteration 6494\n",
            "q values:  tensor([[4.9727, 4.8640, 4.9375]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.80069177 -0.04706902]\n",
            "iteration 6495\n",
            "q values:  tensor([[4.9742, 4.8730, 4.9509]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.8459138  -0.04522203]\n",
            "iteration 6496\n",
            "q values:  tensor([[4.7543, 4.5806, 4.6035]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.89007795 -0.04416414]\n",
            "iteration 6497\n",
            "q values:  tensor([[4.3405, 4.1493, 4.1368]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.93301471 -0.04293676]\n",
            "iteration 6498\n",
            "q values:  tensor([[4.9725, 4.8798, 4.9625]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.97259672 -0.03958201]\n",
            "iteration 6499\n",
            "q values:  tensor([[4.9888, 4.8643, 4.9298]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.00974108 -0.03714436]\n",
            "iteration 6500\n",
            "q values:  tensor([[4.9847, 4.8679, 4.9374]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.04540121 -0.03566013]\n",
            "iteration 6501\n",
            "q values:  tensor([[4.9907, 4.8313, 4.8734]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.07956137 -0.03416016]\n",
            "iteration 6502\n",
            "q values:  tensor([[5.0101, 4.8782, 4.9408]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.1112333  -0.03167194]\n",
            "iteration 6503\n",
            "q values:  tensor([[5.0141, 4.8817, 4.9442]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.13945123 -0.02821793]\n",
            "iteration 6504\n",
            "q values:  tensor([[4.7038, 4.5661, 4.5755]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.16626429 -0.02681306]\n",
            "iteration 6505\n",
            "q values:  tensor([[5.0043, 4.8439, 4.8898]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.18973516 -0.02347086]\n",
            "iteration 6506\n",
            "q values:  tensor([[4.8704, 4.7220, 4.7500]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.2  0. ]\n",
            "iteration 6507\n",
            "q values:  tensor([[4.9922, 4.8451, 4.8844]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.1977581  0.0022419]\n",
            "iteration 6508\n",
            "q values:  tensor([[4.9776, 4.8322, 4.8696]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.19326692  0.00449118]\n",
            "iteration 6509\n",
            "q values:  tensor([[5.0136, 4.8652, 4.9068]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.18751196  0.00575497]\n",
            "iteration 6510\n",
            "q values:  tensor([[5.1160, 4.9617, 5.0146]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.17947523  0.00803673]\n",
            "iteration 6511\n",
            "q values:  tensor([[5.1578, 5.0063, 5.0625]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.17013278  0.00934245]\n",
            "iteration 6512\n",
            "q values:  tensor([[5.1069, 4.9611, 5.0111]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.15945844  0.01067435]\n",
            "iteration 6513\n",
            "q values:  tensor([[5.1827, 5.0272, 5.0868]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.14742453  0.0120339 ]\n",
            "iteration 6514\n",
            "q values:  tensor([[5.0381, 4.8765, 4.9237]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.13300279  0.01442174]\n",
            "iteration 6515\n",
            "q values:  tensor([[5.0835, 4.9238, 4.9748]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.11516342  0.01783937]\n",
            "iteration 6516\n",
            "q values:  tensor([[5.1196, 4.9615, 5.0156]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-1.09387584  0.02128758]\n",
            "iteration 6517\n",
            "q values:  tensor([[5.1808, 5.0256, 5.0850]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.07111274  0.02276311]\n",
            "iteration 6518\n",
            "q values:  tensor([[4.9771, 4.8530, 4.9179]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-1.04585606  0.02525668]\n",
            "iteration 6519\n",
            "q values:  tensor([[4.9820, 4.8600, 4.9265]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-1.0190994   0.02675666]\n",
            "iteration 6520\n",
            "q values:  tensor([[4.9866, 4.8485, 4.9060]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.99085162  0.02824778]\n",
            "iteration 6521\n",
            "q values:  tensor([[4.9744, 4.8623, 4.9339]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.95913948  0.03171215]\n",
            "iteration 6522\n",
            "q values:  tensor([[3.5117, 3.2854, 3.2020]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.92501406  0.03412542]\n",
            "iteration 6523\n",
            "q values:  tensor([[1.3370, 1.3219, 1.7354]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.88755472  0.03745934]\n",
            "iteration 6524\n",
            "q values:  tensor([[4.9694, 4.8710, 4.9502]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.84787665  0.03967806]\n",
            "iteration 6525\n",
            "q values:  tensor([[4.9985, 4.8585, 4.9156]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.80513238  0.04274427]\n",
            "iteration 6526\n",
            "q values:  tensor([[4.8818, 4.7699, 4.8360]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.75951884  0.04561354]\n",
            "iteration 6527\n",
            "q values:  tensor([[5.0090, 4.8943, 4.9666]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.71127996  0.04823887]\n",
            "iteration 6528\n",
            "q values:  tensor([[4.9739, 4.8782, 4.9592]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.66070668  0.05057328]\n",
            "iteration 6529\n",
            "q values:  tensor([[4.9764, 4.8717, 4.9477]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.60913385  0.05157284]\n",
            "iteration 6530\n",
            "q values:  tensor([[4.9769, 4.8661, 4.9386]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.55792651  0.05120733]\n",
            "iteration 6531\n",
            "q values:  tensor([[4.9730, 4.8701, 4.9470]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.50546218  0.05246434]\n",
            "iteration 6532\n",
            "q values:  tensor([[4.9797, 4.8668, 4.9383]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.4521338   0.05332838]\n",
            "iteration 6533\n",
            "q values:  tensor([[4.9728, 4.8675, 4.9430]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.39833731  0.05379649]\n",
            "iteration 6534\n",
            "q values:  tensor([[4.9867, 4.8755, 4.9484]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.34545832  0.05287898]\n",
            "iteration 6535\n",
            "q values:  tensor([[4.9895, 4.8845, 4.9611]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.2928527   0.05260563]\n",
            "iteration 6536\n",
            "q values:  tensor([[4.9825, 4.8818, 4.9605]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.24184273  0.05100997]\n",
            "iteration 6537\n",
            "q values:  tensor([[7.2109, 7.2437, 7.4550]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.19270313  0.0491396 ]\n",
            "iteration 6538\n",
            "q values:  tensor([[ 9.5027,  9.7813, 10.1501]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [-0.14665728  0.04604585]\n",
            "iteration 6539\n",
            "q values:  tensor([[8.0435, 8.1265, 8.4207]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [-0.10187333  0.04478395]\n",
            "iteration 6540\n",
            "q values:  tensor([[7.5981, 7.7281, 8.0109]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.05947354  0.04239979]\n",
            "iteration 6541\n",
            "q values:  tensor([[8.1505, 8.3542, 8.6785]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [-0.01953406  0.03993948]\n",
            "iteration 6542\n",
            "q values:  tensor([[6.3527, 6.3930, 6.5527]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.01890972 0.03844377]\n",
            "iteration 6543\n",
            "q values:  tensor([[8.1575, 8.3424, 8.6440]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.05585751 0.03694779]\n",
            "iteration 6544\n",
            "q values:  tensor([[8.6097, 8.7883, 9.2492]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.09134032 0.03548281]\n",
            "iteration 6545\n",
            "q values:  tensor([[10.0733, 10.1005, 10.0544]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.12541641 0.03407609]\n",
            "iteration 6546\n",
            "q values:  tensor([[9.7836, 9.7496, 9.7559]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.15816737 0.03275096]\n",
            "iteration 6547\n",
            "q values:  tensor([[9.6724, 9.6688, 9.7026]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.18969454 0.03152716]\n",
            "iteration 6548\n",
            "q values:  tensor([[8.9487, 8.8789, 8.8664]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.21811571 0.02842117]\n",
            "iteration 6549\n",
            "q values:  tensor([[8.9228, 8.8728, 8.8832]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.24355327 0.02543756]\n",
            "iteration 6550\n",
            "q values:  tensor([[8.9359, 8.9074, 8.9362]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.266129   0.02257573]\n",
            "iteration 6551\n",
            "q values:  tensor([[9.0531, 9.0066, 9.0206]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.28796006 0.02183107]\n",
            "iteration 6552\n",
            "q values:  tensor([[9.1795, 9.1785, 9.2498]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.3081674  0.02020734]\n",
            "iteration 6553\n",
            "q values:  tensor([[9.0437, 9.0107, 9.0359]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.32686916 0.01870176]\n",
            "iteration 6554\n",
            "q values:  tensor([[8.9687, 8.9414, 8.9701]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.34517962 0.01831046]\n",
            "iteration 6555\n",
            "q values:  tensor([[8.9069, 8.8826, 8.9137]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.36321493 0.01803531]\n",
            "iteration 6556\n",
            "q values:  tensor([[8.9909, 8.9570, 8.9828]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.37909324 0.01587831]\n",
            "iteration 6557\n",
            "q values:  tensor([[9.1729, 9.1299, 9.1485]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.39292138 0.01382814]\n",
            "iteration 6558\n",
            "q values:  tensor([[8.9674, 8.9315, 8.9608]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.40479436 0.01187298]\n",
            "iteration 6559\n",
            "q values:  tensor([[8.7131, 8.6974, 8.7544]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.41479505 0.01000069]\n",
            "iteration 6560\n",
            "q values:  tensor([[8.5482, 8.5612, 8.6535]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.42299412 0.00819907]\n",
            "iteration 6561\n",
            "q values:  tensor([[8.6041, 8.6267, 8.7295]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.43145006 0.00845594]\n",
            "iteration 6562\n",
            "q values:  tensor([[8.6830, 8.7003, 8.7979]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.43922366 0.0077736 ]\n",
            "iteration 6563\n",
            "q values:  tensor([[8.7068, 8.7112, 8.7950]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.44737118 0.00814752]\n",
            "iteration 6564\n",
            "q values:  tensor([[8.6668, 8.6557, 8.7233]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.45495196 0.00758078]\n",
            "iteration 6565\n",
            "q values:  tensor([[8.6791, 8.6574, 8.7101]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.46302152 0.00806956]\n",
            "iteration 6566\n",
            "q values:  tensor([[8.7368, 8.7122, 8.7525]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.46963925 0.00661773]\n",
            "iteration 6567\n",
            "q values:  tensor([[8.7507, 8.7258, 8.7626]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.47685405 0.0072148 ]\n",
            "iteration 6568\n",
            "q values:  tensor([[8.8699, 8.8445, 8.8800]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.48471941 0.00786536]\n",
            "iteration 6569\n",
            "q values:  tensor([[2.0359, 1.7470, 1.5373]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  0\n",
            "Current state after Action:  [0.49129383 0.00657443]\n",
            "iteration 6570\n",
            "q values:  tensor([[0.6883, 0.3423, 0.0173]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  1\n",
            "Current state after Action:  [0.49762635 0.00633252]\n",
            "iteration 6571\n",
            "q values:  tensor([[-0.1176, -0.4978, -0.8918]], device='cuda:0', grad_fn=<AddmmBackward>)\n",
            "Action:  2\n",
            "Current state after Action:  [0.50476427 0.00713792]\n",
            "Total testing runtime in seconds:  104.41990733146667\n",
            "Testing Complete\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}